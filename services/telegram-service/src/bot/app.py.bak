#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
tukuai åŠ å¯†å¸‚åœºæƒ…æŠ¥æœºå™¨äºº
UIè®¾è®¡: åŠ¨æ€è§†å›¾å¯¹é½ + ä¸“ä¸šæ’è¡Œæ¦œå±•ç¤º
åŸºäºå¸å®‰Uæœ¬ä½åˆçº¦API v1.0
æ•´åˆç‰ˆæœ¬ï¼šåŒ…å«å……å€¼ã€ç”¨æˆ·ä¸­å¿ƒã€ä¿¡å·è®¢é˜…åŠŸèƒ½
"""

# æµ‹è¯•ç”¨æˆ·IDåˆ—è¡¨ï¼ˆåœ¨æ•°æ®åˆ†ææŠ¥å‘Šä¸­éœ€è¦æ’é™¤çš„ç”¨æˆ·ï¼‰
TEST_USER_IDS = {
    6511182257,   # desci0
}

import os
import sys
import asyncio
import logging
import requests
import time
import functools
import random
import json
import hashlib
import re
import threading
import subprocess
import ssl
import aiohttp
import websockets
import logging
import importlib.util
import httpx
import gzip

# æå‰åˆå§‹åŒ– loggerï¼Œé¿å…å¯é€‰ä¾èµ–ç¼ºå¤±æ—¶ NameError
logger = logging.getLogger(__name__)
# é™ä½ç¬¬ä¸‰æ–¹åº“å™ªå£°
logging.getLogger("httpx").setLevel(logging.WARNING)
logging.getLogger("apscheduler").setLevel(logging.WARNING)

# å¯ç”¨SSLè¯ä¹¦éªŒè¯ - ä½¿ç”¨æ­£ç¡®çš„è¯ä¹¦é…ç½®
# ssl._create_default_https_context = ssl._create_unverified_context  # å·²æ³¨é‡Šï¼Œå¯ç”¨SSLéªŒè¯
print("ğŸ” å…¨å±€SSLéªŒè¯å·²å¯ç”¨ - ä½¿ç”¨æ­£ç¡®çš„è¯ä¹¦é…ç½®")

# SSLè¯ä¹¦æ”¯æŒ
try:
    import certifi
    CERTIFI_AVAILABLE = True
    print(f"[OK] certifiå¯ç”¨ï¼Œè¯ä¹¦è·¯å¾„: {certifi.where()}")
except ImportError:
    CERTIFI_AVAILABLE = False
    print("[WARNING] certifiä¸å¯ç”¨ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è¯ä¹¦")

# Windows SSLè¯ä¹¦æ”¯æŒ
try:
    import wincertstore
    WINCERTSTORE_AVAILABLE = True
    print("[OK] wincertstoreåº“å·²åŠ è½½ï¼Œæ”¯æŒWindowsè¯ä¹¦å­˜å‚¨")
except ImportError:
    WINCERTSTORE_AVAILABLE = False
    print("[INFO] wincertstoreåº“æœªå®‰è£…")

# python-certifi-win32æ”¯æŒ
try:
    import certifi_win32
    certifi_win32.wincerts.where()  # è¿™ä¼šè‡ªåŠ¨å°†Windowsè¯ä¹¦æ·»åŠ åˆ°certifi
    CERTIFI_WIN32_AVAILABLE = True
    print("[OK] python-certifi-win32å·²åŠ è½½ï¼ŒWindowsè¯ä¹¦å·²é›†æˆåˆ°certifi")
except ImportError:
    CERTIFI_WIN32_AVAILABLE = False
    print("[INFO] python-certifi-win32åº“æœªå®‰è£…")
from datetime import datetime, timezone, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Tuple
# å½“å‰ä½ç½® bot/app.pyï¼Œéœ€è¦ä¸Šç§»ä¸€å±‚å›åˆ° src ä½œä¸ºæ ¹
SRC_ROOT = Path(__file__).resolve().parent.parent  # .../src
PROJECT_ROOT = SRC_ROOT.parent                    # .../telegram-service
REPO_SRC_ROOT = PROJECT_ROOT.parent               # ä¸Šå±‚é¡¹ç›®çš„ src ç›®å½•ï¼ŒåŒ…å« utils ç­‰å…±äº«æ¨¡å—
REPO_ROOT = REPO_SRC_ROOT.parent                  # é¡¶å±‚é¡¹ç›®æ ¹ç›®å½•ï¼Œä¾¿äº import src.utils.*
ASSETS_DIR = PROJECT_ROOT / "assets"
ANIMATION_DIR = ASSETS_DIR / "animations"
if str(SRC_ROOT) not in sys.path:
    sys.path.insert(0, str(SRC_ROOT))
if str(REPO_SRC_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_SRC_ROOT))
if str(REPO_ROOT) not in sys.path:
    sys.path.insert(0, str(REPO_ROOT))

# å½“ä»¥è„šæœ¬æ–¹å¼è¿è¡Œï¼ˆ__main__ï¼‰æ—¶ï¼Œä¸ºé¿å… utils.signal_formatter åå‘å¯¼å…¥å¤±è´¥ï¼Œæ˜¾å¼æ³¨å†Œæ¨¡å—åˆ«å
if __name__ == "__main__":
    sys.modules.setdefault("crypto_trading_bot", sys.modules[__name__])

from cards import RankingRegistry

# ==== æ•°æ®åº“æŒ‡æ ‡æœåŠ¡ï¼ˆå¯é€‰ï¼‰ ==============================================
# å‰ç«¯ä»…æ¶ˆè´¹æœ¬åœ° CSV/SQLite æ—¶ä¸éœ€è¦è¿æ¥ Postgres/Timescaleã€‚
# ä¸ºé¿å…æœªå®‰è£… psycopg å¯¼è‡´å¯åŠ¨å¤±è´¥ï¼Œè¿™é‡Œä½¿ç”¨å®‰å…¨é™çº§å¯¼å…¥ã€‚
try:  # noqa: SIM105
    from services.å¸å®‰æ•°æ®åº“æŒ‡æ ‡æœåŠ¡ import å¸å®‰æ•°æ®åº“æŒ‡æ ‡æœåŠ¡ as _MetricService
except Exception as exc:  # pragma: no cover - ç¯å¢ƒç¼ºä¾èµ–æ—¶é™çº§
    _MetricService = None
    logger.warning("âš ï¸ å·²ç¦ç”¨æ•°æ®åº“æŒ‡æ ‡æœåŠ¡ï¼ˆæœªå®‰è£… psycopg æˆ–ä¸éœ€è¦PGï¼‰: %s", exc)
from telegram import Update, InlineKeyboardButton, InlineKeyboardMarkup, ReplyKeyboardMarkup, KeyboardButton
from telegram.request import HTTPXRequest
from telegram.ext import (
    Application,
    CommandHandler,
    CallbackQueryHandler,
    MessageHandler,
    filters,
    ContextTypes,
    ApplicationHandlerStop,  # ç”¨äºåœ¨ç¦ç”¨åœºæ™¯ä¸‹é˜»æ–­åç»­å‘½ä»¤å¤„ç†
)
from telegram.error import Conflict, NetworkError, BadRequest, Forbidden
from telegram.helpers import escape_markdown

# ================== æœ¬åœ° .env åŠ è½½ ==================
ENV_FILE = PROJECT_ROOT / ".env"


def _load_env_file(env_path: Path) -> None:
    """ç®€æ˜“ .env è§£æï¼šKEY=VALUEï¼Œå¿½ç•¥å·²å­˜åœ¨çš„ç¯å¢ƒå˜é‡ã€‚"""
    if not env_path.exists():
        return
    for line in env_path.read_text(encoding="utf-8").splitlines():
        line = line.strip()
        if not line or line.startswith("#") or "=" not in line:
            continue
        key, val = line.split("=", 1)
        if key and key not in os.environ:
            os.environ[key] = val


_load_env_file(ENV_FILE)


def _require_env(name: str, default=None, required: bool = False, cast=None):
    """è·å–å¿…éœ€/å¯é€‰ç¯å¢ƒå˜é‡ï¼Œå¯é€‰ç±»å‹è½¬æ¢ã€‚"""
    val = os.getenv(name, default)
    if required and (val is None or val == ""):
        raise RuntimeError(f"ç¯å¢ƒå˜é‡ {name} æœªè®¾ç½®ï¼Œè¯·åœ¨ .env ä¸­é…ç½®")
    if cast and val is not None and val != "":
        try:
            val = cast(val)
        except Exception as exc:  # pragma: no cover - é…ç½®é”™è¯¯å³æŠ›
            raise RuntimeError(f"ç¯å¢ƒå˜é‡ {name} è§£æå¤±è´¥: {exc}") from exc
    return val

# ç»Ÿä¸€ sys.path ä¼˜å…ˆçº§ï¼šæœ¬æœåŠ¡ src æ”¾æœ€å‰ï¼Œå¹¶ç§»é™¤ä¸å­˜åœ¨çš„å ä½è·¯å¾„
sys.path = [p for p in sys.path if p != str(SRC_ROOT)]
sys.path.insert(0, str(SRC_ROOT))
sys.path = [p for p in sys.path if not (p.endswith('/src') and not Path(p).exists())]


def _load_signal_formatter():
    """é¿å…ä¸ ai.utils å†²çªï¼ŒæŒ‰ç»å¯¹è·¯å¾„åŠ è½½ä¿¡å·æ ¼å¼åŒ–å™¨"""
    module_name = "telegram_signal_formatter"
    if module_name in sys.modules:
        return sys.modules[module_name].SignalFormatter
    module_path = SRC_ROOT / "bot" / "signal_formatter.py"
    spec = importlib.util.spec_from_file_location(module_name, module_path)
    module = importlib.util.module_from_spec(spec)
    spec.loader.exec_module(module)
    sys.modules[module_name] = module
    return module.SignalFormatter


# ================== é¢‘é“é…ç½®ä¸æƒé™åŠ©æ‰‹ ==================

def _load_channel_config() -> Dict[str, Dict[str, Any]]:
    cfg = DataManager.load_json(TELEGRAM_CHANNEL_CONFIG_FILE, {})
    if not isinstance(cfg, dict):
        cfg = {}
    # å…¨é‡è¿ç§»åˆ°æ–°æ ¼å¼ï¼Œé¿å…é—ç•™å­—æ®µå¯¼è‡´é€»è¾‘åˆ†å‰
    migrated = {}
    changed = False
    for k, v in cfg.items():
        new_v = _migrate_chat_cfg(v or {})
        migrated[k] = new_v
        if new_v != v:
            changed = True
    if changed:
        DataManager.save_json(TELEGRAM_CHANNEL_CONFIG_FILE, migrated, create_backup=True)
    return migrated


MAIN_THREAD_KEY = "__main__"

def _migrate_chat_cfg(chat_cfg: Dict[str, Any]) -> Dict[str, Any]:
    """
    è¿ç§»åˆ°æœ€ç®€äºŒå…ƒå¼€å…³æ¨¡å‹ï¼š
    states: {thread_key: bool_enabled}ï¼Œthread_key="__main__" è¡¨ç¤ºä¸»é¢‘é“
    æœªå†™å…¥è¡¨ç¤ºé»˜è®¤å¯ç”¨
    """
    states_input = chat_cfg.get("states")
    if isinstance(states_input, dict):
        states: Dict[str, bool] = {str(k): bool(v) for k, v in states_input.items()}
    else:
        states = {}

    return {
        "states": states,
        "retention_seconds": int(chat_cfg.get("retention_seconds", 0)),
    }


def _save_channel_config(cfg: Dict[str, Dict[str, Any]]) -> None:
    DataManager.save_json(TELEGRAM_CHANNEL_CONFIG_FILE, cfg, create_backup=True)


def _ensure_chat_config(chat_id: int) -> Dict[str, Any]:
    cfg = _load_channel_config()
    key = str(chat_id)
    chat_cfg = cfg.get(key) or {}
    chat_cfg = _migrate_chat_cfg(chat_cfg)
    chat_cfg.setdefault("retention_seconds", 0)
    chat_cfg.setdefault("states", {})
    cfg[key] = chat_cfg
    _save_channel_config(cfg)
    return chat_cfg


def _set_topic_state(chat_id: int, thread_id: int, enabled: bool) -> Tuple[Dict[str, Any], bool]:
    cfg = _load_channel_config()
    key = str(chat_id)
    chat_cfg = _migrate_chat_cfg(cfg.get(key) or {"states": {}, "retention_seconds": 0})

    states = chat_cfg.get("states", {})
    states[str(thread_id)] = bool(enabled)
    chat_cfg["states"] = states

    cfg[key] = chat_cfg
    _save_channel_config(cfg)
    logger.info("ğŸ”§ set_topic_state chat=%s thread=%s enabled=%s cfg=%s", chat_id, thread_id, enabled, chat_cfg)
    return chat_cfg, enabled


def _set_group_state(chat_id: int, enabled: bool) -> Dict[str, Any]:
    """è®¾ç½®ä¸»é¢‘é“å¯ç”¨/ç¦ç”¨ï¼ˆç‹¬ç«‹å¼€å…³ï¼‰"""
    cfg = _load_channel_config()
    key = str(chat_id)
    chat_cfg = _migrate_chat_cfg(cfg.get(key) or {"states": {}, "retention_seconds": 0})
    states = chat_cfg.get("states", {})
    states[MAIN_THREAD_KEY] = bool(enabled)
    chat_cfg["states"] = states
    cfg[key] = chat_cfg
    _save_channel_config(cfg)
    logger.info("ğŸ”§ set_group_state chat=%s enabled=%s cfg=%s", chat_id, enabled, chat_cfg)
    return chat_cfg


def _set_retention(chat_id: int, seconds: int) -> Dict[str, Any]:
    cfg = _load_channel_config()
    key = str(chat_id)
    chat_cfg = cfg.get(key) or {"states": {}, "retention_seconds": 0}
    chat_cfg["retention_seconds"] = max(0, int(seconds))
    cfg[key] = chat_cfg
    _save_channel_config(cfg)
    return chat_cfg


def _get_retention(chat_id: int) -> int:
    return _ensure_chat_config(chat_id).get("retention_seconds", 0)


def _is_bot_allowed(chat, thread_id: Optional[int]) -> tuple[bool, str]:
    """
    ç»Ÿä¸€æƒé™æ£€æŸ¥ï¼ˆæç®€äºŒå…ƒå¼€å…³ï¼‰ï¼š
    - æ¯ä¸ª chat_id + thread_id ç‹¬ç«‹å¸ƒå°”å¼€å…³ï¼Œé»˜è®¤å¯ç”¨
    - å…³é—­æ—¶ä»…å…è®¸ /helpï¼ˆæŒ‰é’®åŒç†ï¼‰
    - ç§èŠç›´æ¥æ”¾è¡Œ
    """
    if chat.type not in {"group", "supergroup"}:
        return True, ""

    cfg = _ensure_chat_config(chat.id)
    states = cfg.get("states", {})
    # ç‰¹æ®Šè§„åˆ™ï¼šhazenlee ç¾¤ä»…å…è®¸ç™½åå•è¯é¢˜ï¼Œå…¶å®ƒè¯é¢˜é»˜è®¤å…³é—­
    if chat.id == -1003129285448:
        if thread_id is None:
            key = MAIN_THREAD_KEY
            enabled = states.get(key, False)
        else:
            key = str(thread_id)
            if key not in states:
                logger.info("ğŸš« hazenlee default deny chat=%s thread=%s cfg=%s", chat.id, thread_id, cfg)
                return False, "æœ¬é¢‘é“å·²å…³é—­æœºå™¨äººï¼Œç‚¹å‡»å¼€å¯åå†è¯•ã€‚"
            enabled = states.get(key, False)
    else:
        # é€šç”¨è§„åˆ™ï¼š
        # - MAIN_THREAD_KEY åªæ§åˆ¶ä¸»é¢‘é“ï¼ˆæ— è¯é¢˜ï¼‰æ¶ˆæ¯
        # - è¯é¢˜ç‹¬ç«‹å¼€å…³ï¼›æœªæ˜¾å¼é…ç½®çš„è¯é¢˜é»˜è®¤å¼€å¯ï¼ˆä¸è¢«ä¸»å¼€å…³ç‰µè¿ï¼‰
        if thread_id is None:
            enabled = states.get(MAIN_THREAD_KEY, True)
            key = MAIN_THREAD_KEY
        else:
            key = str(thread_id)
            enabled = states.get(key, True)

    if not enabled:
        logger.info("ğŸš« disabled chat=%s thread=%s cfg=%s", chat.id, thread_id, cfg)
        return False, "æœ¬é¢‘é“å·²å…³é—­æœºå™¨äººï¼Œç‚¹å‡»å¼€å¯åå†è¯•ã€‚"

    return True, ""


def _is_command_allowed(update) -> bool:
    """å‘½ä»¤é€šç”¨æ‹¦æˆªï¼ˆé™¤ /helpï¼‰ï¼Œå¹¶å‘ç”¨æˆ·ç»™å‡ºæ˜ç¡®æç¤º"""
    chat = update.effective_chat
    msg = update.effective_message
    thread_id = getattr(msg, "message_thread_id", None) if msg else None
    allowed, reason = _is_bot_allowed(chat, thread_id)
    if allowed:
        return True

    # æœªå¯ç”¨æ—¶é™é»˜ä¸¢å¼ƒï¼ˆç¬¦åˆâ€œé™¤å¸®åŠ©å¤–ä¸å“åº”â€ï¼‰
    return False


async def _block_disabled_commands(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    åœ¨ç¾¤/è¯é¢˜è¢«å…³é—­æ—¶ï¼Œé™¤äº† /help ä¹‹å¤–çš„æ‰€æœ‰å‘½ä»¤ä¸€å¾‹é™é»˜ä¸¢å¼ƒï¼Œ
    å¹¶ä¸»åŠ¨ç»ˆæ­¢åç»­å‘½ä»¤å¤„ç†å™¨ï¼Œç¡®ä¿â€œå…³é—­=å®Œå…¨ä¸å“åº”â€ã€‚
    """
    chat = update.effective_chat
    msg = update.effective_message
    if not chat or not msg or chat.type not in {"group", "supergroup"}:
        return

    thread_id = getattr(msg, "message_thread_id", None)
    allowed, _reason = _is_bot_allowed(chat, thread_id)
    if allowed:
        return

    cmd = (msg.text or "").split()[0]
    if cmd.startswith("/help"):  # å…è®¸ç”¨æˆ·ç”¨ /help é‡æ–°æ‰“å¼€æˆ–æŸ¥çœ‹çŠ¶æ€
        return

    # ç¾¤å·²å…³é—­ä¸”ä¸æ˜¯ /helpï¼Œé™é»˜é˜»æ–­åç»­å¤„ç†
    raise ApplicationHandlerStop


async def _block_disabled_messages(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    å…¨å±€ç¡¬æ‹¦æˆªï¼šç¾¤/è¯é¢˜å…³é—­æ—¶ï¼Œä»»ä½•é /help çš„æ¶ˆæ¯ï¼ˆæ–‡æœ¬ã€è´´çº¸ç­‰ï¼‰ç«‹å³ç»ˆæ­¢å¤„ç†ã€‚
    ç›®çš„ï¼šé¿å…â€œå›å¤å½¢å¼çš„æ¶ˆæ¯â€è¢«è¯¯åˆ¤ä¸ºæŒ‡ä»¤ä»è§¦å‘æç¤ºã€‚
    """
    chat = update.effective_chat
    if not chat or chat.type not in {"group", "supergroup"}:
        return

    # å…¼å®¹æ¶ˆæ¯/å›è°ƒä¸åŒå…¥å£
    msg = update.effective_message
    thread_id = getattr(msg, "message_thread_id", None) if msg else None
    allowed, _reason = _is_bot_allowed(chat, thread_id)
    if allowed:
        return

    # æ”¾è¡Œå¸®åŠ©ç›¸å…³
    if msg:
        text = (msg.text or msg.caption or "").strip()
        if text.startswith("/help"):
            return
    if update.callback_query:
        data = update.callback_query.data or ""
        if data in {"help", "group_enable", "group_disable", "topic_enable", "topic_disable", "channel_enable", "channel_disable"} or data.startswith("ttl:"):
            return

    # é˜»æ–­åç»­æ‰€æœ‰å¤„ç†å™¨
    raise ApplicationHandlerStop


async def _is_group_admin(bot_obj, chat_id: int, user_id: int) -> bool:
    if user_id == ADMIN_OVERRIDE_ID:
        return True
    try:
        member = await bot_obj.get_chat_member(chat_id, user_id)
        return member.status in ("administrator", "creator")
    except Exception:
        return False


def _build_help_keyboard(chat_id: int, thread_id: Optional[int], chat_type: str) -> InlineKeyboardMarkup:
    chat_cfg = _ensure_chat_config(chat_id)
    is_group = chat_type in {"group", "supergroup"}
    rows: List[List[InlineKeyboardButton]] = []

    if is_group:
        current_ttl = chat_cfg.get("retention_seconds", 0)

        def _ttl_btn(label: str, sec: int) -> InlineKeyboardButton:
            active = current_ttl == sec
            prefix = "âœ… " if active else ""
            return InlineKeyboardButton(f"{prefix}{label}", callback_data=f"ttl:{sec}")

        rows.append([
            _ttl_btn("1åˆ†é’Ÿ", 60),
            _ttl_btn("5åˆ†é’Ÿ", 300),
            _ttl_btn("ä¸åˆ é™¤", 0),
        ])

    if is_group:
        # ä»¥ states["__main__"] ä¸ºå‡†
        group_enabled = chat_cfg["states"].get(MAIN_THREAD_KEY, True)
        main_enable_label = "âœ… æœ¬ç¾¤å¯ç”¨" if group_enabled else "æœ¬ç¾¤å¯ç”¨"
        main_disable_label = "âœ… æœ¬ç¾¤ç¦ç”¨" if not group_enabled else "æœ¬ç¾¤ç¦ç”¨"

        # ç»Ÿä¸€äºŒå…ƒå¼€å…³ï¼šè¯é¢˜/å­é¢‘é“
        if thread_id is not None:
            current_enabled = chat_cfg["states"].get(str(thread_id), True)
            enable_label = "âœ… è¯é¢˜å¯ç”¨" if current_enabled else "è¯é¢˜å¯ç”¨"
            disable_label = "âœ… è¯é¢˜å…³é—­" if not current_enabled else "è¯é¢˜å…³é—­"
            # å››ä¸ªæŒ‰é’®åˆå¹¶ä¸€è¡Œï¼Œå¸¸é©»å±•ç¤º
            rows.append([
                InlineKeyboardButton(main_disable_label, callback_data="group_disable"),
                InlineKeyboardButton(main_enable_label, callback_data="group_enable"),
                InlineKeyboardButton(disable_label, callback_data="channel_disable"),
                InlineKeyboardButton(enable_label, callback_data="channel_enable"),
            ])
        else:
            rows.append([
                InlineKeyboardButton(main_disable_label, callback_data="group_disable"),
                InlineKeyboardButton(main_enable_label, callback_data="group_enable"),
            ])

    rows.append([InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")])

    return InlineKeyboardMarkup(rows)

def _append_auto_delete_record(chat_id: int, message_id: int, ttl: int):
    """è®°å½•éœ€è¦è‡ªåŠ¨åˆ é™¤çš„æ¶ˆæ¯ï¼Œæ–¹ä¾¿åå°è¡¥å¿æ¸…ç†"""
    try:
        now = int(time.time())
        expire_at = now + max(1, int(ttl))
        records = DataManager.load_json(AUTO_DELETE_INDEX_FILE, [])
        if not isinstance(records, list):
            records = []
        key = (chat_id, message_id)
        if any(r.get("chat_id") == key[0] and r.get("message_id") == key[1] for r in records):
            return
        records.append({"chat_id": chat_id, "message_id": message_id, "expire_at": expire_at})
        # æ§åˆ¶ç´¢å¼•å¤§å°ï¼Œé¿å…æ— é™å¢é•¿
        if len(records) > 5000:
            records = records[-4000:]
        DataManager.save_json(AUTO_DELETE_INDEX_FILE, records, create_backup=False)
    except Exception as exc:
        logger.debug("âš ï¸ è®°å½•è‡ªåŠ¨åˆ é™¤ç´¢å¼•å¤±è´¥: %s", exc)

def _remove_auto_delete_record(chat_id: int, message_id: int):
    """åˆ é™¤ç´¢å¼•ä¸­çš„å·²æ¸…ç†æ¶ˆæ¯"""
    try:
        records = DataManager.load_json(AUTO_DELETE_INDEX_FILE, [])
        if not isinstance(records, list) or not records:
            return
        filtered = [r for r in records if not (r.get("chat_id") == chat_id and r.get("message_id") == message_id)]
        if len(filtered) != len(records):
            DataManager.save_json(AUTO_DELETE_INDEX_FILE, filtered, create_backup=False)
    except Exception as exc:
        logger.debug("âš ï¸ æ¸…ç†è‡ªåŠ¨åˆ é™¤ç´¢å¼•å¤±è´¥: %s", exc)

async def _auto_delete_gc(bot_obj):
    """åå°è¡¥å¿æ¸…ç†ï¼šæ‰«æç´¢å¼•ï¼Œåˆ é™¤å·²è¿‡æœŸä½†æœªæˆåŠŸåˆ é™¤çš„æ¶ˆæ¯"""
    try:
        records = DataManager.load_json(AUTO_DELETE_INDEX_FILE, [])
        if not isinstance(records, list) or not records:
            return
        now = int(time.time())
        remaining = []

        # é™åˆ¶å•æ¬¡å¤„ç†é‡ï¼Œé¿å…é•¿æ—¶é—´å ç”¨äº‹ä»¶å¾ªç¯
        MAX_BATCH = 50
        processed = 0

        for r in records:
            if processed >= MAX_BATCH:
                remaining.append(r)
                continue

            try:
                expire_at = int(r.get("expire_at", 0))
                if expire_at > now:
                    remaining.append(r)
                    continue

                await bot_obj.delete_message(r["chat_id"], r["message_id"])
                processed += 1
                continue

            except BadRequest as exc:
                # å¯¹ 400 ç³»åˆ—ï¼ˆæ¶ˆæ¯ä¸å­˜åœ¨/å·²åˆ é™¤ï¼‰ç›´æ¥ä¸¢å¼ƒç´¢å¼•ï¼Œé¿å…æ°¸è¿œé‡è¯•
                logger.debug("ğŸ§¹ è‡ªåŠ¨åˆ é™¤è·³è¿‡ BadRequest chat=%s msg=%s: %s",
                             r.get('chat_id'), r.get('message_id'), exc)
                processed += 1
                continue
            except Forbidden as exc:
                # æ— æƒé™åˆ é™¤æ—¶ä¹Ÿä¸¢å¼ƒï¼Œé˜²æ­¢æ¯åˆ†é’Ÿé‡è¯•
                logger.warning("ğŸ›‘ æ— æƒé™åˆ é™¤ chat=%s msg=%s: %s",
                               r.get('chat_id'), r.get('message_id'), exc)
                processed += 1
                continue
            except Exception as exc:
                # ä»»ä½•å…¶ä»–é”™è¯¯ä¹Ÿä¸å†é‡è¯•ï¼Œç›´æ¥ä¸¢å¼ƒ
                logger.debug("âš ï¸ è¡¥å¿åˆ é™¤å¤±è´¥ï¼ˆä¸å†é‡è¯•ï¼‰ chat=%s msg=%s: %s",
                             r.get('chat_id'), r.get('message_id'), exc)
                processed += 1
                continue

        if len(remaining) != len(records):
            DataManager.save_json(AUTO_DELETE_INDEX_FILE, remaining, create_backup=False)
    except Exception as exc:
        logger.debug("âš ï¸ è‡ªåŠ¨åˆ é™¤åå°æ¸…ç†ä»»åŠ¡å¼‚å¸¸: %s", exc)


_AUTO_DELETE_PATCHED = False


def _patch_extbot_auto_delete():
    """å¯¹ ExtBot ç±»çº§åˆ«æ‰“è¡¥ä¸ï¼Œè¦†ç›–å¸¸ç”¨å‘é€æ¥å£ä»¥æŒ‚è½½ TTL è‡ªåŠ¨åˆ é™¤"""
    global _AUTO_DELETE_PATCHED
    if _AUTO_DELETE_PATCHED:
        return

    from telegram.ext import ExtBot

    def wrap(name: str, returns_list: bool = False):
        orig = getattr(ExtBot, name)

        @functools.wraps(orig)
        async def _wrapped(self, *args, **kwargs):
            msg = await orig(self, *args, **kwargs)
            try:
                msgs = msg if returns_list else [msg]
                for m in msgs:
                    chat = getattr(m, "chat", None)
                    if not chat:
                        continue
                    if chat.type in {"group", "supergroup"}:
                        ttl = _get_retention(chat.id)
                        # ç¾¤èŠ bot æ¶ˆæ¯å³ä¾¿æœªé…ç½® TTL ä¹Ÿå¼ºåˆ¶æŒ‰å‘½ä»¤åŒæ ·çš„ 60s åˆ é™¤
                        if ttl <= 0:
                            ttl = COMMAND_FORCE_TTL
                    else:
                        ttl = 0
                    if ttl > 0:
                        asyncio.create_task(_schedule_auto_delete(self, chat.id, m.message_id, ttl))
            except Exception as exc:
                logger.debug("âš ï¸ å…¨å±€è‡ªåŠ¨åˆ é™¤å°è£…å¤±è´¥: %s", exc)
            return msg

        setattr(ExtBot, name, _wrapped)

    wrap("send_message")
    wrap("send_photo")
    wrap("send_document")
    wrap("send_video")
    wrap("send_animation")
    wrap("send_voice")
    wrap("send_audio")
    wrap("send_media_group", returns_list=True)

    _AUTO_DELETE_PATCHED = True

def _enable_global_auto_delete(bot_obj):
    """å·²åºŸå¼ƒï¼šä½¿ç”¨ ExtBot ç±»çº§åˆ«è¡¥ä¸å®ç°å…¨å±€è‡ªåŠ¨åˆ é™¤"""
    logger.warning("_enable_global_auto_delete å·²å¼ƒç”¨ï¼Œè¯·ä½¿ç”¨ _patch_extbot_auto_delete")


async def _schedule_auto_delete(bot_obj, chat_id: int, message_id: int, ttl: int):
    if ttl <= 0:
        return
    try:
        _append_auto_delete_record(chat_id, message_id, ttl)
        await asyncio.sleep(ttl)
        await bot_obj.delete_message(chat_id, message_id)
        _remove_auto_delete_record(chat_id, message_id)
    except Exception as exc:  # åˆ é™¤å¤±è´¥åŠ å¼ºæç¤ºï¼Œä¾¿äºå‘ç°æƒé™é—®é¢˜
        logger.warning("ğŸ§¹ è‡ªåŠ¨åˆ é™¤æ¶ˆæ¯å¤±è´¥ chat=%s msg=%s: %s", chat_id, message_id, exc)


async def _maybe_delete_user_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ç¾¤èŠå†…ç”¨æˆ·å‘å‡ºçš„è§¦å‘æ¶ˆæ¯ä¹ŸæŒ‰TTLè‡ªåŠ¨åˆ é™¤"""
    try:
        chat = update.effective_chat
        msg = update.effective_message
        if not chat or not msg:
            return
        if chat.type not in {"group", "supergroup"}:
            return
        ttl = _get_retention(chat.id)
        if ttl > 0:
            asyncio.create_task(_schedule_auto_delete(context.bot, chat.id, msg.message_id, ttl))
    except Exception as exc:
        logger.debug("âš ï¸ ç”¨æˆ·æ¶ˆæ¯è‡ªåŠ¨åˆ é™¤è°ƒåº¦å¤±è´¥: %s", exc)


async def _force_delete_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """
    ç¾¤èŠå‘½ä»¤æ¶ˆæ¯å¼ºåˆ¶æŒ‚60ç§’åˆ é™¤ï¼Œä¸ retention_seconds æ— å…³ã€‚
    ç›®çš„ï¼šè¦†ç›– /start@bot ç­‰å¸¦ @ å½¢å¼ï¼Œç¡®ä¿æœ€å¼ºç”Ÿæ•ˆã€‚
    """
    try:
        chat = update.effective_chat
        msg = update.effective_message
        if not chat or not msg:
            return
        if chat.type not in {"group", "supergroup"}:
            return
        asyncio.create_task(_schedule_auto_delete(context.bot, chat.id, msg.message_id, COMMAND_FORCE_TTL))
    except Exception as exc:
        logger.debug("âš ï¸ å‘½ä»¤å¼ºåˆ¶è‡ªåŠ¨åˆ é™¤è°ƒåº¦å¤±è´¥: %s", exc)


async def send_help_message(update_or_query, context: ContextTypes.DEFAULT_TYPE, *, via_query: bool = False):
    """ç»Ÿä¸€çš„å¸®åŠ©å±•ç¤ºä¸è‡ªåŠ¨åˆ é™¤ã€ç™½åå•æ§åˆ¶"""
    help_text = """â„¹ï¸tukuaiåŠ å¯†å¸‚åœºæƒ…æŠ¥æœºå™¨äººä½¿ç”¨æŒ‡å—

âš¡ï¸ å¯ç”¨å‘½ä»¤ï¼š
/start ğŸ  - å¼€å§‹ä½¿ç”¨ï¼Œæ˜¾ç¤ºä¸»èœå•
/stats ğŸ‘¤ - ç”¨æˆ·ä¸­å¿ƒï¼ŒæŸ¥çœ‹ä¸ªäººä¿¡æ¯
/help â„¹ï¸ - å¸®åŠ©æŒ‡å—ï¼ŒæŸ¥çœ‹ä½¿ç”¨è¯´æ˜
/recharge ğŸ’³ - å……å€¼ä¸­å¿ƒï¼Œè´¦æˆ·å……å€¼

ğŸ”§ ä½¿ç”¨æ–¹æ³•ï¼š
å‘é€ /start æŸ¥çœ‹ä¸»èœå•
ä½¿ç”¨åº•éƒ¨é”®ç›˜å¿«é€Ÿå¯¼èˆª
ç‚¹å‡»å†…è”æŒ‰é’®æµè§ˆå„ç§æ•°æ®æ’è¡Œæ¦œ
æ”¯æŒå¤šç§æ—¶é—´æ®µå’Œæ’åºæ–¹å¼

ğŸ“ æŠ€æœ¯æ”¯æŒï¼š
å¦‚æœ‰é—®é¢˜è¯·è”ç³»å®¢æœï¼š@desci0"""

    if via_query:
        query = update_or_query.callback_query
        chat = query.message.chat
        thread_id = getattr(query.message, "message_thread_id", None)
    else:
        chat = update_or_query.message.chat
        thread_id = getattr(update_or_query.message, "message_thread_id", None)
        query = None

    chat_id = chat.id
    chat_type = chat.type
    is_group = chat_type in {"group", "supergroup"}

    keyboard = _build_help_keyboard(chat_id, thread_id, chat_type)

    if query:
        sent = await query.message.reply_text(help_text, reply_markup=keyboard, parse_mode='Markdown')
    else:
        sent = await update_or_query.message.reply_text(help_text, reply_markup=keyboard, parse_mode='Markdown')

    # è‡ªåŠ¨åˆ é™¤ç”±å…¨å±€å°è£…ç»Ÿä¸€å¤„ç†ï¼Œè¿™é‡Œæ— éœ€é‡å¤å®‰æ’

# æ·»åŠ ä¿¡å·ç›‘æ§æ‰€éœ€çš„å¯¼å…¥
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger

# ç”¨æˆ·æ•°æ®ä¿æŠ¤åŠŸèƒ½å·²ç§»é™¤
from apscheduler.triggers.interval import IntervalTrigger
try:
    from telethon import TelegramClient, events
    from telethon.sessions import StringSession
    TELETHON_AVAILABLE = True
except ImportError:
    TELETHON_AVAILABLE = False
    logger.warning("âš ï¸ Telethonæœªå®‰è£…ï¼ŒTelegramç›‘å¬åŠŸèƒ½å°†è¢«ç¦ç”¨")

# é…ç½®æ—¥å¿—
# æ—¥å¿—ç›®å½•è¿ç§»åˆ°æœåŠ¡æ ¹ç›®å½•ï¼Œé¿å…ä¸æºç æ··æ”¾
LOG_DIR = PROJECT_ROOT / "logs"
LOG_DIR.mkdir(parents=True, exist_ok=True)
LOG_FILE = LOG_DIR / "telegram_bot.log"

logging.basicConfig(
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    level=logging.INFO,
    handlers=[
        logging.FileHandler(LOG_FILE, encoding="utf-8"),
        logging.StreamHandler(sys.stdout),
    ],
)
logger = logging.getLogger(__name__)

# æ’è¡Œæ¦œå¡ç‰‡æ³¨å†Œè¡¨ï¼ˆå»¶è¿ŸåŠ è½½ï¼‰
ranking_registry: Optional[RankingRegistry] = None


try:
    BINANCE_DB_METRIC_SERVICE = _MetricService() if _MetricService else None
    if BINANCE_DB_METRIC_SERVICE:
        logger.info("âœ… å¸å®‰æ•°æ®åº“æŒ‡æ ‡æœåŠ¡å·²åˆå§‹åŒ–")
    else:
        logger.info("â¸ï¸ å¸å®‰æ•°æ®åº“æŒ‡æ ‡æœåŠ¡æœªå¯ç”¨ï¼ˆæœ¬åœ°CSVæ¨¡å¼ï¼‰")
except Exception as exc:  # pragma: no cover - åˆå§‹åŒ–å¤±è´¥æ—¶è®°å½•æ—¥å¿—
    BINANCE_DB_METRIC_SERVICE = None
    logger.warning("âš ï¸ å¸å®‰æ•°æ®åº“æŒ‡æ ‡æœåŠ¡ä¸å¯ç”¨: %s", exc)


def _ensure_ranking_sys_path():
    """ä¿éšœæ’è¡Œæ¦œå¡ç‰‡ä¾èµ–è·¯å¾„å®Œæ•´ï¼Œé¿å…æ³¨å†Œè¡¨ä¸ºç©º"""
    added_paths = []
    for path in (REPO_ROOT, REPO_SRC_ROOT, SRC_ROOT):
        if str(path) not in sys.path:
            sys.path.insert(0, str(path))
            added_paths.append(str(path))
    if added_paths:
        logger.info("ğŸ”§ å·²è¡¥å……æ’è¡Œæ¦œä¾èµ–è·¯å¾„: %s", added_paths)


def ensure_ranking_registry() -> Optional[RankingRegistry]:
    """æƒ°æ€§åˆå§‹åŒ–æ’è¡Œæ¦œå¡ç‰‡æ³¨å†Œè¡¨"""
    global ranking_registry
    if ranking_registry is not None:
        return ranking_registry

    try:
        _ensure_ranking_sys_path()
        registry = RankingRegistry("cards")
        registry.load_cards()
        if registry.card_count() == 0:
            logger.warning("âš ï¸ æ’è¡Œæ¦œå¡ç‰‡æ³¨å†Œè¡¨ä¸ºç©ºï¼Œè§¦å‘è·¯å¾„ä¿®å¤åé‡è½½")
            registry.load_cards()
        if registry.card_count() == 0:
            raise RuntimeError("æ’è¡Œæ¦œå¡ç‰‡æ³¨å†Œè¡¨ä¸ºç©ºï¼Œåˆå§‹åŒ–å¤±è´¥")
        ranking_registry = registry
        logger.info("âœ… æ’è¡Œæ¦œå¡ç‰‡æ³¨å†Œè¡¨åˆå§‹åŒ–å®Œæˆï¼Œå…± %d ä¸ªå¡ç‰‡", registry.card_count())
    except Exception as exc:  # pylint: disable=broad-except
        logger.error("âŒ åˆå§‹åŒ–æ’è¡Œæ¦œå¡ç‰‡æ³¨å†Œè¡¨å¤±è´¥: %s", exc)
        ranking_registry = None
    return ranking_registry

# ç”¨æˆ·æ•°æ®ä¿æŠ¤ç›¸å…³å‡½æ•°å·²ç§»é™¤ï¼Œç›´æ¥ä½¿ç”¨DataManager

# åŒ—äº¬æ—¶é—´å·¥å…·å‡½æ•°
def get_beijing_time():
    """è·å–åŒ—äº¬æ—¶é—´"""
    beijing_tz = timezone(timedelta(hours=8))
    return datetime.now(beijing_tz)

def beijing_time_isoformat():
    """è·å–åŒ—äº¬æ—¶é—´çš„ISOæ ¼å¼å­—ç¬¦ä¸²"""
    return get_beijing_time().isoformat()

def format_beijing_time(dt_str, format_str="%Y-%m-%d %H:%M:%S"):
    """å°†ISOæ ¼å¼çš„æ—¶é—´å­—ç¬¦ä¸²è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´å¹¶æ ¼å¼åŒ–"""
    try:
        # å¦‚æœè¾“å…¥çš„æ˜¯ISOæ ¼å¼å­—ç¬¦ä¸²ï¼Œå…ˆè§£æ
        if isinstance(dt_str, str):
            dt = datetime.fromisoformat(dt_str.replace('Z', '+00:00'))
        else:
            dt = dt_str
        
        # å¦‚æœæ²¡æœ‰æ—¶åŒºä¿¡æ¯ï¼Œå‡è®¾æ˜¯UTC
        if dt.tzinfo is None:
            dt = dt.replace(tzinfo=timezone.utc)
        
        # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´
        beijing_tz = timezone(timedelta(hours=8))
        beijing_dt = dt.astimezone(beijing_tz)
        
        return beijing_dt.strftime(format_str)
    except Exception as e:
        logger.error(f"æ—¶é—´æ ¼å¼åŒ–å¤±è´¥: {e}")
        return str(dt_str)


# é…ç½®ï¼ˆå…¨éƒ¨æ”¹ç”±ç¯å¢ƒå˜é‡ç®¡ç†ï¼‰
BOT_TOKEN = _require_env('BOT_TOKEN', required=True)
TELEGRAM_BOT_TOKEN = BOT_TOKEN  # ä¸ºäº†å…¼å®¹æ€§æ·»åŠ åˆ«å
BINANCE_FUTURES_URL = 'https://fapi.binance.com'
BINANCE_SPOT_URL = 'https://api.binance.com'
ENABLE_SCHEDULED_BACKUP = _require_env('ENABLE_SCHEDULED_BACKUP', default='1') == '1'
# å…³é—­CoinGlassç›¸å…³åŠŸèƒ½ï¼šé»˜è®¤å…³é—­ï¼ˆæ— API/æœ¬åœ°æ•°æ®æ—¶é¿å…æŠ¥é”™ï¼‰
COINGLASS_DISABLED = _require_env('COINGLASS_DISABLED', default='1') == '1'
# å…³é—­Binance APIè°ƒç”¨ï¼šé»˜è®¤å…³é—­ï¼ˆä»…ä½¿ç”¨æœ¬åœ°SQLiteæ•°æ®ï¼‰
BINANCE_API_DISABLED = _require_env('BINANCE_API_DISABLED', default='1') == '1'
# AIå…è´¹æ¨¡å¼å¼€å…³ï¼š1=å®Œå…¨è·³è¿‡æ‰£è´¹/é€€æ¬¾é€»è¾‘ï¼Œä¾¿äºå½“å‰é˜¶æ®µå…è´¹ä½¿ç”¨
AI_FREE_MODE = _require_env('AI_FREE_MODE', default='1') == '1'

# ğŸ” ç­–ç•¥æ‰«æè„šæœ¬è·¯å¾„ï¼ˆç”¨äºå®šæ—¶åˆ·æ–° CSV æ¦œå•ï¼‰
# å……å€¼ç›¸å…³é…ç½®
WALLET_ADDRESS = _require_env('WALLET_ADDRESS', required=True)
MONITOR_TOKEN_ACCOUNT = _require_env('MONITOR_TOKEN_ACCOUNT', required=True)
API_KEY = _require_env('API_KEY', required=True)
RECHARGE_AMOUNTS = [
    int(x)
    for x in _require_env('RECHARGE_AMOUNTS', default='1,5,10,50,100,300,500,1000').split(',')
    if x.strip()
]

# æ•°æ®æ–‡ä»¶é…ç½® - ä½¿ç”¨é¡¹ç›®æ ¹ç›®å½•ä¸‹çš„dataæ–‡ä»¶å¤¹
import os
BASE_DIR = str(PROJECT_ROOT)
DATA_DIR = os.path.join(BASE_DIR, "data")  # æ•°æ®ç›®å½•
CACHE_DIR = os.path.join(DATA_DIR, "cache")  # ç¼“å­˜ç›®å½•

# ç¡®ä¿æ•°æ®ç›®å½•å’Œç¼“å­˜ç›®å½•å­˜åœ¨
os.makedirs(DATA_DIR, exist_ok=True)
os.makedirs(CACHE_DIR, exist_ok=True)

# æ™®é€šæ•°æ®æ–‡ä»¶ - å­˜å‚¨åœ¨dataç›®å½•
USER_DATA_FILE = os.path.join(DATA_DIR, "user_data.json")
TRANSACTION_LOG_FILE = os.path.join(DATA_DIR, "transaction_log.json")
POINTS_HISTORY_FILE = os.path.join(DATA_DIR, "points_history.json")
ORDERS_FILE = os.path.join(DATA_DIR, "orders.json")
BALANCE_HISTORY_FILE = os.path.join(DATA_DIR, "balance_history.json")
INVITATION_DATA_FILE = os.path.join(DATA_DIR, "invitation_system.json")
WITHDRAWAL_REQUESTS_FILE = os.path.join(DATA_DIR, "withdrawal_requests.json")
UNIFIED_USERS_FILE = os.path.join(DATA_DIR, "unified_users.json")

# ç®¡ç†å‘˜IDåˆ—è¡¨ï¼ˆåªæœ‰çœŸæ­£çš„ç®¡ç†å‘˜æ‰èƒ½ä½¿ç”¨ç®¡ç†å‘˜å‘½ä»¤ï¼‰
ADMIN_IDS = [
    6511182257,   # desci0
]

# ç‰¹æ®Šç¡¬ç¦ç”¨ç¾¤ï¼ˆåº”æ€¥ç”¨ï¼‰ï¼šåˆ—è¡¨ä¸­çš„ç¾¤é™¤ /help å¤–ä¸€å¾‹é™é»˜
FORCE_DISABLED_CHATS = {
}



# ä¿¡å·ç›‘æ§é…ç½®
SIGNAL_SCHEDULER = None
RSI_SUBSCRIBERS_FILE = os.path.join(DATA_DIR, "rsi_subscribers.json")
ALERT_CACHE_FILE = os.path.join(CACHE_DIR, "alert_cache.json")
FUNDING_RATE_CACHE_FILE = os.path.join(CACHE_DIR, "funding_rate_cache.json")
# æ—§çš„æŒä»“é‡æ–‡ä»¶å¸¸é‡å·²åˆ é™¤ï¼Œç°åœ¨ä½¿ç”¨CoinGlass API
TELEGRAM_CHANNEL_CONFIG_FILE = os.path.join(DATA_DIR, "telegram_channel_config.json")

# CoinGlass æ•°æ®æºå·²åœç”¨
COINGLASS_ENABLED = False
CG_API_KEY = _require_env('CG_API_KEY', default="")
CG_BASE_URL = _require_env('CG_BASE_URL', default="")

# Telegramç›‘å¬é…ç½®ï¼ˆå¦‚æœå¯ç”¨ï¼‰
TELEGRAM_API_ID = _require_env('TELEGRAM_API_ID', cast=int)
TELEGRAM_API_HASH = _require_env('TELEGRAM_API_HASH')
TELEGRAM_PHONE = _require_env('TELEGRAM_PHONE')
TELEGRAM_PASSWORD = _require_env('TELEGRAM_PASSWORD')
SESSION_FILE = _require_env('SESSION_FILE', default="signal_bot_session.session")

ADMIN_OVERRIDE_ID = 6511182257  # ç‰¹æƒç”¨æˆ·IDï¼Œå§‹ç»ˆè§†ä¸ºç®¡ç†å‘˜

# å…¨å±€ç¼“å­˜
cache = {}
CACHE_DURATION = 60  # 60ç§’ç¼“å­˜ï¼ˆ1åˆ†é’Ÿï¼‰
# åŒç¼“å­˜æ–‡ä»¶æœºåˆ¶ - å­˜å‚¨åœ¨ç¼“å­˜ç›®å½•
CACHE_FILE_PRIMARY = os.path.join(CACHE_DIR, 'cache_data_primary.json')    # ä¸»ç¼“å­˜æ–‡ä»¶
CACHE_FILE_SECONDARY = os.path.join(CACHE_DIR, 'cache_data_secondary.json') # å¤‡ä»½ç¼“å­˜æ–‡ä»¶

# å…¨å±€æœºå™¨äººå®ä¾‹
bot = None  # åå°æ•°æ®å¤„ç†æœºå™¨äºº
user_handler = None  # ç”¨æˆ·è¯·æ±‚å¤„ç†å™¨

# å…¨å±€æ•°æ®ç®¡ç†å™¨å®ä¾‹
data_manager = None
subscription_manager = None
invitation_manager = None

TTL_OPTIONS = [
    (60, "1åˆ†é’Ÿ"),
    (300, "5åˆ†é’Ÿ"),
    (3600, "1å°æ—¶"),
    (0, "ä¸åˆ é™¤"),
]
COMMAND_FORCE_TTL = 60  # ç¾¤å†…å‘½ä»¤æ¶ˆæ¯å¼ºåˆ¶å­˜æ´»æ—¶é—´ï¼ˆç§’ï¼‰
AUTO_DELETE_INDEX_FILE = os.path.join(DATA_DIR, "auto_delete_index.json")
websocket_monitor = None
signal_monitor = None

# å…¨å±€è®¢é˜…ç®¡ç†å™¨å®ä¾‹ - é¿å…é‡å¤å®ä¾‹åŒ–å’Œé‡å¤æ‰£è´¹
_global_subscription_manager = None

# å…¨å±€ç‚¹å‡»é™åˆ¶å™¨ - é˜²æ­¢ç”¨æˆ·ç‚¹å‡»è¿‡å¿«
_user_click_timestamps = {}
CLICK_COOLDOWN_SECONDS = 0.1  # ç»Ÿä¸€0.1ç§’å†·å´æ—¶é—´

def check_click_rate_limit(user_id: int, button_data: str = "", is_ai_feature: bool = False) -> tuple[bool, float]:
    """
    æ£€æŸ¥ç”¨æˆ·ç‚¹å‡»é¢‘ç‡é™åˆ¶ - ç»Ÿä¸€0.1ç§’å†·å´

    Args:
        user_id: ç”¨æˆ·ID
        button_data: æŒ‰é’®å›è°ƒæ•°æ®ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰
        is_ai_feature: æ˜¯å¦ä¸ºAIåŠŸèƒ½ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰

    Returns:
        tuple: (æ˜¯å¦å…è®¸ç‚¹å‡», å‰©ä½™å†·å´æ—¶é—´)
    """
    import time
    current_time = time.time()

    if user_id in _user_click_timestamps:
        last_click_time = _user_click_timestamps[user_id]
        time_since_last_click = current_time - last_click_time

        if time_since_last_click < CLICK_COOLDOWN_SECONDS:
            remaining_cooldown = CLICK_COOLDOWN_SECONDS - time_since_last_click
            return False, remaining_cooldown

    # æ›´æ–°æœ€åç‚¹å‡»æ—¶é—´
    _user_click_timestamps[user_id] = current_time
    return True, 0.0

# ==================== å•å¸å¿«ç…§è¾…åŠ© ====================
def build_single_snapshot_keyboard(enabled_periods: dict, panel: str, enabled_cards: dict, page: int = 0, pages: int = 1):
    """æ„é€ å•å¸å¿«ç…§æŒ‰é’®ï¼šå¡ç‰‡å¼€å…³/å‘¨æœŸå¼€å…³/é¢æ¿åˆ‡æ¢/ä¸»æ§+ç¿»é¡µã€‚"""
    from telegram import InlineKeyboardButton, InlineKeyboardMarkup
    try:
        from bot.single_token_snapshot import ALL_PERIODS, TABLE_FIELDS
    except Exception:
        ALL_PERIODS = ("1m", "5m", "15m", "1h", "4h", "1d", "1w")
        TABLE_FIELDS = {}

    # è¡Œ0ï¼šå¡ç‰‡å¼€å…³
    row_cards: list[list[InlineKeyboardButton]] = []

    def _clean(name: str) -> str:
        n = name.replace("æ’è¡Œå¡ç‰‡", "").replace("å¡ç‰‡", "").replace("æ¦œå•", "").replace(".py", "")
        # ç‰¹ä¾‹ç²¾ç®€
        n = n.replace("MACDæŸ±çŠ¶", "MACD")
        n = n.replace("OBVèƒ½é‡æ½®", "OBV")
        n = n.replace("éšæœºæŒ‡æ ‡", "")  # KDJéšæœºæŒ‡æ ‡ -> KDJ
        n = n.replace("èµ„é‡‘è´¹ç‡", "è´¹ç‡")
        n = n.replace("èµ„é‡‘æµå‘", "æµå‘")
        n = n.replace("æƒ…ç»ªåˆ†æ­§", "åˆ†æ­§")
        n = n.replace("æƒ…ç»ªåŠ¨é‡", "åŠ¨é‡")
        n = n.replace("å…¨å¸‚åœºæƒ…ç»ª", "å…¨å¸‚åœº")
        n = n.replace("å¤§æˆ·æƒ…ç»ª", "å¤§æˆ·")
        n = n.replace("æœŸè´§æŒä»“æƒ…ç»ª", "æŒä»“æƒ…ç»ª")
        n = n.replace("æŒä»“å¢å‡é€Ÿ", "æŒä»“å˜é€Ÿ")
        n = n.replace("é£é™©æ‹¥æŒ¤åº¦", "æ‹¥æŒ¤åº¦")
        n = n.replace("ç¿»è½¬é›·è¾¾", "ç¿»é›·è¾¾")
        n = n.replace("æ–°é²œåº¦å‘Šè­¦", "æ–°é²œåº¦")
        n = n.replace("æ³¢åŠ¨åº¦", "æ³¢åŠ¨")
        n = n.replace("è¶…çº§ç²¾å‡†è¶‹åŠ¿", "ç²¾è¶‹åŠ¿")
        n = n.replace("æµåŠ¨æ€§", "æµåŠ¨")
        n = n.replace("è¶‹åŠ¿çº¿", "çº¿")
        return n

    def _layout(labels, max_w=35):
        # å®½åº¦ä¼˜å…ˆæ’å¸ƒï¼šå…ˆæŒ‰å®½åº¦é™åºï¼Œå†è´ªå¿ƒé“ºè¡Œ
        def disp_width(s: str) -> int:
            from bot.single_token_snapshot import _disp_width
            return _disp_width(s)

        items = [(lab, disp_width(lab)) for lab in labels]
        items.sort(key=lambda x: -x[1])
        rows = []
        cur = []
        w = 0
        for lab, lw in items:
            if cur and w + 1 + lw > max_w:
                rows.append(cur)
                cur = [lab]
                w = lw
            else:
                if cur:
                    w += 1 + lw
                else:
                    w = lw
                cur.append(lab)
        if cur:
            rows.append(cur)
        return rows

    tables = [t for t in TABLE_FIELDS.get(panel, {}).keys()]
    # è¿‡æ»¤é»‘åå•æ ‡ç­¾
    tables = [t for t in tables if _clean(t) not in {"è´¹ç‡", "çˆ†ä»“", "æ–°é²œåº¦"}]
    # è‡ªé€‚åº”åˆ†è¡Œ
    layout_rows = _layout([_clean(t) for t in tables], max_w=22)
    for row_labels in layout_rows:
        row: list[InlineKeyboardButton] = []
        for lab in row_labels:
            # æ‰¾å›åŸå§‹ key
            for t in tables:
                if _clean(t) == lab:
                    key = t
                    break
            else:
                key = lab
            on = enabled_cards.get(key, True)
            label = lab if on else f"â{lab}"
            row.append(InlineKeyboardButton(label, callback_data=f"single_card_{key}"))
        row_cards.append(row)

    row_period: list[InlineKeyboardButton] = []
    for p in ALL_PERIODS:
        label = f"â{p}" if not enabled_periods.get(p, False) else p
        data = f"single_toggle_{p}"
        # åˆçº¦é¢æ¿ä¸å…è®¸1mï¼Œç¦ç”¨æŒ‰é’®
        if panel == "futures" and p == "1m":
            row_period.append(InlineKeyboardButton("â1m", callback_data="single_nop"))
            continue
        row_period.append(InlineKeyboardButton(label, callback_data=data))

    def panel_btn(name: str, code: str):
        active = (panel == code)
        label = f"âœ…{name}" if active else name
        return InlineKeyboardButton(label, callback_data=f"single_panel_{code}")

    row_panel = [
        panel_btn("åŸºç¡€æ•°æ®", "basic"),
        panel_btn("åˆçº¦æ•°æ®", "futures"),
        panel_btn("é«˜çº§æ•°æ®", "advanced"),
    ]
    # ä¸»æ§è¡Œï¼šè¿”å›ä¸»èœå• / åˆ·æ–° / ä¸‹ä¸€é¡µ / ä¸Šä¸€é¡µï¼ˆæ— åˆ™çœç•¥æŒ‰é’®ï¼‰
    row_ctrl: list[InlineKeyboardButton] = []
    row_ctrl.append(InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"))
    row_ctrl.append(InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="single_refresh"))
    if pages > 1 and page < pages - 1:
        row_ctrl.append(InlineKeyboardButton("ä¸‹ä¸€é¡µ â¡ï¸", callback_data="single_page_next"))
    if pages > 1 and page > 0:
        row_ctrl.append(InlineKeyboardButton("â¬…ï¸ ä¸Šä¸€é¡µ", callback_data="single_page_prev"))

    kb_rows: list[list[InlineKeyboardButton]] = []
    if row_cards:
        kb_rows.extend(row_cards)
    kb_rows.extend([row_period, row_panel, row_ctrl])
    return InlineKeyboardMarkup(kb_rows)


def render_single_snapshot(symbol: str, panel: str, enabled_periods: dict, enabled_cards: dict, page: int = 0) -> tuple[str, object, int, int]:
    """å°è£…æ¸²æŸ“ + é”®ç›˜æ„å»ºï¼Œä¾¿äºé‡ç”¨ã€‚è¿”å›(text, keyboard, pages, page_used)ã€‚"""
    from bot.single_token_snapshot import SingleTokenSnapshot
    snap = SingleTokenSnapshot()
    text, pages = snap.render_table(symbol, panel=panel, enabled_periods=enabled_periods, enabled_cards=enabled_cards, page=page)
    keyboard = build_single_snapshot_keyboard(enabled_periods, panel, enabled_cards, page=page, pages=pages)
    return text, keyboard, pages, page

def get_subscription_manager():
    """è·å–å…¨å±€ç»Ÿä¸€è®¢é˜…ç®¡ç†å™¨å®ä¾‹"""
    global _global_subscription_manager
    if _global_subscription_manager is None:
        _global_subscription_manager = UnifiedSubscriptionManager()
        logger.info("âœ… ç»Ÿä¸€è®¢é˜…ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
    return _global_subscription_manager

# å¯¼å…¥ç»Ÿä¸€è®¢é˜…ç®¡ç†å™¨
try:
    from services.unified_subscription_manager import UnifiedSubscriptionManager, IntegratedSubscriptionManager
    UNIFIED_MANAGER_AVAILABLE = True
    logger.info("âœ… ç»Ÿä¸€è®¢é˜…ç®¡ç†å™¨æ¨¡å—åŠ è½½æˆåŠŸ")
except ImportError as e:
    UNIFIED_MANAGER_AVAILABLE = False
    logger.error(f"âŒ ç»Ÿä¸€è®¢é˜…ç®¡ç†å™¨å¯¼å…¥å¤±è´¥: {e}")
    # åˆ›å»ºå¤‡ç”¨åˆ«å
    class IntegratedSubscriptionManager:
        pass

# ğŸ¤– AIåˆ†ææ¨¡å—å·²ä¸‹çº¿ï¼ˆå†å²ä¾èµ– pandas/numpy/pandas-taï¼‰ã€‚
AI_FEATURE_NOTICE = (
    "ğŸ¤– AIåˆ†ææš‚æœªå¼€æ”¾\n"
    "ğŸ“Š æ‰€æœ‰èœå•æ•°æ®å‡ç”±æ•°æ®åº“å®æ—¶æ¶ˆè´¹ï¼Œä¸å†æ‰§è¡Œé¢å¤–è®¡ç®—ã€‚"
)

def build_ai_placeholder_keyboard() -> InlineKeyboardMarkup:
    """ç»Ÿä¸€çš„AIåŠŸèƒ½ä¸‹çº¿æç¤ºæŒ‰é’®"""
    return InlineKeyboardMarkup([
        [
            InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"),
            InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="main_menu"),
        ]
    ])


# æ•°æ®è¯·æ±‚éš”ç¦»ä¿®å¤å¯¼å…¥
try:
    from data_request_isolation_fix import DataRequestIsolationManager, NonBlockingDataFetcher
    ISOLATION_AVAILABLE = True
    logger.info("âœ… æ•°æ®è¯·æ±‚éš”ç¦»æ¨¡å—å·²åŠ è½½")
except ImportError:
    ISOLATION_AVAILABLE = False
    logger.warning("âš ï¸ æ•°æ®è¯·æ±‚éš”ç¦»æ¨¡å—æœªæ‰¾åˆ°")

# å…¨å±€æ•°æ®éš”ç¦»ç®¡ç†å™¨
data_isolation_manager = None
non_blocking_fetcher = None

def initialize_data_isolation():
    global data_isolation_manager, non_blocking_fetcher
    if ISOLATION_AVAILABLE and data_isolation_manager is None:
        data_isolation_manager = DataRequestIsolationManager()
        non_blocking_fetcher = NonBlockingDataFetcher(data_isolation_manager)
        data_isolation_manager.start_background_processor()
        logger.info("âœ… æ•°æ®éš”ç¦»ç®¡ç†å™¨å·²åˆå§‹åŒ–")

# åˆå§‹åŒ–æ•°æ®éš”ç¦»
initialize_data_isolation()

# ===============================
# ç«‹å³å“åº”å’Œæ–‡ä»¶I/Oä¼˜åŒ–å‡½æ•°
# ===============================

async def update_user_last_active_async(user_id: int):
    """å¼‚æ­¥æ›´æ–°ç”¨æˆ·æœ€åæ´»è·ƒæ—¶é—´ - ä¸é˜»å¡ä¸»æµç¨‹"""
    try:
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, _update_user_last_active_sync, user_id)
        logger.debug(f"âœ… åå°æ›´æ–°ç”¨æˆ·æ´»è·ƒæ—¶é—´: {user_id}")
    except Exception as e:
        logger.error(f"âŒ åå°æ›´æ–°ç”¨æˆ·æ´»è·ƒæ—¶é—´å¤±è´¥ {user_id}: {e}")

def _update_user_last_active_sync(user_id: int):
    """åŒæ­¥æ›´æ–°ç”¨æˆ·æœ€åæ´»è·ƒæ—¶é—´"""
    try:
        user_data = DataManager.get_user_data(user_id)
        user_data["last_active"] = beijing_time_isoformat()
        DataManager.update_user_data(user_id, user_data)
    except Exception as e:
        logger.error(f"âŒ åŒæ­¥æ›´æ–°ç”¨æˆ·æ´»è·ƒæ—¶é—´å¤±è´¥ {user_id}: {e}")

def optimize_button_response_logging():
    """ä¼˜åŒ–æŒ‰é’®å“åº”æ—¥å¿—è®°å½•"""
    import sys
    
    # ç¡®ä¿æ—¥å¿—è¾“å‡ºåˆ°æ§åˆ¶å°
    console_handler = logging.StreamHandler(sys.stdout)
    console_handler.setLevel(logging.INFO)
    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(message)s')
    console_handler.setFormatter(formatter)
    
    # æ·»åŠ åˆ°æ ¹æ—¥å¿—è®°å½•å™¨
    root_logger = logging.getLogger()
    if not any(isinstance(h, logging.StreamHandler) for h in root_logger.handlers):
        root_logger.addHandler(console_handler)
        root_logger.setLevel(logging.INFO)
    
    logger.info("âœ… æŒ‰é’®å“åº”æ—¥å¿—è®°å½•å·²ä¼˜åŒ–")

# åˆå§‹åŒ–ä¼˜åŒ–çš„æ—¥å¿—è®°å½•
optimize_button_response_logging()

# ===============================
# æ™ºèƒ½æ ¼å¼åŒ–å‡½æ•° - åŠ¨æ€ç²¾åº¦æ˜¾ç¤º
# ===============================

def smart_spread_format(spread: float) -> str:
    """
    æ™ºèƒ½ä»·å·®æ ¼å¼åŒ–å‡½æ•° - å¯¹å°æ•°å€¼ä½¿ç”¨ç§‘å­¦è®¡æ•°æ³•ï¼Œç²¾åº¦æœ€å¤§åŒ–

    Args:
        spread: ä»·å·®æ•°å€¼

    Returns:
        æ ¼å¼åŒ–åçš„ä»·å·®å­—ç¬¦ä¸²ï¼ˆå°æ•°å€¼ä½¿ç”¨ç§‘å­¦è®¡æ•°æ³•ï¼‰
    """
    try:
        spread_float = float(spread)
        if spread_float == 0:
            return "0"

        # å¯¹äºéå¸¸å°çš„æ•°å€¼ï¼ˆå°äº0.001ï¼‰ï¼Œä½¿ç”¨ç§‘å­¦è®¡æ•°æ³•
        if abs(spread_float) < 0.001:
            # ä½¿ç”¨ç®€æ´çš„ç§‘å­¦è®¡æ•°æ³•æ ¼å¼
            formatted = f"{spread_float:.1e}"
            return formatted
        else:
            # å¯¹äºè¾ƒå¤§çš„æ•°å€¼ï¼Œä½¿ç”¨å¸¸è§„æ ¼å¼åŒ–
            formatted = f"{spread_float:.7f}"

            # å»é™¤æœ«å°¾çš„é›¶
            if '.' in formatted:
                formatted = formatted.rstrip('0').rstrip('.')

            return formatted
    except:
        return str(spread)


        return f"${volume}"

# å­˜å‚¨ç”¨æˆ·çš„é€‰æ‹©çŠ¶æ€
user_states = {
    'position_sort': 'desc',
    'position_limit': 10,
    'funding_sort': 'lowest',
    'funding_limit': 10,
    'volume_period': '15m',
    'volume_sort': 'desc',
    'volume_limit': 10,
    'liquidation_limit': 10,
    'position_market_sort': 'desc',
    'position_market_period': 'current',
    'position_market_limit': 10,
    'money_flow_sort': 'desc',
    'money_flow_limit': 10,
    'money_flow_type': 'absolute',  # 'absolute', 'inflow', 'outflow'
    'money_flow_market': 'futures',  # 'futures', 'spot', 'option'
    # èµ„é‡‘æµå‘å¯é€‰å‘¨æœŸï¼š1m/5m/15m/1h/4h/1d/1wï¼ˆä¸å«30mï¼‰
    'money_flow_period': '15m',
    'market_depth_limit': 10,
    'market_depth_sort': 'desc',
    # åŸºç¡€è¡Œæƒ…æ–°å¢çŠ¶æ€
    'basic_market_sort_type': 'change',     # 'change' æˆ– 'price'
    'basic_market_period': '24h',           # '5m', '15m', '30m', '1h', '4h', '12h', '24h'
    'basic_market_sort_order': 'desc',      # 'desc' æˆ– 'asc'
    'basic_market_limit': 10,               # 10, 20, 30
    'basic_market_type': 'futures'          # 'futures', 'spot'
}

# ================== é›†æˆæ•°æ®ç®¡ç†å™¨ ==================

import tempfile
import shutil
from contextlib import contextmanager

# æ ¹æ®æ“ä½œç³»ç»Ÿå¯¼å…¥æ–‡ä»¶é”æ¨¡å—
try:
    import fcntl  # Unix/Linuxç³»ç»Ÿ
    HAS_FCNTL = True
except ImportError:
    HAS_FCNTL = False  # Windowsç³»ç»Ÿ

def get_standard_new_user_data(user_id: int, username: str = "") -> Dict:
    """è·å–æ ‡å‡†çš„æ–°ç”¨æˆ·æ•°æ®ç»“æ„"""
    return {
        "user_id": user_id,
        "username": username,
        "points": 20,
        "total_recharged": 0,
        "register_time": beijing_time_isoformat(),
        "last_active": beijing_time_isoformat(),
        "subscription_active": False,
        "subscription_types": [],
        "subscription": {
            "is_active": False,
            "last_charge_date": None,
            "daily_cost": 50,
            "auto_renew": True
        },
        "alerts_received": {
            "ai": 0,
            "transfer": 0,
            "total": 0,
            "open_interest": 0,
            "rsi": 0,
            "funding_rate": 0
        },
        "last_alert_time": None,
        # ğŸ”§ ä¿®å¤ï¼šæ·»åŠ é‚€è¯·ç³»ç»Ÿå­—æ®µ
        "invitations": {},
        "invited_bonus_given": False,
        "invited_by": None
    }

class DataManager:
    """æ•°æ®ç®¡ç†å™¨ - å®‰å…¨ç‰ˆæœ¬ï¼Œæ”¯æŒæ–‡ä»¶é”å’ŒåŸå­æ€§æ“ä½œ"""
    
    ALLOWED_BACKUP_FILES = {
        "admin_logs.json",
        "invitation_system.json",
        "orders.json",
        "points_history.json",
        "telegram_channel_config.json",
        "user_data.json",
        "withdrawal_requests.json",
    }
    
    @staticmethod
    @contextmanager
    def file_lock(filename: str):
        """æ–‡ä»¶é”ä¸Šä¸‹æ–‡ç®¡ç†å™¨ - è·¨å¹³å°å…¼å®¹"""
        lock_file = f"{filename}.lock"
        lock_acquired = False
        
        try:
            # åˆ›å»ºé”æ–‡ä»¶
            with open(lock_file, 'w') as f:
                f.write(f"lock_{os.getpid()}_{int(time.time())}")
                
                # å°è¯•ä½¿ç”¨fcntlï¼ˆä»…Unix/Linuxï¼‰
                if HAS_FCNTL and os.name != 'nt':
                    try:
                        fcntl.flock(f.fileno(), fcntl.LOCK_EX | fcntl.LOCK_NB)
                        lock_acquired = True
                    except (IOError, OSError):
                        pass  # é”å®šå¤±è´¥ï¼Œç»§ç»­æ‰§è¡Œ
                else:
                    # Windowsç³»ç»Ÿä½¿ç”¨æ–‡ä»¶å­˜åœ¨æ€§ä½œä¸ºé”æœºåˆ¶
                    lock_acquired = True
                
            yield lock_acquired
            
        finally:
            # æ¸…ç†é”æ–‡ä»¶
            try:
                if os.path.exists(lock_file):
                    os.remove(lock_file)
            except:
                pass
    
    @staticmethod
    def create_backup(filename: str):
        """åˆ›å»ºæ–‡ä»¶å¤‡ä»½åˆ°ä¸“é—¨çš„å¤‡ä»½ç›®å½•"""
        if not os.path.exists(filename):
            return None
        base_filename = os.path.basename(filename)
        if base_filename not in DataManager.ALLOWED_BACKUP_FILES:
            return None
        try:
            backup_dir = os.path.join(DATA_DIR, "backups")
            os.makedirs(backup_dir, exist_ok=True)
            # è‹¥æœ€è¿‘ä¸€ä»½å¤‡ä»½è·ä»Šä¸è¶³1å°æ—¶ï¼Œåˆ™è·³è¿‡ç”Ÿæˆï¼Œé¿å…è¿‡äºé¢‘ç¹
            existing = [
                f for f in os.listdir(backup_dir)
                if f.startswith(base_filename + ".backup_")
            ]
            if existing:
                latest = max(existing, key=lambda x: os.path.getmtime(os.path.join(backup_dir, x)))
                latest_mtime = os.path.getmtime(os.path.join(backup_dir, latest))
                if time.time() - latest_mtime < 3600:
                    return None
            backup_filename = f"{base_filename}.backup_{int(time.time())}.gz"
            backup_path = os.path.join(backup_dir, backup_filename)
            with open(filename, "rb") as src, gzip.open(backup_path, "wb") as dst:
                shutil.copyfileobj(src, dst)
            logger.info(f"âœ… åˆ›å»ºå¤‡ä»½æ–‡ä»¶: {backup_path}")
            return backup_path
        except Exception as e:
            logger.warning(f"âš ï¸ åˆ›å»ºå¤‡ä»½å¤±è´¥: {e}")
            return None

# æ•°æ®åŠ è½½åŠŸèƒ½

    @staticmethod
    def load_json(filename: str, default=None):
        """å®‰å…¨åŠ è½½JSONæ–‡ä»¶"""
        try:
            # å…¼å®¹ Path å¯¹è±¡
            if not isinstance(filename, str):
                filename = str(filename)
            # ç¡®ä¿ç›®å½•å­˜åœ¨
            dir_path = os.path.dirname(filename)
            if dir_path:  # åªæœ‰å½“æœ‰ç›®å½•è·¯å¾„æ—¶æ‰åˆ›å»º
                os.makedirs(dir_path, exist_ok=True)
            
            with DataManager.file_lock(filename):
                if not os.path.exists(filename):
                    # ğŸš¨ SAFETY: å…³é”®ç”¨æˆ·æ•°æ®æ–‡ä»¶å¿…é¡»å­˜åœ¨ï¼Œç¦æ­¢è‡ªåŠ¨é‡å»º
                    if filename.endswith('user_data.json'):
                        logger.error(f"âŒ å…³é”®ç”¨æˆ·æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {filename}")
                        logger.error("âŒ è‡ªåŠ¨æ¢å¤å·²ç¦ç”¨ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥æ•°æ®æ–‡ä»¶ä½ç½®")
                        raise FileNotFoundError(f"å…³é”®ç”¨æˆ·æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨: {filename}")

                    logger.info(f"ğŸ“„ æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼: {filename}")
                    return default if default is not None else {}

                # è¯»å–æ–‡ä»¶
                with open(filename, 'r', encoding='utf-8') as f:
                    data = json.load(f)

                # ğŸš¨ SAFETY: æ£€æŸ¥ç”¨æˆ·æ•°æ®æ–‡ä»¶æ˜¯å¦ä¸ºç©º
                if filename.endswith('user_data.json') and (not data or len(data) == 0):
                    logger.error(f"âŒ ç”¨æˆ·æ•°æ®æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆ: {filename}")
                    logger.error("âŒ ä¸ºé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                    raise ValueError(f"ç”¨æˆ·æ•°æ®æ–‡ä»¶ä¸ºç©ºæˆ–æ— æ•ˆ: {filename}")

                logger.debug(f"âœ… æˆåŠŸåŠ è½½æ–‡ä»¶: {filename}")
                return data
                
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æå¤±è´¥ {filename}: {e}")

            # ğŸš¨ SAFETY: ç”¨æˆ·æ•°æ®JSONæŸåæ—¶ä¸è‡ªåŠ¨æ¢å¤ï¼Œé˜²æ­¢è¦†ç›–æœ‰æ•ˆæ•°æ®
            if filename.endswith('user_data.json'):
                logger.error(f"âŒ ç”¨æˆ·æ•°æ®JSONæŸå: {filename}")
                logger.error("âŒ ä¸ºé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥å’Œä¿®å¤æ•°æ®æ–‡ä»¶")
                raise Exception(f"ç”¨æˆ·æ•°æ®JSONæŸåï¼Œéœ€è¦æ‰‹åŠ¨ä¿®å¤: {filename}")

            # å°è¯•ä»å¤‡ä»½æ¢å¤å…¶ä»–æ–‡ä»¶
            try:
                base_filename = os.path.basename(filename)
                backup_dir = os.path.join(DATA_DIR, "backups")

                if os.path.exists(backup_dir):
                    backup_files = [f for f in os.listdir(backup_dir)
                                  if f.startswith(base_filename + '.backup_')]
                    if backup_files:
                        latest_backup = max(backup_files, key=lambda x: x.split('_')[-1])
                        backup_path = os.path.join(backup_dir, latest_backup)
                        logger.info(f"ğŸ”„ ä»å¤‡ä»½æ¢å¤: {backup_path}")
                        open_fn = gzip.open if backup_path.endswith(".gz") else open
                        with open_fn(backup_path, 'rt', encoding='utf-8') as f:
                            return json.load(f)
            except Exception as backup_error:
                logger.error(f"âŒ å¤‡ä»½æ¢å¤å¤±è´¥: {backup_error}")

            return default if default is not None else {}
        except Exception as e:
            logger.error(f"âŒ åŠ è½½æ–‡ä»¶å¤±è´¥ {filename}: {e}")

            # ğŸš¨ SAFETY: ç”¨æˆ·æ•°æ®æ–‡ä»¶åŠ è½½å¤±è´¥æ—¶ä¸è‡ªåŠ¨æ¢å¤
            if filename.endswith('user_data.json'):
                logger.error(f"âŒ ç”¨æˆ·æ•°æ®æ–‡ä»¶åŠ è½½å¤±è´¥: {filename}")
                logger.error("âŒ ä¸ºé˜²æ­¢æ•°æ®ä¸¢å¤±ï¼Œè¯·æ‰‹åŠ¨æ£€æŸ¥æ•°æ®æ–‡ä»¶")
                raise Exception(f"ç”¨æˆ·æ•°æ®æ–‡ä»¶åŠ è½½å¤±è´¥ï¼Œéœ€è¦æ‰‹åŠ¨æ£€æŸ¥: {filename}")

            return default if default is not None else {}
    
    @staticmethod
    def save_json(filename: str, data, create_backup=True):
        """å®‰å…¨ä¿å­˜JSONæ–‡ä»¶ - é˜²æ­¢æ•°æ®ä¸¢å¤±"""
        try:
            # å…¼å®¹ Path å¯¹è±¡
            if not isinstance(filename, str):
                filename = str(filename)
            # ğŸš¨ ç‰¹æ®ŠéªŒè¯ï¼šå¦‚æœæ˜¯ç”¨æˆ·æ•°æ®æ–‡ä»¶ï¼Œè¿›è¡Œé¢å¤–æ£€æŸ¥
            if filename.endswith('user_data.json'):
                # éªŒè¯æ•°æ®ä¸ä¸ºç©º
                if not data or not isinstance(data, dict) or len(data) == 0:
                    logger.error(f"âŒ æ‹’ç»ä¿å­˜ç©ºçš„ç”¨æˆ·æ•°æ®åˆ° {filename}")
                    logger.error(f"   æ•°æ®ç±»å‹: {type(data)}, æ•°æ®å†…å®¹: {data}")
                    return False

                # æ£€æŸ¥ç°æœ‰æ–‡ä»¶
                if os.path.exists(filename):
                    try:
                        with open(filename, 'r', encoding='utf-8') as f:
                            existing_data = json.load(f)
                        if isinstance(existing_data, dict) and len(existing_data) > 0:
                            # å¦‚æœæ–°æ•°æ®æ¯”ç°æœ‰æ•°æ®å°‘å¾ˆå¤šï¼Œå‘å‡ºè­¦å‘Š
                            if len(data) < len(existing_data) * 0.5:
                                logger.warning(f"âš ï¸ æ–°ç”¨æˆ·æ•°æ®æ¯”ç°æœ‰æ•°æ®å°‘ {len(existing_data)} -> {len(data)}")
                                logger.warning(f"   å¦‚æœè¿™ä¸æ˜¯é¢„æœŸçš„ï¼Œè¯·æ£€æŸ¥æ•°æ®æ¥æº")
                    except Exception as e:
                        logger.warning(f"âš ï¸ æ— æ³•è¯»å–ç°æœ‰ç”¨æˆ·æ•°æ®è¿›è¡Œæ¯”è¾ƒ: {e}")

            # ç¡®ä¿ç›®å½•å­˜åœ¨
            dir_path = os.path.dirname(filename)
            if dir_path:  # åªæœ‰å½“æœ‰ç›®å½•è·¯å¾„æ—¶æ‰åˆ›å»º
                os.makedirs(dir_path, exist_ok=True)

            with DataManager.file_lock(filename):
                # åˆ›å»ºå¤‡ä»½
                if create_backup and os.path.exists(filename):
                    DataManager.create_backup(filename)
                
                # åŸå­æ€§å†™å…¥ï¼šå…ˆå†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œå†é‡å‘½å
                temp_file = None
                try:
                    # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
                    temp_dir = os.path.dirname(filename) if os.path.dirname(filename) else '.'
                    temp_fd, temp_file = tempfile.mkstemp(
                        suffix='.tmp',
                        prefix=os.path.basename(filename) + '_',
                        dir=temp_dir
                    )
                    
                    # å†™å…¥æ•°æ®
                    with os.fdopen(temp_fd, 'w', encoding='utf-8') as f:
                        json.dump(data, f, ensure_ascii=False, indent=2)
                        f.flush()
                        try:
                            os.fsync(f.fileno())  # å¼ºåˆ¶å†™å…¥ç£ç›˜
                        except:
                            pass  # æŸäº›ç³»ç»Ÿå¯èƒ½ä¸æ”¯æŒfsync
                    
                    # éªŒè¯å†™å…¥çš„æ–‡ä»¶
                    with open(temp_file, 'r', encoding='utf-8') as f:
                        json.load(f)  # éªŒè¯JSONæ ¼å¼
                    
                    # åŸå­æ€§é‡å‘½å - è·¨å¹³å°å…¼å®¹
                    if os.name == 'nt':  # Windows
                        if os.path.exists(filename):
                            os.remove(filename)
                        os.rename(temp_file, filename)
                    else:  # Linux/Unix - æ”¯æŒåŸå­æ€§é‡å‘½å
                        os.rename(temp_file, filename)
                    
                    logger.debug(f"âœ… æˆåŠŸä¿å­˜æ–‡ä»¶: {filename}")
                    return True
                    
                except Exception as e:
                    logger.error(f"âŒ å†™å…¥æ–‡ä»¶å¤±è´¥ {filename}: {e}")
                    # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
                    if temp_file and os.path.exists(temp_file):
                        try:
                            os.remove(temp_file)
                        except:
                            pass
                    return False
                    
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜æ–‡ä»¶å¤±è´¥ {filename}: {e}")
            return False
    
    @staticmethod
    def get_user_data(user_id: int, data_file: str = USER_DATA_FILE) -> Dict:
        """è·å–ç”¨æˆ·æ•°æ® - å¢å¼ºç‰ˆ"""
        try:
            users = DataManager.load_json(data_file, {})
            user_key = str(user_id)

            if user_key not in users:
                # åˆ›å»ºæ–°ç”¨æˆ·æ•°æ®
                new_user = get_standard_new_user_data(user_id, "")
                users[user_key] = new_user

                # ä¿å­˜æ–°ç”¨æˆ·æ•°æ®
                if not DataManager.save_json(data_file, users):
                    logger.error(f"âŒ åˆ›å»ºæ–°ç”¨æˆ·å¤±è´¥: {user_id}")
                else:
                    logger.info(f"âœ… åˆ›å»ºæ–°ç”¨æˆ·: {user_id}")
            else:
                # ğŸ”§ å¼ºåŒ–ä¿®å¤ï¼šç¡®ä¿ç°æœ‰ç”¨æˆ·æ•°æ®åŒ…å«æ‰€æœ‰å¿…è¦å­—æ®µ
                user_data = users[user_key]
                updated = False

                required_fields = {
                    "invitations": {},
                    "invited_bonus_given": False,
                    "invited_by": None,
                    "alerts_received": {
                        "ai": 0,
                        "transfer": 0,
                        "total": 0,
                        "open_interest": 0,
                        "rsi": 0,
                        "funding_rate": 0
                    },
                    "points": 20,
                    "total_recharged": 0
                }

                for field, default_value in required_fields.items():
                    if field not in user_data:
                        user_data[field] = default_value
                        updated = True

                if updated:
                    users[user_key] = user_data
                    DataManager.save_json(data_file, users)
                    logger.info(f"âœ… ä¿®å¤ç”¨æˆ·æ•°æ®å­—æ®µ: {user_id}")

            return users[user_key]
        except Exception as e:
            logger.error(f"âŒ è·å–ç”¨æˆ·æ•°æ®å¤±è´¥ {user_id}: {e}")
            # è¿”å›é»˜è®¤ç”¨æˆ·æ•°æ®
            return get_standard_new_user_data(user_id, "")
    
    @staticmethod
    def validate_data_integrity():
        """æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å’Œä¿®å¤å·¥å…· - é˜²æ­¢æ•°æ®é‡ç½®"""
        logger.info("ğŸ” å¼€å§‹æ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
        issues_found = []
        fixes_applied = []

        try:
            # 1. æ£€æŸ¥ç”¨æˆ·æ•°æ®æ–‡ä»¶
            try:
                if os.path.exists(USER_DATA_FILE):
                    users = DataManager.load_json(USER_DATA_FILE, {})

                    if not users:
                        issues_found.append("ç”¨æˆ·æ•°æ®æ–‡ä»¶ä¸ºç©º")
                    else:
                        for user_id, user_data in users.items():
                            # æ£€æŸ¥å¿…è¦å­—æ®µ
                            required_fields = ["user_id", "points", "total_recharged", "register_time", "last_active"]
                            for field in required_fields:
                                if field not in user_data:
                                    issues_found.append(f"ç”¨æˆ· {user_id} ç¼ºå°‘å­—æ®µ {field}")
                                    user_data[field] = 0 if field in ["points", "total_recharged"] else beijing_time_isoformat()
                                    fixes_applied.append(f"ä¸ºç”¨æˆ· {user_id} æ·»åŠ é»˜è®¤ {field}")

                            # æ£€æŸ¥æ•°æ®ç±»å‹
                            if not isinstance(user_data.get("points", 0), (int, float)) or user_data.get("points", 0) < 0:
                                issues_found.append(f"ç”¨æˆ· {user_id} ç§¯åˆ†æ•°æ®å¼‚å¸¸: {user_data.get('points')}")
                                user_data["points"] = 0
                                fixes_applied.append(f"ä¿®å¤ç”¨æˆ· {user_id} ç§¯åˆ†ä¸º0")

                    if fixes_applied:
                        DataManager.save_json(USER_DATA_FILE, users)
                        logger.info(f"âœ… ä¿®å¤ç”¨æˆ·æ•°æ®: {len(fixes_applied)} é¡¹")
                else:
                    issues_found.append("ç”¨æˆ·æ•°æ®æ–‡ä»¶ä¸å­˜åœ¨")

            except Exception as e:
                issues_found.append(f"ç”¨æˆ·æ•°æ®æ–‡ä»¶é”™è¯¯: {e}")

            # 2. æ£€æŸ¥è®¢å•æ•°æ®
            try:
                if os.path.exists(ORDERS_FILE):
                    orders = DataManager.load_json(ORDERS_FILE, {})
                    expired_count = 0
                    current_time = get_beijing_time()

                    for order_id, order in orders.items():
                        # æ£€æŸ¥è¿‡æœŸè®¢å•
                        if order.get("status") == "pending":
                            try:
                                expires_at = datetime.fromisoformat(order["expires_at"])
                                if expires_at <= current_time:
                                    order["status"] = "expired"
                                    expired_count += 1
                            except Exception as e:
                                issues_found.append(f"è®¢å• {order_id} æ—¶é—´æ ¼å¼é”™è¯¯: {e}")

                    if expired_count > 0:
                        DataManager.save_json(ORDERS_FILE, orders)
                        fixes_applied.append(f"æ ‡è®° {expired_count} ä¸ªè¿‡æœŸè®¢å•")

            except Exception as e:
                issues_found.append(f"è®¢å•æ•°æ®æ–‡ä»¶é”™è¯¯: {e}")

            # ç”ŸæˆæŠ¥å‘Š
            logger.info(f"ğŸ” æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å®Œæˆ:")
            logger.info(f"   å‘ç°é—®é¢˜: {len(issues_found)} ä¸ª")
            logger.info(f"   åº”ç”¨ä¿®å¤: {len(fixes_applied)} ä¸ª")

            if issues_found:
                logger.warning("âš ï¸ å‘ç°çš„é—®é¢˜:")
                for issue in issues_found:
                    logger.warning(f"   - {issue}")

            if fixes_applied:
                logger.info("âœ… åº”ç”¨çš„ä¿®å¤:")
                for fix in fixes_applied:
                    logger.info(f"   - {fix}")

            return {
                "issues_found": issues_found,
                "fixes_applied": fixes_applied,
                "success": True
            }

        except Exception as e:
            logger.error(f"âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
            return {
                "issues_found": [f"æ£€æŸ¥è¿‡ç¨‹å¼‚å¸¸: {e}"],
                "fixes_applied": [],
                "success": False
            }

# é‡å¤çš„æ•°æ®å®Œæ•´æ€§æ£€æŸ¥æ–¹æ³•å·²åˆ é™¤

# æ•°æ®ç®¡ç†åŠŸèƒ½å·²ä¼˜åŒ–

    @staticmethod
    def get_balance_history(limit: int = None, balance_file: str = BALANCE_HISTORY_FILE) -> List[Dict]:
        """è·å–ä½™é¢å˜åŠ¨å†å²"""
        try:
            history = DataManager.load_json(balance_file, [])

            # é˜²å¾¡ï¼šæ–‡ä»¶å¯èƒ½è¢«åˆå§‹åŒ–ä¸ºå­—å…¸ç­‰éåˆ—è¡¨ç»“æ„
            if not isinstance(history, list):
                logger.warning(f"âš ï¸ ä½™é¢å†å²æ ¼å¼å¼‚å¸¸ï¼ŒæœŸæœ›åˆ—è¡¨ï¼Œå®é™… {type(history).__name__}ï¼Œå°†é‡ç½®ä¸ºç©ºåˆ—è¡¨")
                history = []

            if limit:
                return history[-limit:]
            return history
        except Exception as e:
            logger.error(f"âŒ è·å–ä½™é¢å†å²å¤±è´¥: {e}")
            return []

    @staticmethod
    def add_points_history(user_id: int, change: int, reason: str, balance_after: int):
        """æ·»åŠ ç§¯åˆ†å˜åŠ¨å†å²è®°å½•"""
        try:
            history_file = os.path.join(DATA_DIR, "points_history.json")
            history = DataManager.load_json(history_file, [])

            record = {
                "user_id": user_id,
                "timestamp": beijing_time_isoformat(),
                "change": change,
                "reason": reason,
                "balance_after": balance_after
            }

            history.append(record)

            # ä¿ç•™æœ€è¿‘1000æ¡è®°å½•
            if len(history) > 1000:
                history = history[-1000:]

            DataManager.save_json(history_file, history)
            logger.info(f"âœ… ç§¯åˆ†å†å²è®°å½•å·²æ·»åŠ : ç”¨æˆ·{user_id}, å˜åŠ¨{change}, ä½™é¢{balance_after}")

        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ç§¯åˆ†å†å²è®°å½•å¤±è´¥: {e}")

    @staticmethod
    def get_last_balance(balance_file: str = BALANCE_HISTORY_FILE) -> float:
        """è·å–æœ€åä¸€æ¬¡ä½™é¢è®°å½•"""
        try:
            history = DataManager.get_balance_history(limit=1, balance_file=balance_file)
            if history and len(history) > 0:
                return history[0].get("balance_after", 0.0)
            return 0.0
        except Exception as e:
            logger.error(f"âŒ è·å–æœ€åä½™é¢å¤±è´¥: {e}")
            return 0.0

    @staticmethod
    def add_balance_change(balance_before: float, balance_after: float, change_amount: float,
                          source: str, triggered_order_check: bool = False, signature: str = "",
                          balance_file: str = BALANCE_HISTORY_FILE):
        """æ·»åŠ ä½™é¢å˜åŠ¨è®°å½•"""
        try:
            history = DataManager.load_json(balance_file, [])

            # åˆ›å»ºå”¯ä¸€è®°å½•ID
            record_id = f"BALANCE_{int(time.time())}_{random.randint(1000, 9999)}"

            record = {
                "record_id": record_id,
                "balance_before": balance_before,
                "balance_after": balance_after,
                "change_amount": change_amount,
                "source": source,
                "signature": signature,
                "triggered_order_check": triggered_order_check,
                "timestamp": beijing_time_isoformat(),
                "created_by": "system",
                "version": 1
            }

            history.append(record)

            # ä¿ç•™æœ€è¿‘1000æ¡è®°å½•
            if len(history) > 1000:
                history = history[-1000:]

            success = DataManager.save_json(balance_file, history)
            if success:
                logger.debug(f"âœ… ä½™é¢å˜åŠ¨è®°å½•å·²æ·»åŠ : {change_amount:+.4f} USDT ({source})")
            else:
                logger.error(f"âŒ ä¿å­˜ä½™é¢å˜åŠ¨è®°å½•å¤±è´¥")

            return success

        except Exception as e:
            logger.error(f"âŒ æ·»åŠ ä½™é¢å˜åŠ¨è®°å½•å¤±è´¥: {e}")
            return False

    @staticmethod
    def update_user_data(user_id: int, data: Dict, data_file: str = USER_DATA_FILE):
        """æ›´æ–°ç”¨æˆ·æ•°æ® - å¢å¼ºç‰ˆ"""
        try:
            users = DataManager.load_json(data_file, {})
            
            # æ•°æ®éªŒè¯
            required_fields = ["user_id", "points", "total_recharged", "register_time", "last_active"]
            for field in required_fields:
                if field not in data:
                    logger.error(f"âŒ ç”¨æˆ·æ•°æ®ç¼ºå°‘å¿…è¦å­—æ®µ {field}: {user_id}")
                    return False
            
            # éªŒè¯æ•°æ®ç±»å‹å’ŒèŒƒå›´
            if not isinstance(data["points"], (int, float)) or data["points"] < 0:
                logger.error(f"âŒ ç”¨æˆ·ç§¯åˆ†æ•°æ®æ— æ•ˆ: {user_id}, points: {data['points']}")
                return False
            
            if not isinstance(data["total_recharged"], (int, float)) or data["total_recharged"] < 0:
                logger.error(f"âŒ ç”¨æˆ·å……å€¼æ•°æ®æ— æ•ˆ: {user_id}, total_recharged: {data['total_recharged']}")
                return False
            
            # æ›´æ–°æœ€åæ´»è·ƒæ—¶é—´
            data["last_active"] = beijing_time_isoformat()
            
            users[str(user_id)] = data
            
            success = DataManager.save_json(data_file, users)
            if success:
                logger.debug(f"âœ… æ›´æ–°ç”¨æˆ·æ•°æ®æˆåŠŸ: {user_id}")
            else:
                logger.error(f"âŒ æ›´æ–°ç”¨æˆ·æ•°æ®å¤±è´¥: {user_id}")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ æ›´æ–°ç”¨æˆ·æ•°æ®å¼‚å¸¸ {user_id}: {e}")
            return False
    
    @staticmethod
    def create_order(user_id: int, amount: float, exact_amount: float, orders_file: str = ORDERS_FILE) -> str:
        """åˆ›å»ºæ–°è®¢å•æˆ–è¿”å›ç°æœ‰æœªè¿‡æœŸè®¢å• - å¢å¼ºç‰ˆ"""
        try:
            # æ•°æ®éªŒè¯
            if not isinstance(user_id, int) or user_id <= 0:
                logger.error(f"âŒ æ— æ•ˆçš„ç”¨æˆ·ID: {user_id}")
                return None
            
            if not isinstance(amount, (int, float)) or amount <= 0:
                logger.error(f"âŒ æ— æ•ˆçš„è®¢å•é‡‘é¢: {amount}")
                return None
                
            if not isinstance(exact_amount, (int, float)) or exact_amount <= 0:
                logger.error(f"âŒ æ— æ•ˆçš„ç²¾ç¡®é‡‘é¢: {exact_amount}")
                return None
            
            # æ£€æŸ¥ç°æœ‰è®¢å•
            existing_order = DataManager.get_user_active_order(user_id, amount, orders_file)
            if existing_order:
                logger.info(f"âœ… è¿”å›ç°æœ‰è®¢å•: {existing_order['order_id']}")
                return existing_order['order_id']
            
            orders = DataManager.load_json(orders_file, {})
            
            # åˆ›å»ºå”¯ä¸€è®¢å•IDï¼ˆæ·»åŠ éšæœºæ•°é˜²æ­¢å†²çªï¼‰
            timestamp = int(time.time())
            order_id = f"ORDER_{timestamp}_{user_id}_{random.randint(1000, 9999)}"
            
            # ç¡®ä¿è®¢å•IDå”¯ä¸€
            while order_id in orders:
                order_id = f"ORDER_{timestamp}_{user_id}_{random.randint(1000, 9999)}"
            
            order_data = {
                "order_id": order_id,
                "user_id": user_id,
                "amount": amount,
                "exact_amount": exact_amount,
                "status": "pending",
                "created_at": beijing_time_isoformat(),
                "expires_at": (get_beijing_time() + timedelta(minutes=10)).isoformat(),
                "created_by": "system",
                "version": 1
            }
            
            orders[order_id] = order_data
            
            if DataManager.save_json(orders_file, orders):
                logger.info(f"âœ… åˆ›å»ºè®¢å•æˆåŠŸ: {order_id}, ç”¨æˆ·: {user_id}, é‡‘é¢: {amount}")
                return order_id
            else:
                logger.error(f"âŒ ä¿å­˜è®¢å•å¤±è´¥: {order_id}")
                return None
                
        except Exception as e:
            logger.error(f"âŒ åˆ›å»ºè®¢å•å¼‚å¸¸: {e}")
            return None
    
    @staticmethod
    def get_user_active_order(user_id: int, amount: float, orders_file: str = ORDERS_FILE) -> Dict:
        """è·å–ç”¨æˆ·æŒ‡å®šé‡‘é¢çš„æ´»è·ƒè®¢å•"""
        orders = DataManager.load_json(orders_file, {})
        current_time = get_beijing_time()
        
        for order in orders.values():
            if (order["user_id"] == user_id and 
                order["amount"] == amount and 
                order["status"] == "pending"):
                
                expires_at = datetime.fromisoformat(order["expires_at"])
                if expires_at > current_time:
                    return order
                else:
                    order["status"] = "expired"
                    DataManager.save_json(orders_file, orders)
        
        return None
    
    @staticmethod
    def complete_order(order_id: str, signature: str = "", orders_file: str = ORDERS_FILE):
        """å®Œæˆè®¢å• - å¢å¼ºç‰ˆ"""
        try:
            if not order_id:
                logger.error("âŒ è®¢å•IDä¸ºç©º")
                return False
            
            orders = DataManager.load_json(orders_file, {})
            
            if order_id not in orders:
                logger.error(f"âŒ è®¢å•ä¸å­˜åœ¨: {order_id}")
                return False
            
            order = orders[order_id]
            
            # æ£€æŸ¥è®¢å•çŠ¶æ€
            if order.get("status") == "completed":
                logger.warning(f"âš ï¸ è®¢å•å·²å®Œæˆ: {order_id}")
                return True
                
            if order.get("status") == "expired":
                logger.error(f"âŒ è®¢å•å·²è¿‡æœŸ: {order_id}")
                return False
            
            # æ£€æŸ¥è®¢å•æ˜¯å¦è¿‡æœŸ
            try:
                expires_at = datetime.fromisoformat(order["expires_at"])
                if expires_at <= get_beijing_time():
                    logger.error(f"âŒ è®¢å•å·²è¿‡æœŸ: {order_id}")
                    orders[order_id]["status"] = "expired"
                    DataManager.save_json(orders_file, orders)
                    return False
            except Exception as e:
                logger.error(f"âŒ è§£æè®¢å•è¿‡æœŸæ—¶é—´å¤±è´¥: {e}")
            
            # æ›´æ–°è®¢å•çŠ¶æ€
            orders[order_id]["status"] = "completed"
            orders[order_id]["signature"] = signature
            orders[order_id]["completed_at"] = beijing_time_isoformat()
            orders[order_id]["version"] = order.get("version", 1) + 1
            
            success = DataManager.save_json(orders_file, orders)
            if success:
                logger.info(f"âœ… è®¢å•å®Œæˆ: {order_id}")
            else:
                logger.error(f"âŒ ä¿å­˜è®¢å•å®ŒæˆçŠ¶æ€å¤±è´¥: {order_id}")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ å®Œæˆè®¢å•å¼‚å¸¸ {order_id}: {e}")
            return False
    
    @staticmethod
    def add_transaction(transaction: Dict, transaction_file: str = TRANSACTION_LOG_FILE):
        """æ·»åŠ äº¤æ˜“è®°å½• - å¢å¼ºç‰ˆ"""
        try:
            # éªŒè¯äº¤æ˜“æ•°æ®å®Œæ•´æ€§
            required_fields = ["user_id", "type", "amount", "timestamp"]
            for field in required_fields:
                if field not in transaction:
                    logger.error(f"âŒ äº¤æ˜“è®°å½•ç¼ºå°‘å¿…è¦å­—æ®µ {field}")
                    return False
            
            # æ·»åŠ å”¯ä¸€IDå’Œç‰ˆæœ¬å·
            transaction["transaction_id"] = f"TXN_{int(time.time())}_{random.randint(1000, 9999)}"
            transaction["created_at"] = beijing_time_isoformat()
            transaction["version"] = 1
            
            transactions = DataManager.load_json(transaction_file, [])
            transactions.append(transaction)
            
            # æ§åˆ¶æ–‡ä»¶å¤§å°ï¼Œä¿ç•™æœ€è¿‘1000æ¡è®°å½•
            if len(transactions) > 1000:
                transactions = transactions[-1000:]
                logger.info("ğŸ”„ äº¤æ˜“è®°å½•å·²è½®è½¬ï¼Œä¿ç•™æœ€è¿‘1000æ¡")
            
            success = DataManager.save_json(transaction_file, transactions)
            if success:
                logger.debug(f"âœ… æ·»åŠ äº¤æ˜“è®°å½•æˆåŠŸ: {transaction.get('transaction_id')}")
            else:
                logger.error("âŒ æ·»åŠ äº¤æ˜“è®°å½•å¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"âŒ æ·»åŠ äº¤æ˜“è®°å½•å¼‚å¸¸: {e}")
            return False
    
    @staticmethod
    def add_admin_log(admin_id: int, action: str, target_user_id: int = None, details: Dict = None, 
                     admin_logs_file: str = None) -> bool:
        """æ·»åŠ ç®¡ç†å‘˜æ“ä½œæ—¥å¿—"""
        if admin_logs_file is None:
            admin_logs_file = os.path.join(DATA_DIR, "admin_logs.json")
        
        try:
            with DataManager.file_lock(admin_logs_file):
                # åŠ è½½ç°æœ‰æ—¥å¿—
                logs = DataManager.load_json(admin_logs_file, [])
                
                # åˆ›å»ºæ–°æ—¥å¿—æ¡ç›®
                log_entry = {
                    "log_id": f"admin_{int(time.time())}_{admin_id}",
                    "timestamp": beijing_time_isoformat(),
                    "admin_id": admin_id,
                    "action": action,
                    "target_user_id": target_user_id,
                    "details": details or {},
                    "ip_address": "system",  # å¯ä»¥åç»­æ‰©å±•è·å–çœŸå®IP
                    "user_agent": "telegram_bot"
                }
                
                # æ·»åŠ åˆ°æ—¥å¿—åˆ—è¡¨
                logs.append(log_entry)
                
                # ä¿æŒæ—¥å¿—æ•°é‡é™åˆ¶ï¼ˆæœ€å¤šä¿ç•™1000æ¡ï¼‰
                if len(logs) > 1000:
                    logs = logs[-1000:]
                
                # ä¿å­˜æ—¥å¿—
                DataManager.save_json(admin_logs_file, logs, create_backup=True)
                
                logger.info(f"ğŸ“ ç®¡ç†å‘˜æ“ä½œå·²è®°å½•: {action} by {admin_id}")
                return True
                
        except Exception as e:
            logger.error(f"âŒ ç®¡ç†å‘˜æ—¥å¿—è®°å½•å¤±è´¥: {e}")
            return False
    
    @staticmethod
    def get_admin_logs(limit: int = 50, admin_id: int = None, action_filter: str = None,
                      admin_logs_file: str = None) -> List[Dict]:
        """è·å–ç®¡ç†å‘˜æ“ä½œæ—¥å¿—"""
        if admin_logs_file is None:
            admin_logs_file = os.path.join(DATA_DIR, "admin_logs.json")
        
        try:
            logs = DataManager.load_json(admin_logs_file, [])
            
            # è¿‡æ»¤æ¡ä»¶
            filtered_logs = []
            for log in logs:
                # æŒ‰ç®¡ç†å‘˜IDè¿‡æ»¤
                if admin_id and log.get("admin_id") != admin_id:
                    continue
                
                # æŒ‰æ“ä½œç±»å‹è¿‡æ»¤
                if action_filter and action_filter.lower() not in log.get("action", "").lower():
                    continue
                
                filtered_logs.append(log)
            
            # æŒ‰æ—¶é—´å€’åºæ’åˆ—ï¼Œè¿”å›æœ€æ–°çš„è®°å½•
            filtered_logs.sort(key=lambda x: x.get("timestamp", ""), reverse=True)
            
            return filtered_logs[:limit]
            
        except Exception as e:
            logger.error(f"âŒ è·å–ç®¡ç†å‘˜æ—¥å¿—å¤±è´¥: {e}")
            return []
    
    @staticmethod
    def clean_old_admin_logs(days: int = 30, admin_logs_file: str = None) -> bool:
        """æ¸…ç†æ—§çš„ç®¡ç†å‘˜æ—¥å¿—"""
        if admin_logs_file is None:
            admin_logs_file = os.path.join(DATA_DIR, "admin_logs.json")
        
        try:
            with DataManager.file_lock(admin_logs_file):
                logs = DataManager.load_json(admin_logs_file, [])
                
                # è®¡ç®—æˆªæ­¢æ—¶é—´
                cutoff_time = get_beijing_time() - timedelta(days=days)
                
                # è¿‡æ»¤ä¿ç•™æœ€è¿‘çš„æ—¥å¿—
                filtered_logs = []
                for log in logs:
                    try:
                        log_time = datetime.fromisoformat(log.get("timestamp", ""))
                        if log_time >= cutoff_time:
                            filtered_logs.append(log)
                    except:
                        # å¦‚æœæ—¶é—´æ ¼å¼æœ‰é—®é¢˜ï¼Œä¿ç•™è¯¥æ—¥å¿—
                        filtered_logs.append(log)
                
                # ä¿å­˜æ¸…ç†åçš„æ—¥å¿—
                DataManager.save_json(admin_logs_file, filtered_logs, create_backup=True)
                
                removed_count = len(logs) - len(filtered_logs)
                logger.info(f"ğŸ§¹ æ¸…ç†äº† {removed_count} æ¡æ—§ç®¡ç†å‘˜æ—¥å¿—")
                return True
                
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ç®¡ç†å‘˜æ—¥å¿—å¤±è´¥: {e}")
            return False

# é‡å¤çš„æ•°æ®å®Œæ•´æ€§éªŒè¯æ–¹æ³•å·²åˆ é™¤

    @staticmethod
    def get_file_size_mb(filename: str) -> float:
        """è·å–æ–‡ä»¶å¤§å°ï¼ˆMBï¼‰"""
        try:
            if os.path.exists(filename):
                size_bytes = os.path.getsize(filename)
                return size_bytes / (1024 * 1024)
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¤§å°å¤±è´¥ {filename}: {e}")
        return 0.0

    @staticmethod
    def get_file_age_days(filename: str) -> float:
        """è·å–æ–‡ä»¶å¹´é¾„ï¼ˆå¤©æ•°ï¼‰"""
        try:
            if os.path.exists(filename):
                mtime = os.path.getmtime(filename)
                current_time = time.time()
                age_seconds = current_time - mtime
                return age_seconds / (24 * 3600)
        except Exception as e:
            logger.error(f"è·å–æ–‡ä»¶å¹´é¾„å¤±è´¥ {filename}: {e}")
        return 0.0

    @staticmethod
    def cleanup_cache_and_logs(max_cache_age_days: int = 7, max_log_age_days: int = 30, 
                              max_backup_age_days: int = 1, max_cache_size_mb: float = 100.0) -> Dict[str, Any]:
        """
        ç»Ÿä¸€çš„ç¼“å­˜å’Œæ—¥å¿—æ¸…ç†åŠŸèƒ½
        
        Args:
            max_cache_age_days: ç¼“å­˜æ–‡ä»¶æœ€å¤§ä¿ç•™å¤©æ•°
            max_log_age_days: æ—¥å¿—æ–‡ä»¶æœ€å¤§ä¿ç•™å¤©æ•°  
            max_backup_age_days: å¤‡ä»½æ–‡ä»¶æœ€å¤§ä¿ç•™å¤©æ•°
            max_cache_size_mb: å•ä¸ªç¼“å­˜æ–‡ä»¶æœ€å¤§å¤§å°(MB)
            
        Returns:
            æ¸…ç†ç»“æœç»Ÿè®¡
        """
        logger.info("ğŸ§¹ å¼€å§‹æ‰§è¡Œå®šæœŸç¼“å­˜å’Œæ—¥å¿—æ¸…ç†...")
        
        cleanup_stats = {
            "start_time": beijing_time_isoformat(),
            "cache_files_cleaned": 0,
            "log_entries_cleaned": 0,
            "backup_files_cleaned": 0,
            "space_freed_mb": 0.0,
            "errors": []
        }
        
        try:
            # 1. æ¸…ç†ç¼“å­˜æ–‡ä»¶
            logger.info("ğŸ—‚ï¸ æ¸…ç†ç¼“å­˜æ–‡ä»¶...")
            cache_files = [
                ALERT_CACHE_FILE,
                FUNDING_RATE_CACHE_FILE,
                # OPEN_INTEREST_CACHE_FILE,  # å·²åˆ é™¤
            ]
            
            for cache_file in cache_files:
                try:
                    if os.path.exists(cache_file):
                        file_age_days = DataManager.get_file_age_days(cache_file)
                        file_size_mb = DataManager.get_file_size_mb(cache_file)
                        
                        # æ£€æŸ¥æ˜¯å¦éœ€è¦æ¸…ç†
                        should_clean = False
                        reason = ""
                        
                        if file_age_days > max_cache_age_days:
                            should_clean = True
                            reason = f"æ–‡ä»¶è¿‡æ—§({file_age_days:.1f}å¤©)"
                        elif file_size_mb > max_cache_size_mb:
                            should_clean = True  
                            reason = f"æ–‡ä»¶è¿‡å¤§({file_size_mb:.1f}MB)"
                        
                        if should_clean:
                            # å…ˆåˆ›å»ºå¤‡ä»½
                            DataManager.create_backup(cache_file)
                            
                            # åˆ é™¤åŸæ–‡ä»¶æˆ–é‡ç½®å†…å®¹
                            if "cache_data" in cache_file:
                                # å¯¹äºä¸»ç¼“å­˜æ–‡ä»¶ï¼Œé‡ç½®è€Œä¸æ˜¯åˆ é™¤
                                DataManager.save_json(cache_file, {})
                                logger.info(f"ğŸ”„ é‡ç½®ç¼“å­˜æ–‡ä»¶: {cache_file} ({reason})")
                            else:
                                # å…¶ä»–ç¼“å­˜æ–‡ä»¶å¯ä»¥åˆ é™¤
                                cleanup_stats["space_freed_mb"] += file_size_mb
                                os.remove(cache_file)
                                logger.info(f"ğŸ—‘ï¸ åˆ é™¤ç¼“å­˜æ–‡ä»¶: {cache_file} ({reason})")
                            
                            cleanup_stats["cache_files_cleaned"] += 1
                            
                except Exception as e:
                    error_msg = f"æ¸…ç†ç¼“å­˜æ–‡ä»¶å¤±è´¥ {cache_file}: {str(e)}"
                    logger.error(error_msg)
                    cleanup_stats["errors"].append(error_msg)
            
            # 2. æ¸…ç†å¤§å‹ç¼“å­˜æ–‡ä»¶ä¸­çš„è¿‡æœŸæ•°æ®
            logger.info("ğŸ“Š æ¸…ç†ç¼“å­˜æ–‡ä»¶ä¸­çš„è¿‡æœŸæ•°æ®...")
            cache_data_files = [CACHE_FILE_PRIMARY, CACHE_FILE_SECONDARY]
            
            for cache_data_file in cache_data_files:
                try:
                    if os.path.exists(cache_data_file):
                        cache_data = DataManager.load_json(cache_data_file, {})
                        if cache_data:
                            original_count = len(cache_data)
                            current_time = time.time()
                            valid_cache = {}
                            
                            # æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ¡ç›®
                            for key, cache_item in cache_data.items():
                                if isinstance(cache_item, dict) and 'timestamp' in cache_item:
                                    cache_age = current_time - cache_item['timestamp']
                                    # ä¿ç•™24å°æ—¶å†…çš„ç¼“å­˜
                                    if cache_age < 86400:  # 24å°æ—¶ = 86400ç§’
                                        valid_cache[key] = cache_item
                            
                            if len(valid_cache) < original_count:
                                DataManager.save_json(cache_data_file, valid_cache, create_backup=True)
                                cleaned_entries = original_count - len(valid_cache)
                                cleanup_stats["log_entries_cleaned"] += cleaned_entries
                                logger.info(f"ğŸ§¹ æ¸…ç†äº† {cleaned_entries} ä¸ªè¿‡æœŸç¼“å­˜æ¡ç›®: {cache_data_file}")
                                
                except Exception as e:
                    error_msg = f"æ¸…ç†ç¼“å­˜æ•°æ®å¤±è´¥ {cache_data_file}: {str(e)}"
                    logger.error(error_msg)
                    cleanup_stats["errors"].append(error_msg)
            
            # 3. æ¸…ç†å†å²æ—¥å¿—æ–‡ä»¶
            logger.info("ğŸ“ æ¸…ç†å†å²æ—¥å¿—...")
            log_files = [
                POINTS_HISTORY_FILE,
                TRANSACTION_LOG_FILE,
                # OPEN_INTEREST_HISTORY_FILE,  # å·²åˆ é™¤
                os.path.join(DATA_DIR, "admin_logs.json")
            ]
            
            for log_file in log_files:
                try:
                    if os.path.exists(log_file):
                        logs = DataManager.load_json(log_file, [])
                        if isinstance(logs, list) and logs:
                            original_count = len(logs)
                            current_time = get_beijing_time()
                            cutoff_time = current_time - timedelta(days=max_log_age_days)
                            
                            # è¿‡æ»¤ä¿ç•™æœ€è¿‘çš„æ—¥å¿—
                            filtered_logs = []
                            for log in logs:
                                try:
                                    log_time_str = log.get("timestamp", "")
                                    if log_time_str:
                                        log_time = datetime.fromisoformat(log_time_str.replace('Z', '+00:00'))
                                        if log_time.tzinfo is None:
                                            log_time = log_time.replace(tzinfo=timezone.utc)
                                        
                                        beijing_tz = timezone(timedelta(hours=8))
                                        log_time = log_time.astimezone(beijing_tz)
                                        
                                        if log_time >= cutoff_time:
                                            filtered_logs.append(log)
                                    else:
                                        # ä¿ç•™æ²¡æœ‰æ—¶é—´æˆ³çš„æ—¥å¿—
                                        filtered_logs.append(log)
                                except:
                                    # ä¿ç•™æ— æ•ˆæ—¶é—´æˆ³çš„æ—¥å¿—
                                    filtered_logs.append(log)
                            
                            if len(filtered_logs) < original_count:
                                # ä¿ç•™æœ€è¿‘1000æ¡è®°å½•ï¼ˆå³ä½¿è¶…è¿‡æ—¶é—´é™åˆ¶ï¼‰
                                if len(filtered_logs) > 1000:
                                    filtered_logs = filtered_logs[-1000:]
                                    
                                DataManager.save_json(log_file, filtered_logs, create_backup=True)
                                cleaned_entries = original_count - len(filtered_logs)
                                cleanup_stats["log_entries_cleaned"] += cleaned_entries
                                logger.info(f"ğŸ§¹ æ¸…ç†äº† {cleaned_entries} æ¡è¿‡æœŸæ—¥å¿—: {log_file}")
                                
                except Exception as e:
                    error_msg = f"æ¸…ç†æ—¥å¿—æ–‡ä»¶å¤±è´¥ {log_file}: {str(e)}"
                    logger.error(error_msg)
                    cleanup_stats["errors"].append(error_msg)
            
            # 4. æ¸…ç†å¤‡ä»½æ–‡ä»¶
            logger.info("ğŸ“¦ æ¸…ç†æ—§å¤‡ä»½æ–‡ä»¶...")
            backup_dirs = [
                os.path.join(DATA_DIR, "backups")
            ]
            
            for backup_dir in backup_dirs:
                try:
                    if os.path.exists(backup_dir):
                        for filename in os.listdir(backup_dir):
                            file_path = os.path.join(backup_dir, filename)
                            if os.path.isfile(file_path):
                                file_age_days = DataManager.get_file_age_days(file_path)
                                if file_age_days > max_backup_age_days:
                                    file_size_mb = DataManager.get_file_size_mb(file_path)
                                    cleanup_stats["space_freed_mb"] += file_size_mb
                                    os.remove(file_path)
                                    cleanup_stats["backup_files_cleaned"] += 1
                                    logger.info(f"ğŸ—‘ï¸ åˆ é™¤æ—§å¤‡ä»½æ–‡ä»¶: {filename} ({file_age_days:.1f}å¤©)")
                                    
                except Exception as e:
                    error_msg = f"æ¸…ç†å¤‡ä»½ç›®å½•å¤±è´¥ {backup_dir}: {str(e)}"
                    logger.error(error_msg)
                    cleanup_stats["errors"].append(error_msg)
            
            # 5. æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            logger.info("ğŸ§½ æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
            try:
                temp_patterns = [
                    "*.tmp",
                    "*.lock", 
                    "*.session-journal",
                    "*.pid"
                ]
                
                for pattern in temp_patterns:
                    import glob
                    temp_files = glob.glob(os.path.join(BASE_DIR, pattern))
                    for temp_file in temp_files:
                        try:
                            if os.path.exists(temp_file):
                                file_age_days = DataManager.get_file_age_days(temp_file)
                                if file_age_days > 1:  # åˆ é™¤1å¤©ä»¥ä¸Šçš„ä¸´æ—¶æ–‡ä»¶
                                    file_size_mb = DataManager.get_file_size_mb(temp_file)
                                    cleanup_stats["space_freed_mb"] += file_size_mb
                                    os.remove(temp_file)
                                    cleanup_stats["cache_files_cleaned"] += 1
                                    logger.info(f"ğŸ—‘ï¸ åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_file}")
                        except Exception as e:
                            logger.warning(f"åˆ é™¤ä¸´æ—¶æ–‡ä»¶å¤±è´¥ {temp_file}: {e}")
                            
            except Exception as e:
                error_msg = f"æ¸…ç†ä¸´æ—¶æ–‡ä»¶å¤±è´¥: {str(e)}"
                logger.warning(error_msg)
                cleanup_stats["errors"].append(error_msg)
            
            # ç»Ÿè®¡ç»“æœ
            cleanup_stats["end_time"] = beijing_time_isoformat()
            
            logger.info(f"""
ğŸ‰ ç¼“å­˜å’Œæ—¥å¿—æ¸…ç†å®Œæˆï¼
ğŸ“Š æ¸…ç†ç»Ÿè®¡:
   - æ¸…ç†ç¼“å­˜æ–‡ä»¶: {cleanup_stats['cache_files_cleaned']} ä¸ª
   - æ¸…ç†æ—¥å¿—æ¡ç›®: {cleanup_stats['log_entries_cleaned']} æ¡  
   - æ¸…ç†å¤‡ä»½æ–‡ä»¶: {cleanup_stats['backup_files_cleaned']} ä¸ª
   - é‡Šæ”¾ç©ºé—´: {cleanup_stats['space_freed_mb']:.2f} MB
   - é”™è¯¯æ•°é‡: {len(cleanup_stats['errors'])} ä¸ª
""")
            
            return cleanup_stats
            
        except Exception as e:
            error_msg = f"æ¸…ç†è¿‡ç¨‹å¼‚å¸¸: {str(e)}"
            logger.error(error_msg)
            cleanup_stats["errors"].append(error_msg)
            return cleanup_stats

    @staticmethod
    def get_storage_usage_stats() -> Dict[str, Any]:
        """è·å–å­˜å‚¨ä½¿ç”¨ç»Ÿè®¡"""
        stats = {
            "data_dir_size_mb": 0.0,
            "cache_dir_size_mb": 0.0,
            "backup_dir_size_mb": 0.0,
            "file_counts": {},
            "largest_files": []
        }
        
        try:
            # è®¡ç®—å„ç›®å½•å¤§å°
            for root, dirs, files in os.walk(DATA_DIR):
                for file in files:
                    file_path = os.path.join(root, file)
                    size_mb = DataManager.get_file_size_mb(file_path)
                    
                    # åˆ†ç±»ç»Ÿè®¡
                    if "cache" in root:
                        stats["cache_dir_size_mb"] += size_mb
                    elif "backup" in root:
                        stats["backup_dir_size_mb"] += size_mb
                    else:
                        stats["data_dir_size_mb"] += size_mb
                    
                    # è®°å½•å¤§æ–‡ä»¶
                    if size_mb > 1.0:  # å¤§äº1MBçš„æ–‡ä»¶
                        stats["largest_files"].append({
                            "file": file_path,
                            "size_mb": size_mb,
                            "age_days": DataManager.get_file_age_days(file_path)
                        })
            
            # æ’åºå¤§æ–‡ä»¶åˆ—è¡¨
            stats["largest_files"].sort(key=lambda x: x["size_mb"], reverse=True)
            stats["largest_files"] = stats["largest_files"][:10]  # åªä¿ç•™å‰10ä¸ª
            
            # æ–‡ä»¶ç±»å‹ç»Ÿè®¡
            file_types = {}
            for root, dirs, files in os.walk(DATA_DIR):
                for file in files:
                    ext = os.path.splitext(file)[1] or "æ— æ‰©å±•å"
                    file_types[ext] = file_types.get(ext, 0) + 1
            
            stats["file_counts"] = file_types
            
        except Exception as e:
            logger.error(f"è·å–å­˜å‚¨ç»Ÿè®¡å¤±è´¥: {e}")
        
        return stats

# ===== åˆ é™¤é‡å¤çš„å¯¼å…¥å’Œé…ç½®å— =====
# æ‰€æœ‰å¯¼å…¥å’Œé…ç½®å·²åœ¨æ–‡ä»¶å¼€å¤´å®šä¹‰ï¼Œæ­¤å¤„å†—ä½™å†…å®¹å·²ç§»é™¤
# æ‰€æœ‰å‰©ä½™çš„å­¤ç«‹å‡½æ•°å·²åˆ é™¤

class IntegratedInvitationManager:
    """æ•´åˆçš„é‚€è¯·ç®¡ç†å™¨"""
    
    def __init__(self, data_file: str = INVITATION_DATA_FILE, withdrawal_file: str = WITHDRAWAL_REQUESTS_FILE):
        self.data_file = data_file
        self.withdrawal_file = withdrawal_file
        self._ensure_data_files()
    
    def _ensure_data_files(self):
        """ç¡®ä¿æ•°æ®æ–‡ä»¶å­˜åœ¨"""
        Path(self.data_file).parent.mkdir(parents=True, exist_ok=True)
        Path(self.withdrawal_file).parent.mkdir(parents=True, exist_ok=True)
        
        if not Path(self.data_file).exists():
            default_data = {
                "invitations": {},
                "relationships": {},
                "commissions": {},
                "stats": {
                    "total_commissions": 0.0,
                    "total_invitations": 0,
                    "total_active_inviters": 0,
                    "created_at": beijing_time_isoformat()
                },
                "code_to_user": {}
            }
            DataManager.save_json(self.data_file, default_data)
            
        if not Path(self.withdrawal_file).exists():
            DataManager.save_json(self.withdrawal_file, {"requests": {}})
    
    def get_user_invitation_code(self, user_id: int) -> str:
        """è·å–ç”¨æˆ·çš„é‚€è¯·ç """
        data = DataManager.load_json(self.data_file)
        user_key = str(user_id)
        
        if user_key in data["invitations"]:
            return data["invitations"][user_key]["invitation_code"]
        
        # ç”Ÿæˆæ–°çš„é‚€è¯·ç 
        import random
        import string
        code = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))
        
        # ç¡®ä¿å”¯ä¸€æ€§
        while code in data["code_to_user"]:
            code = ''.join(random.choices(string.ascii_uppercase + string.digits, k=10))
        
        # åˆ›å»ºé‚€è¯·è®°å½•
        data["invitations"][user_key] = {
            "user_id": user_id,
            "invitation_code": code,
            "username": None,
            "created_at": beijing_time_isoformat(),
            "invitees": [],
            "total_commission": 0.0,
            "available_commission": 0.0,
            "withdrawn_commission": 0.0,
            "stats": {
                "total_invites": 0,
                "successful_invites": 0,
                "total_recharges": 0.0
            }
        }
        data["code_to_user"][code] = user_id
        DataManager.save_json(self.data_file, data)
        
        return code
    
    def process_invitation(self, invitee_id: int, invitation_code: str, invitee_username: str = None) -> bool:
        """å¤„ç†é‚€è¯·å…³ç³»"""
        data = DataManager.load_json(self.data_file)
        
        # æ£€æŸ¥é‚€è¯·ç æ˜¯å¦å­˜åœ¨
        if invitation_code not in data["code_to_user"]:
            return False
        
        inviter_id = data["code_to_user"][invitation_code]
        
        # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨é‚€è¯·å…³ç³»
        if str(invitee_id) in data["relationships"]:
            return False  # å·²è¢«é‚€è¯·
        
        # å»ºç«‹é‚€è¯·å…³ç³»
        data["relationships"][str(invitee_id)] = inviter_id
        
        # æ›´æ–°é‚€è¯·è€…è®°å½•
        inviter_key = str(inviter_id)
        if inviter_key in data["invitations"]:
            invitee_record = {
                "user_id": invitee_id,
                "username": invitee_username,
                "invited_at": beijing_time_isoformat(),
                "total_recharge": 0.0,
                "commission_earned": 0.0
            }
            data["invitations"][inviter_key]["invitees"].append(invitee_record)
            data["invitations"][inviter_key]["stats"]["total_invites"] += 1
        
        DataManager.save_json(self.data_file, data)
        return True
    
    def calculate_commission_rate(self, inviter_total_recharge: float) -> float:
        """è®¡ç®—ä½£é‡‘æ¯”ä¾‹"""
        return 0.05  # å›ºå®š5%ä½£é‡‘
    
    def process_commission(self, invitee_id: int, recharge_amount: float) -> dict:
        """å¤„ç†ä½£é‡‘åˆ†é…"""
        data = DataManager.load_json(self.data_file)
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‚€è¯·å…³ç³»
        if str(invitee_id) not in data["relationships"]:
            return {"success": False, "message": "æ— é‚€è¯·å…³ç³»"}
        
        inviter_id = data["relationships"][str(invitee_id)]
        inviter_key = str(inviter_id)
        
        if inviter_key not in data["invitations"]:
            return {"success": False, "message": "é‚€è¯·è€…æ•°æ®ä¸å­˜åœ¨"}
        
        # è®¡ç®—ä½£é‡‘
        commission_rate = self.calculate_commission_rate(0)  # å¯ä»¥æ ¹æ®éœ€è¦å®ç°åŠ¨æ€ä½£é‡‘ç‡
        commission_amount = recharge_amount * commission_rate
        
        # æ›´æ–°é‚€è¯·è€…æ•°æ®
        invitation_data = data["invitations"][inviter_key]
        invitation_data["total_commission"] += commission_amount
        invitation_data["available_commission"] += commission_amount
        
        # æ›´æ–°è¢«é‚€è¯·è€…å……å€¼è®°å½•
        for invitee in invitation_data["invitees"]:
            if invitee["user_id"] == invitee_id:
                invitee["total_recharge"] += recharge_amount
                invitee["commission_earned"] += commission_amount
                break
        
        # æ›´æ–°ç»Ÿè®¡
        invitation_data["stats"]["total_recharges"] += recharge_amount
        
        # è®°å½•ä½£é‡‘
        if inviter_key not in data["commissions"]:
            data["commissions"][inviter_key] = []
        
        commission_record = {
            "invitee_id": invitee_id,
            "recharge_amount": recharge_amount,
            "commission_rate": commission_rate,
            "commission_amount": commission_amount,
            "timestamp": beijing_time_isoformat(),
            "status": "available"
        }
        data["commissions"][inviter_key].append(commission_record)
        
        # æ›´æ–°å…¨å±€ç»Ÿè®¡
        data["stats"]["total_commissions"] += commission_amount
        
        DataManager.save_json(self.data_file, data)
        
        return {
            "success": True,
            "inviter_id": inviter_id,
            "invitee_id": invitee_id,
            "commission_amount": commission_amount,
            "commission_rate": commission_rate,
            "recharge_amount": recharge_amount,
            "new_total_commission": invitation_data["total_commission"],
            "new_available_commission": invitation_data["available_commission"]
        }
    
    def get_user_invitation_data(self, user_id: int) -> Dict:
        """è·å–ç”¨æˆ·é‚€è¯·ç›¸å…³æ•°æ®"""
        data = DataManager.load_json(self.data_file)
        user_key = str(user_id)
        
        if user_key not in data["invitations"]:
            return None
        
        return data["invitations"][user_key]
    
    def create_invitation(self, user_id: int, username: str = None):
        """åˆ›å»ºé‚€è¯·è®°å½•"""
        self.get_user_invitation_code(user_id)  # è¿™ä¼šè‡ªåŠ¨åˆ›å»ºé‚€è¯·è®°å½•
        
        # æ›´æ–°ç”¨æˆ·å
        if username:
            data = DataManager.load_json(self.data_file)
            user_key = str(user_id)
            if user_key in data["invitations"]:
                data["invitations"][user_key]["username"] = username
                DataManager.save_json(self.data_file, data)

class WebSocketMonitor:
    """WebSocketå®æ—¶ç›‘æ§å™¨ - ç›‘æ§Solanaè½¬è´¦"""
    
    def __init__(self):
        self.websocket = None
        self.is_running = False
        self.subscription_ids = {}
        
        # WebSocketç›‘æ§ï¼šé»˜è®¤å…³é—­ï¼Œéœ€æ˜¾å¼ ENABLE_WEBSOCKET_MONITOR=1 å¼€å¯
        self.websocket_url = f"wss://mainnet.helius-rpc.com/?api-key={API_KEY}"
        self.websocket_enabled = os.getenv("ENABLE_WEBSOCKET_MONITOR", "0") == "1"
        self.wallet_address = WALLET_ADDRESS
        self.token_account = MONITOR_TOKEN_ACCOUNT
        self.helius_rpc_url = f"https://mainnet.helius-rpc.com/?api-key={API_KEY}"
        
        self.last_balance = DataManager.get_last_balance(BALANCE_HISTORY_FILE)
        
        balance_history = DataManager.get_balance_history(limit=1, balance_file=BALANCE_HISTORY_FILE)
        if balance_history:
            last_record = balance_history[0]
            last_time = format_beijing_time(last_record["timestamp"], "%m-%d %H:%M:%S")
            logger.info(f"ğŸ”„ ä»å†å²è®°å½•æ¢å¤ä½™é¢: {self.last_balance:.4f} USDT (æ›´æ–°äº: {last_time})")
        else:
            logger.info(f"ğŸ”„ æ— å†å²è®°å½•ï¼Œåˆå§‹ä½™é¢: {self.last_balance:.4f} USDT")
    
    async def start_monitoring(self):
        """å¯åŠ¨ç›‘æ§"""
        if not self.websocket_enabled:
            logger.info("ğŸ”‡ WebSocketç›‘æ§å·²ç¦ç”¨ï¼Œè·³è¿‡å¯åŠ¨")
            return

        if self.is_running:
            logger.warning("âš ï¸ ç›‘æ§å·²ç»åœ¨è¿è¡Œä¸­")
            return

        self.is_running = True
        logger.info("ğŸš€ å¯åŠ¨WebSocketç›‘æ§...")

        await self._fetch_current_balance()
        asyncio.create_task(self._periodic_backup_check())

        while self.is_running:
            try:
                await self._connect_and_monitor()
            except Exception as e:
                logger.error(f"WebSocketè¿æ¥å¤±è´¥: {e}")
                if self.is_running:
                    logger.info("â³ 5ç§’åé‡æ–°è¿æ¥...")
                    await asyncio.sleep(5)
    
    def stop_monitoring(self):
        """åœæ­¢ç›‘æ§"""
        self.is_running = False
        logger.info("ğŸ›‘ WebSocketç›‘æ§å·²åœæ­¢")
    
    async def _periodic_backup_check(self):
        """å®šæœŸå¤‡ç”¨æ£€æµ‹æœºåˆ¶"""
        logger.info("ğŸ”„ å¯åŠ¨å®šæœŸå¤‡ç”¨æ£€æµ‹...")
        
        while self.is_running:
            try:
                await asyncio.sleep(30)
                
                if self.is_running:
                    logger.debug("ğŸ” æ‰§è¡Œå®šæœŸå¤‡ç”¨æ£€æµ‹...")
                    await self._check_recent_transactions()
                    await self._check_expired_orders()
                    
            except Exception as e:
                logger.error(f"å®šæœŸå¤‡ç”¨æ£€æµ‹å¤±è´¥: {e}")
                await asyncio.sleep(5)
    
    async def _check_expired_orders(self):
        """æ£€æŸ¥è¿‡æœŸè®¢å•"""
        try:
            orders = DataManager.load_json(ORDERS_FILE, {})
            current_time = get_beijing_time()
            expired_count = 0
            
            for order_id, order in orders.items():
                if order["status"] == "pending":
                    expires_at = datetime.fromisoformat(order["expires_at"])
                    if expires_at <= current_time:
                        order["status"] = "expired"
                        expired_count += 1
            
            if expired_count > 0:
                DataManager.save_json(ORDERS_FILE, orders)
                logger.info(f"â° æ ‡è®°äº† {expired_count} ä¸ªè¿‡æœŸè®¢å•")
                
        except Exception as e:
            logger.error(f"æ£€æŸ¥è¿‡æœŸè®¢å•å¤±è´¥: {e}")
    
    async def _connect_and_monitor(self):
        """è¿æ¥WebSocketå¹¶å¼€å§‹ç›‘æ§"""
        try:
            # å¯ç”¨SSLè¯ä¹¦éªŒè¯ - ä½¿ç”¨æ­£ç¡®çš„è¯ä¹¦é…ç½®
            ssl_context = ssl.create_default_context()
            if CERTIFI_AVAILABLE:
                ssl_context.load_verify_locations(certifi.where())
            print(f"ğŸ” SSLé…ç½®: å¯ç”¨è¯ä¹¦éªŒè¯ï¼ˆä½¿ç”¨æ­£ç¡®çš„è¯ä¹¦ï¼‰")

            print(f"ğŸ” è¿æ¥ç›®æ ‡: {self.websocket_url}")

            # å¯ç”¨SSLéªŒè¯è¿›è¡Œè¿æ¥
            async with websockets.connect(
                self.websocket_url,
                ping_interval=30,
                ping_timeout=10,
                ssl=ssl_context,  # å¯ç”¨SSLéªŒè¯
                close_timeout=10,
                max_size=2**20,
                max_queue=32
            ) as websocket:
                self.websocket = websocket
                print("âœ… WebSocketè¿æ¥æˆåŠŸå»ºç«‹")

                await self._subscribe_addresses()

                async for message in websocket:
                    await self._handle_message(message)

        except websockets.ConnectionClosed:
            print("âš ï¸ WebSocketè¿æ¥å·²å…³é—­")
        except Exception as e:
            print(f"âŒ WebSocketè¿æ¥é”™è¯¯: {e}")
            raise
    
    async def _subscribe_addresses(self):
        """è®¢é˜…åœ°å€ç›‘æ§"""
        token_request = {
            "jsonrpc": "2.0", 
            "id": 1,
            "method": "accountSubscribe",
            "params": [
                self.token_account,
                {"encoding": "jsonParsed", "commitment": "confirmed"}
            ]
        }
        
        await self.websocket.send(json.dumps(token_request))
        logger.info(f"ğŸ“¡ å·²è®¢é˜…ä»£å¸è´¦æˆ·ç›‘æ§: {self.token_account}")
    
    async def _handle_message(self, message: str):
        """å¤„ç†WebSocketæ¶ˆæ¯"""
        try:
            data = json.loads(message)
            
            if "result" in data and isinstance(data["result"], int):
                subscription_id = data["result"]
                self.subscription_ids["token"] = subscription_id
                logger.info(f"âœ… ä»£å¸è´¦æˆ·è®¢é˜…æˆåŠŸ (ID: {subscription_id})")
                return
            
            if data.get("method") == "accountNotification":
                await self._handle_account_notification(data["params"])
                
        except json.JSONDecodeError:
            logger.error("WebSocketæ¶ˆæ¯JSONè§£æå¤±è´¥")
        except Exception as e:
            logger.error(f"å¤„ç†WebSocketæ¶ˆæ¯å¤±è´¥: {e}")
    
    async def _handle_account_notification(self, params):
        """å¤„ç†è´¦æˆ·å˜åŒ–é€šçŸ¥"""
        try:
            result = params["result"]
            
            logger.info(f"ğŸ”” æ£€æµ‹åˆ°ä»£å¸è´¦æˆ·å˜åŒ–!")
            logger.info(f"â° æ—¶é—´: {format_beijing_time(get_beijing_time().isoformat(), '%Y-%m-%d %H:%M:%S')}")
            
            if result['value'].get('data') and result['value']['data'].get('parsed'):
                parsed_data = result['value']['data']['parsed']
                await self._check_usdt_transfer(parsed_data)
            
            await self._check_recent_transactions()
                
        except Exception as e:
            logger.error(f"å¤„ç†è´¦æˆ·å˜åŒ–é€šçŸ¥å¤±è´¥: {e}")
    
    async def _check_usdt_transfer(self, parsed_data):
        """æ£€æŸ¥USDTè½¬è´¦ - ç²¾ç¡®åŒ¹é…ç‰ˆ"""
        try:
            if parsed_data.get("type") == "account" and "info" in parsed_data:
                info = parsed_data["info"]
                if "tokenAmount" in info and info["tokenAmount"]:
                    token_amount = info["tokenAmount"]
                    ui_amount = token_amount.get("uiAmount")
                    
                    if ui_amount is not None:
                        current_balance = float(ui_amount)
                        previous_balance = self.last_balance
                        
                        balance_change = current_balance - previous_balance
                        
                        logger.info(f"ğŸ’° ä½™é¢æ›´æ–°: {previous_balance:.4f} â†’ {current_balance:.4f} USDT")
                        if balance_change != 0:
                            logger.info(f"ğŸ“Š ä½™é¢å˜åŒ–: {balance_change:+.4f} USDT")
                        
                        triggered_check = False
                        if balance_change > 0.0001:
                            triggered_check = True
                            logger.info(f"ğŸ‰ æ£€æµ‹åˆ°USDTæ”¶å…¥: +{balance_change:.4f} USDT")
                            logger.info(f"ğŸ“Š å½“å‰ä½™é¢: {current_balance:.4f} USDT")
                            
                            try:
                                await self._trigger_order_check(balance_change, "websocket_balance_change")
                            except Exception as e:
                                logger.error(f"è§¦å‘è®¢å•æ£€æŸ¥å¤±è´¥: {e}")
                        
                        DataManager.add_balance_change(
                            balance_before=previous_balance,
                            balance_after=current_balance,
                            change_amount=balance_change,
                            source="websocket",
                            triggered_order_check=triggered_check,
                            balance_file=BALANCE_HISTORY_FILE
                        )
                        
                        self.last_balance = current_balance
                        
        except Exception as e:
            logger.error(f"æ£€æŸ¥USDTè½¬è´¦å¤±è´¥: {e}")
    
    async def _trigger_order_check(self, amount: float, signature: str = ""):
        """è§¦å‘è®¢å•æ£€æŸ¥ï¼Œå¯»æ‰¾åŒ¹é…çš„å……å€¼è®¢å•"""
        try:
            logger.info(f"ğŸ” å¼€å§‹æ£€æŸ¥åŒ¹é…è®¢å• (é‡‘é¢: {amount:.4f} USDT)")
            
            pending_orders = DataManager.get_pending_orders(ORDERS_FILE)
            logger.info(f"ğŸ“‹ å½“å‰å¾…å¤„ç†è®¢å•æ•°é‡: {len(pending_orders)}")
            
            if not pending_orders:
                logger.info("ğŸ“­ æ²¡æœ‰å¾…å¤„ç†çš„è®¢å•")
                return
            
            best_match = None
            min_difference = float('inf')
            
            for order in pending_orders:
                exact_amount = order.get("exact_amount", 0.0)
                difference = abs(exact_amount - amount)
                
                logger.info(f"ğŸ” æ£€æŸ¥è®¢å• {order['order_id']}: æœŸæœ› {exact_amount:.4f}, å®é™… {amount:.4f}, å·®å¼‚ {difference:.4f}")
                
                if difference < min_difference:
                    min_difference = difference
                    best_match = order
            
            if best_match and min_difference <= 0.01:
                logger.info(f"âœ… æ‰¾åˆ°åŒ¹é…è®¢å•: {best_match['order_id']} (å·®å¼‚: {min_difference:.4f})")
                await self._complete_payment(best_match, signature)
            else:
                logger.info(f"âŒ æœªæ‰¾åˆ°åŒ¹é…è®¢å• (æœ€å°å·®å¼‚: {min_difference:.4f})")
                
        except Exception as e:
            logger.error(f"è§¦å‘è®¢å•æ£€æŸ¥å¤±è´¥: {e}")
    
    async def _complete_payment(self, order: Dict, signature: str):
        """å®Œæˆæ”¯ä»˜å¤„ç†"""
        try:
            user_id = order["user_id"]
            amount = order["amount"]
            order_id = order["order_id"]
            
            logger.info(f"ğŸ’³ å¼€å§‹å¤„ç†æ”¯ä»˜: ç”¨æˆ· {user_id}, é‡‘é¢ {amount} USDT")
            
            # æ›´æ–°è®¢å•çŠ¶æ€
            DataManager.complete_order(order_id, signature, ORDERS_FILE)
            logger.info(f"âœ… è®¢å•çŠ¶æ€å·²æ›´æ–°: {order_id}")
            
            # è·å–ç”¨æˆ·æ•°æ®
            user_data = DataManager.get_user_data(user_id, USER_DATA_FILE)
            points_before = user_data["points"]
            
            # è®¡ç®—ç§¯åˆ†å’Œå¥–åŠ±
            base_points = amount * 10
            bonus = 0
            if amount >= 1000:
                bonus = int(base_points * 0.25)
                bonus_text = "25%"
            elif amount >= 500:
                bonus = int(base_points * 0.10)
                bonus_text = "10%"
            
            total_points = base_points + bonus
            
            # æ›´æ–°ç”¨æˆ·æ•°æ®
            user_data["points"] += total_points
            user_data["total_recharged"] += amount
            user_data["last_active"] = beijing_time_isoformat()
            DataManager.update_user_data(user_id, user_data, USER_DATA_FILE)
            
            # è®°å½•ç§¯åˆ†å˜åŒ–
            DataManager.add_points_history(
                user_id, total_points, f"å……å€¼ {amount} USDT", user_data["points"]
            )
            
            # è®°å½•äº¤æ˜“
            transaction = {
                "user_id": user_id,
                "amount": amount,
                "points_awarded": total_points,
                "bonus_points": bonus,
                "signature": signature,
                "order_id": order_id,
                "timestamp": beijing_time_isoformat(),
                "type": "recharge"
            }
            DataManager.add_transaction(transaction, TRANSACTION_LOG_FILE)
            
            logger.info(f"ğŸ’ ç§¯åˆ†å·²æ·»åŠ : {points_before} â†’ {user_data['points']} (+{total_points})")
            
            # å¤„ç†é‚€è¯·è¿”ä½£
            if invitation_manager:
                try:
                    await self._notify_inviter_about_commission(user_id, amount)
                except Exception as e:
                    logger.error(f"å¤„ç†é‚€è¯·è¿”ä½£å¤±è´¥: {e}")
            
            # å‘é€å……å€¼æˆåŠŸé€šçŸ¥ç»™ç”¨æˆ·
            try:
                from telegram import Bot
                if BOT_TOKEN:
                    bot = Bot(token=BOT_TOKEN)
                    
                    success_message = f"""ğŸ‰ å……å€¼æˆåŠŸï¼

ğŸ’° å……å€¼é‡‘é¢: {amount} USDT
ğŸ’ è·å¾—ç§¯åˆ†: {total_points} ç§¯åˆ†
ğŸ å¥–åŠ±ç§¯åˆ†: {bonus} ç§¯åˆ†
ğŸ“Š å½“å‰ç§¯åˆ†: {user_data['points']} ç§¯åˆ†

âœ… ç§¯åˆ†å·²åˆ°è´¦ï¼Œå¯ç«‹å³ä½¿ç”¨ä¿¡å·æœåŠ¡ï¼
â° å¯ä½¿ç”¨å¤©æ•°: {user_data['points'] // 50} å¤©

ğŸ”” æ¸©é¦¨æç¤ºï¼šä¿¡å·æœåŠ¡éœ€è¦ç§¯åˆ†
ğŸ’³ æ„Ÿè°¢æ‚¨çš„å……å€¼ï¼Œç¥æ‚¨äº¤æ˜“æ„‰å¿«ï¼"""

                    await bot.send_message(
                        chat_id=user_id,
                        text=success_message,
                        parse_mode='Markdown'
                    )
                    logger.info(f"âœ… å……å€¼æˆåŠŸé€šçŸ¥å·²å‘é€ç»™ç”¨æˆ· {user_id}")
                    
            except Exception as notify_error:
                logger.error(f"å‘é€å……å€¼æˆåŠŸé€šçŸ¥å¤±è´¥: {notify_error}")
            
            logger.info(f"ğŸ‰ å……å€¼å¤„ç†å®Œæˆ: ç”¨æˆ· {user_id}, é‡‘é¢ {amount} USDT, ç§¯åˆ† +{total_points}")
                
        except Exception as e:
            logger.error(f"å®Œæˆæ”¯ä»˜å¤„ç†å¤±è´¥: {e}")
    
    async def _notify_inviter_about_commission(self, invitee_id: int, recharge_amount: float):
        """é€šçŸ¥é‚€è¯·äººå…³äºä½£é‡‘"""
        try:
            commission_result = invitation_manager.process_commission(invitee_id, recharge_amount)
            
            if commission_result["success"]:
                inviter_id = commission_result["inviter_id"]
                commission_amount = commission_result["commission_amount"]
                commission_rate = commission_result["commission_rate"]
                new_available = commission_result["new_available_commission"]
                
                logger.info(f"âœ… é‚€è¯·è¿”ä½£å¤„ç†æˆåŠŸ: é‚€è¯·è€… {inviter_id}, è¢«é‚€è¯·äºº {invitee_id}, è¿”ä½£ ${commission_amount:.2f}")
                
                # å‘é€è¿”ä½£åˆ°è´¦é€šçŸ¥ç»™é‚€è¯·è€…
                try:
                    from telegram import Bot
                    if BOT_TOKEN:
                        bot = Bot(token=BOT_TOKEN)
                        
                        commission_message = f"""ğŸ’° é‚€è¯·è¿”ä½£åˆ°è´¦ï¼

ğŸ‰ æ‚¨çš„é‚€è¯·å¥½å‹å……å€¼æˆåŠŸï¼
ğŸ‘¤ è¢«é‚€è¯·äººID: {invitee_id}
ğŸ’µ å¥½å‹å……å€¼é‡‘é¢: ${recharge_amount:.2f}
ğŸ“Š è¿”ä½£æ¯”ä¾‹: {commission_rate*100:.1f}%
ğŸ’ æœ¬æ¬¡è¿”ä½£: ${commission_amount:.2f}

ğŸ’° å¯æç°ä½™é¢: ${new_available:.2f}
âš ï¸ æœ€ä½æç°é‡‘é¢: $1.00

ğŸ“ˆ ç»§ç»­é‚€è¯·å¥½å‹è·å¾—æ›´å¤šè¿”ä½£ï¼
ğŸ’¡ æ¯ä½å¥½å‹å……å€¼éƒ½å¯è·å¾—5%è¿”ä½£

ğŸ”— ç«‹å³æŸ¥çœ‹é‚€è¯·è¯¦æƒ…"""

                        await bot.send_message(
                            chat_id=inviter_id,
                            text=commission_message,
                            parse_mode='Markdown'
                        )
                        logger.info(f"âœ… è¿”ä½£é€šçŸ¥å·²å‘é€ç»™é‚€è¯·è€… {inviter_id}")
                        
                except Exception as notify_error:
                    logger.error(f"å‘é€è¿”ä½£é€šçŸ¥å¤±è´¥: {notify_error}")
                    
            else:
                logger.info(f"â„¹ï¸ æ— é‚€è¯·è¿”ä½£: è¢«é‚€è¯·äºº {invitee_id} - {commission_result['message']}")
                
        except Exception as e:
            logger.error(f"å¤„ç†é‚€è¯·è¿”ä½£å¤±è´¥: {e}")
    
    async def _fetch_current_balance(self):
        """è·å–å½“å‰ä½™é¢"""
        try:
            payload = {
                "jsonrpc": "2.0",
                "id": 1,
                "method": "getTokenAccountBalance",
                "params": [self.token_account]
            }
            
            # åˆ›å»ºSSLä¸Šä¸‹æ–‡ç”¨äºaiohttp
            ssl_context = ssl.create_default_context()
            if CERTIFI_AVAILABLE:
                ssl_context.load_verify_locations(certifi.where())

            connector = aiohttp.TCPConnector(ssl=ssl_context)
            async with aiohttp.ClientSession(connector=connector) as session:
                async with session.post(self.helius_rpc_url, json=payload) as response:
                    if response.status == 200:
                        data = await response.json()
                        if "result" in data and "value" in data["result"]:
                            ui_amount = data["result"]["value"]["uiAmount"]
                            current_balance = float(ui_amount)
                            
                            if current_balance != self.last_balance:
                                logger.info(f"ğŸ’° ä½™é¢åŒæ­¥: {self.last_balance:.4f} â†’ {current_balance:.4f} USDT")
                                
                                DataManager.add_balance_change(
                                    balance_before=self.last_balance,
                                    balance_after=current_balance,
                                    change_amount=current_balance - self.last_balance,
                                    source="rpc_sync",
                                    balance_file=BALANCE_HISTORY_FILE
                                )
                                
                                self.last_balance = current_balance
                            
                            logger.info(f"ğŸ“Š å½“å‰USDTä½™é¢: {current_balance:.4f}")
                    else:
                        logger.error(f"è·å–ä½™é¢å¤±è´¥: HTTP {response.status}")
                        
        except Exception as e:
            logger.error(f"è·å–å½“å‰ä½™é¢å¤±è´¥: {e}")
    
    async def _check_recent_transactions(self):
        """æ£€æŸ¥æœ€è¿‘äº¤æ˜“"""
        try:
            # ç®€åŒ–ç‰ˆæœ¬ï¼Œä¸»è¦ä¾èµ–WebSocketå®æ—¶ç›‘æ§
            logger.debug("ğŸ” æ‰§è¡Œæœ€è¿‘äº¤æ˜“æ£€æŸ¥...")
            
        except Exception as e:
            logger.error(f"æ£€æŸ¥æœ€è¿‘äº¤æ˜“å¤±è´¥: {e}")

# ================== é›†æˆä¿¡å·ç›‘æ§ç³»ç»Ÿ ==================

def extract_base_symbol(symbol: str) -> str:
    """ä»äº¤æ˜“å¯¹ä¸­æå–åŸºç¡€å¸ç§åç§°
    
    Args:
        symbol: äº¤æ˜“å¯¹ç¬¦å·ï¼Œå¦‚ BTCUSDT, BTC/USDT, ETH-USDT ç­‰
        
    Returns:
        åŸºç¡€å¸ç§åç§°ï¼Œå¦‚ BTC, ETH, SOL ç­‰
        
    Examples:
        BTCUSDT â†’ BTC
        BTC/USDT â†’ BTC  
        ETH-USDT â†’ ETH
        SOLUSDT â†’ SOL
    """
    if not symbol:
        return symbol
    
    # ç§»é™¤å¸¸è§çš„äº¤æ˜“å¯¹åç¼€
    symbol = symbol.upper().strip()
    
    # å¤„ç†ä¸åŒæ ¼å¼çš„äº¤æ˜“å¯¹
    for suffix in ['USDT', '/USDT', '-USDT', '_USDT']:
        if symbol.endswith(suffix):
            return symbol[:-len(suffix)]
    
    # å¦‚æœæ²¡æœ‰åŒ¹é…çš„åç¼€ï¼Œè¿”å›åŸå§‹ç¬¦å·
    return symbol

class BinanceFuturesClient:
    """å¸å®‰åˆçº¦APIå®¢æˆ·ç«¯ - åŸºäºå®˜æ–¹APIæ–‡æ¡£v1.0"""
    
    def __init__(self):
        self.base_url = BINANCE_FUTURES_URL
        self.spot_url = BINANCE_SPOT_URL
        
        # ä¼˜åŒ–è¿æ¥æ± é…ç½®
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10,  # è¿æ¥æ± æ•°é‡
            pool_maxsize=20,      # æœ€å¤§è¿æ¥æ•°
            max_retries=0,        # ç¦ç”¨è‡ªåŠ¨é‡è¯•ï¼Œæˆ‘ä»¬è‡ªå·±æ§åˆ¶
            pool_block=False      # éé˜»å¡è¿æ¥æ± 
        )
        
        self.session = requests.Session()
        self.session.mount('https://', adapter)
        self.session.mount('http://', adapter)

        # é…ç½®SSLéªŒè¯
        if CERTIFI_AVAILABLE:
            self.session.verify = certifi.where()
        else:
            self.session.verify = True  # ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è¯ä¹¦
        
        # ä¼˜åŒ–è¯·æ±‚å¤´
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36',
            'Accept': 'application/json',
            'Content-Type': 'application/json',
            'Connection': 'keep-alive'  # ä¿æŒè¿æ¥æ´»è·ƒ
        })
        
        # ç¼“å­˜äº¤æ˜“è§„åˆ™ä¿¡æ¯
        self._exchange_info = None
        self._exchange_info_timestamp = 0
    
    def make_request_with_retry(self, endpoint, params=None, max_retries=2, timeout=8, fast_mode=False):
        """å¸¦é‡è¯•æœºåˆ¶çš„è¯·æ±‚æ–¹æ³• - ä¼˜åŒ–ç‰ˆæœ¬"""
        # å¦‚æœç¦ç”¨äº† Binance APIï¼Œç›´æ¥è¿”å› None
        if BINANCE_API_DISABLED:
            logger.debug(f"Binance API å·²ç¦ç”¨ï¼Œè·³è¿‡è¯·æ±‚: {endpoint}")
            return None
        
        # å¿«é€Ÿæ¨¡å¼ä¸‹ä½¿ç”¨æ›´çŸ­çš„è¶…æ—¶å’Œæ›´å°‘çš„é‡è¯•
        if fast_mode:
            timeout = min(timeout, 5)
            max_retries = 1
            
        for attempt in range(max_retries):
            try:
                # æ ¹æ®endpointé€‰æ‹©æ­£ç¡®çš„base URL
                if endpoint.startswith('/fapi/'):
                    url = f"{self.base_url}{endpoint}"
                elif endpoint.startswith('/futures/'):
                    url = f"{self.base_url}{endpoint}"
                else:
                    url = f"{self.spot_url}{endpoint}"
                
                logger.info(f"è¯·æ±‚ {url} (ç¬¬{attempt+1}æ¬¡) - å‚æ•°: {params} - è¶…æ—¶: {timeout}s")
                response = self.session.get(url, params=params, timeout=timeout)
                
                # æ£€æŸ¥å“åº”çŠ¶æ€
                if response.status_code == 429:
                    # è¯·æ±‚é¢‘ç‡é™åˆ¶ - ä¼˜åŒ–ç­‰å¾…æ—¶é—´
                    retry_after = min(int(response.headers.get('Retry-After', 30)), 30)  # æœ€å¤§ç­‰å¾…30ç§’
                    if fast_mode:
                        retry_after = min(retry_after, 5)  # å¿«é€Ÿæ¨¡å¼æœ€å¤§ç­‰å¾…5ç§’
                    logger.warning(f"è¯·æ±‚é¢‘ç‡é™åˆ¶ï¼Œç­‰å¾… {retry_after} ç§’")
                    time.sleep(retry_after)
                    continue
                
                response.raise_for_status()
                data = response.json()
                
                # éªŒè¯è¿”å›æ•°æ®
                if isinstance(data, dict) and 'code' in data and data['code'] != 200:
                    logger.warning(f"APIè¿”å›é”™è¯¯: {data}")
                    if attempt < max_retries - 1:
                        time.sleep((attempt + 1) * 2)
                        continue
                
                logger.info(f"è¯·æ±‚æˆåŠŸï¼Œè¿”å› {len(data) if isinstance(data, list) else 1} æ¡æ•°æ®")
                return data
                
            except requests.exceptions.RequestException as e:
                logger.warning(f"ç¬¬{attempt+1}æ¬¡è¯·æ±‚å¤±è´¥: {e}")
                if attempt < max_retries - 1:
                    wait_time = min((attempt + 1) * 1, 5)  # å‡å°‘ç­‰å¾…æ—¶é—´ï¼Œæœ€å¤§5ç§’
                    if fast_mode:
                        wait_time = min(wait_time, 2)  # å¿«é€Ÿæ¨¡å¼æœ€å¤§ç­‰å¾…2ç§’
                    logger.info(f"ç­‰å¾… {wait_time} ç§’åé‡è¯•...")
                    time.sleep(wait_time)
                else:
                    logger.error(f"æ‰€æœ‰é‡è¯•å¤±è´¥ï¼Œæœ€ç»ˆé”™è¯¯: {e}")
                    
        return []
    
    def ping(self):
        """æµ‹è¯•æœåŠ¡å™¨è¿é€šæ€§"""
        return self.make_request_with_retry('/fapi/v1/ping')
    
    def get_exchange_info(self, force_refresh=False):
        """è·å–äº¤æ˜“è§„åˆ™å’Œäº¤æ˜“å¯¹ä¿¡æ¯"""
        now = time.time()
        if not force_refresh and self._exchange_info and (now - self._exchange_info_timestamp) < 300:
            return self._exchange_info
        data = self.make_request_with_retry('/fapi/v1/exchangeInfo')
        if data:
            self._exchange_info = data
            self._exchange_info_timestamp = now
        return data
    
    def get_depth(self, symbol, limit=500):
        """è·å–æ·±åº¦ä¿¡æ¯"""
        params = {'symbol': symbol}
        if limit:
            params['limit'] = limit
        return self.make_request_with_retry('/fapi/v1/depth', params)
    
    def get_premium_index(self, symbol=None):
        """è·å–æœ€æ–°æ ‡è®°ä»·æ ¼å’Œèµ„é‡‘è´¹ç‡"""
        params = {}
        if symbol:
            params['symbol'] = symbol
        return self.make_request_with_retry('/fapi/v1/premiumIndex', params)
    
    def get_24hr_ticker(self, symbol=None):
        """è·å–24å°æ—¶ä»·æ ¼å˜åŠ¨æƒ…å†µ"""
        params = {}
        if symbol:
            params['symbol'] = symbol
        return self.make_request_with_retry('/fapi/v1/ticker/24hr', params)
    
    def get_open_interest(self, symbol):
        """è·å–æœªå¹³ä»“åˆçº¦æ•°"""
        params = {'symbol': symbol}
        return self.make_request_with_retry('/fapi/v1/openInterest', params)
    
    def get_open_interest_hist(self, symbol, period, limit=30, start_time=None, end_time=None):
        """è·å–åˆçº¦æŒä»“é‡å†å²"""
        params = {'symbol': symbol, 'period': period, 'limit': limit}
        if start_time:
            params['startTime'] = start_time
        if end_time:
            params['endTime'] = end_time
        return self.make_request_with_retry('/futures/data/openInterestHist', params)
    
    def get_long_short_ratio(self, symbol, period, limit=30, start_time=None, end_time=None):
        """è·å–å¤šç©ºæŒä»“äººæ•°æ¯”"""
        params = {'symbol': symbol, 'period': period, 'limit': limit}
        if start_time:
            params['startTime'] = start_time
        if end_time:
            params['endTime'] = end_time
        return self.make_request_with_retry('/futures/data/globalLongShortAccountRatio', params)
    
    def get_klines(self, symbol, interval, start_time=None, end_time=None, limit=500):
        """è·å–Kçº¿æ•°æ®"""
        params = {'symbol': symbol, 'interval': interval, 'limit': limit}
        if start_time:
            params['startTime'] = start_time
        if end_time:
            params['endTime'] = end_time
        return self.make_request_with_retry('/fapi/v1/klines', params)

class UserRequestHandler:
    """ä¸“é—¨å¤„ç†ç”¨æˆ·è¯·æ±‚çš„è½»é‡çº§å¤„ç†å™¨ - åªè¯»å–ç¼“å­˜ï¼Œä¸è¿›è¡Œç½‘ç»œè¯·æ±‚"""
    
    def __init__(self, card_registry: Optional[RankingRegistry] = None):
        # éœ€è¦å±è”½çš„å¸ç§åˆ—è¡¨
        self.blocked_symbols = {'BNXUSDT', 'ALPACAUSDT'}
        # ç”¨æˆ·çŠ¶æ€ç®¡ç†
        self.user_states = {
            'position_sort': 'desc',
            'position_limit': 10,
            'position_period': '24h',  # æ·»åŠ æŒä»“æ’è¡Œæ—¶é—´å‘¨æœŸ
            'funding_sort': 'desc',
            'funding_limit': 10,
            'funding_sort_type': 'funding_rate',
            'volume_period': '24h',
            'volume_sort': 'desc',
            'volume_limit': 10,
            'volume_market_type': 'futures',  # 'futures', 'spot'
            'liquidation_limit': 10,
            'liquidation_sort': 'desc',
            'liquidation_period': '24h',  # æ·»åŠ æ—¶é—´å‘¨æœŸé€‰æ‹©
            'liquidation_type': 'total',  # æ·»åŠ æ•°æ®ç±»å‹é€‰æ‹©: total/long/short
            'position_market_sort': 'desc',
            'volume_market_sort': 'desc',
            'volume_market_limit': 10,
            'volume_oi_sort': 'desc',
            'volume_oi_limit': 10,
            'position_market_limit': 10,
            'current_ratio_type': 'position_market',  # å½“å‰æ¯”ç‡ç±»å‹
            'money_flow_sort': 'desc',
            'money_flow_limit': 10,
            'money_flow_type': 'absolute',
            'money_flow_market': 'futures',  # 'futures', 'spot', 'option'
            'money_flow_period': '24h',
            'market_depth_limit': 10,
            'market_depth_sort': 'desc',
            'market_depth_sort_type': 'ratio',
            'basic_market_sort_type': 'change',
            'basic_market_period': '24h',
            'basic_market_sort_order': 'desc',
            'basic_market_limit': 10,
            'basic_market_type': 'futures',
            # æ’è¡Œæ¦œå¡ç‰‡åˆ†ç»„ï¼šbasic / futures / advanced
            'ranking_group': 'basic',
        }
        
        # å…è´¹åŠŸèƒ½åˆ—è¡¨ï¼ˆæ”¾åœ¨æœ€ä¸Šé¢ä¸€è¡Œï¼‰
        self.free_features = [
            "basic_market",      # åŸºç¡€è¡Œæƒ…
            "market_sentiment",  # å¸‚åœºæƒ…ç»ª 
            "volume_ranking"     # äº¤æ˜“é‡æ’è¡Œ
        ]
        
        # ä»˜è´¹åŠŸèƒ½åˆ—è¡¨ï¼ˆæ¯æ¬¡1ç§¯åˆ†ï¼‰
        self.paid_features = [
            "position_ranking",       # æŒä»“æ’è¡Œ
            "funding_rate",          # èµ„é‡‘è´¹ç‡
            "liquidation_ranking",   # çˆ†ä»“æ’è¡Œ
            "money_flow",           # èµ„é‡‘æµå‘æ’è¡Œ
            "market_depth"          # å¸‚åœºæ·±åº¦
        ]
        
        # å•æ¬¡æ‰£è´¹æ ‡å‡†
        self.FEATURE_COST = 1     # æ™®é€šåŠŸèƒ½æ¯æ¬¡æ‰£é™¤1ç§¯åˆ†

        # æ’è¡Œæ¦œå¡ç‰‡æ³¨å†Œè¡¨ï¼ˆå¯é€‰ï¼‰
        self.card_registry = card_registry
        self._apply_card_registry_defaults()

    def _apply_card_registry_defaults(self):
        """æ³¨å…¥å¡ç‰‡é»˜è®¤çŠ¶æ€å¹¶åŒæ­¥æƒé™é…ç½®"""
        if not self.card_registry:
            return

        for card in self.card_registry.iter_cards():
            for state_key, state_value in card.iter_default_state():
                self.user_states.setdefault(state_key, state_value)

        self._sync_feature_lists()

    def _sync_feature_lists(self):
        if not self.card_registry:
            return

        free_ids = [card.card_id for card in self.card_registry.iter_cards_by_category("free")]
        paid_ids = [card.card_id for card in self.card_registry.iter_cards_by_category("paid")]
        self._extend_unique(self.free_features, free_ids)
        self._extend_unique(self.paid_features, paid_ids)

    @staticmethod
    def _extend_unique(target_list: List[str], new_items: List[str]) -> None:
        existing = set(target_list)
        for item in new_items:
            if item not in existing:
                target_list.append(item)
                existing.add(item)

    def check_feature_access(self, user_id: int, feature_name: str) -> tuple:
        """
        æ£€æŸ¥ç”¨æˆ·æ˜¯å¦å¯ä»¥è®¿é—®æŸä¸ªåŠŸèƒ½
        
        Args:
            user_id: ç”¨æˆ·ID
            feature_name: åŠŸèƒ½åç§°
            
        Returns:
            tuple: (æ˜¯å¦å¯ä»¥è®¿é—®, é”™è¯¯æ¶ˆæ¯æˆ–None)
        """
        # å…è´¹æ¨¡å¼å…¨å±€æ”¾è¡Œï¼Œé¿å…ä»»ä½•æ‰£è´¹æ ¡éªŒ
        if AI_FREE_MODE:
            return True, None

        # å…è´¹åŠŸèƒ½ç›´æ¥å…è®¸è®¿é—®
        if feature_name in self.free_features:
            return True, None
            
        # ä»˜è´¹åŠŸèƒ½éœ€è¦æ£€æŸ¥ç§¯åˆ†
        if feature_name in self.paid_features:
            user_data = DataManager.get_user_data(user_id)
            current_points = user_data.get("points", 0)
            
            if current_points < self.FEATURE_COST:
                error_msg = f"ğŸ’ ç§¯åˆ†ä¸è¶³ï¼\n\nå½“å‰ç§¯åˆ†: {current_points}\néœ€è¦ç§¯åˆ†: {self.FEATURE_COST}\n\nè¯·å…ˆå……å€¼è·å–ç§¯åˆ†"
                return False, error_msg
            
            return True, None
        
        # æœªçŸ¥åŠŸèƒ½
        return False, "æœªçŸ¥åŠŸèƒ½"
        
    def deduct_feature_cost(self, user_id: int, feature_name: str) -> bool:
        """
        æ‰£é™¤åŠŸèƒ½ä½¿ç”¨è´¹ç”¨
        
        Args:
            user_id: ç”¨æˆ·ID  
            feature_name: åŠŸèƒ½åç§°
            
        Returns:
            bool: æ˜¯å¦æ‰£è´¹æˆåŠŸ
        """
        # å…è´¹æ¨¡å¼å…¨å±€æ”¾è¡Œ
        if AI_FREE_MODE:
            return True

        # å…è´¹åŠŸèƒ½ä¸æ‰£è´¹
        if feature_name in self.free_features:
            return True
            
        # ä»˜è´¹åŠŸèƒ½æ‰£é™¤ç§¯åˆ†
        if feature_name in self.paid_features:
            try:
                user_data = DataManager.get_user_data(user_id)
                current_points = user_data.get("points", 0)
                
                if current_points < self.FEATURE_COST:
                    return False
                
                # æ‰£é™¤ç§¯åˆ†
                new_points = current_points - self.FEATURE_COST
                user_data["points"] = new_points
                DataManager.update_user_data(user_id, user_data)
                
                # è®°å½•ç§¯åˆ†å˜åŠ¨
                DataManager.add_points_history(
                    user_id=user_id,
                    change=-self.FEATURE_COST,
                    reason=f"ä½¿ç”¨åŠŸèƒ½: {feature_name}",
                    balance_after=new_points
                )
                
                logger.info(f"âœ… ç”¨æˆ· {user_id} ä½¿ç”¨åŠŸèƒ½ {feature_name}ï¼Œæ‰£é™¤ {self.FEATURE_COST} ç§¯åˆ†ï¼Œä½™é¢: {new_points}")
                return True
                
            except Exception as e:
                logger.error(f"âŒ æ‰£é™¤ç§¯åˆ†å¤±è´¥: {e}")
                return False
        
        return True
    
    def load_cached_data(self, cache_key, max_age_minutes=10):
        """ä»JSONæ–‡ä»¶åŠ è½½ç¼“å­˜æ•°æ®"""
        try:
            cache_file = os.path.join(DATA_DIR, "cache", f"{cache_key}.json")
            
            if not os.path.exists(cache_file):
                return None, "ç¼“å­˜æ–‡ä»¶ä¸å­˜åœ¨"
            
            cache_data = DataManager.load_json(cache_file)
            if not cache_data or 'data' not in cache_data:
                return None, "ç¼“å­˜æ•°æ®æ ¼å¼æ— æ•ˆ"
            
            # æ£€æŸ¥ç¼“å­˜æ—¶é—´
            cache_timestamp = cache_data.get('timestamp', 0)
            current_time = int(time.time() * 1000)
            age_minutes = (current_time - cache_timestamp) / (1000 * 60)
            
            if age_minutes > max_age_minutes:
                return None, f"ç¼“å­˜æ•°æ®è¿‡æœŸ ({age_minutes:.1f}åˆ†é’Ÿå‰)"
            
            logger.info(f"âœ… ä½¿ç”¨ç¼“å­˜æ•°æ®: {cache_key} ({cache_data.get('total_coins', 0)}ä¸ªå¸ç§, {age_minutes:.1f}åˆ†é’Ÿå‰)")
            return cache_data['data'], None
            
        except Exception as e:
            logger.error(f"âŒ åŠ è½½ç¼“å­˜æ•°æ®å¤±è´¥ {cache_key}: {e}")
            return None, str(e)
    
    
    def load_latest_futures_data(self):
        """CoinGlass æœ¬åœ°æ•°æ®å·²ä¸‹çº¿ï¼Œç›´æ¥è¿”å› Noneã€‚"""
        return None
    
    def get_cached_data_safely(self, key, fallback_message=None):
        """å®‰å…¨è·å–ç¼“å­˜æ•°æ®ï¼›CoinGlass æ•°æ®æºå·²ä¸‹çº¿ç›´æ¥è¿”å›ç©ºã€‚"""
        global cache
        if key.startswith("coinglass_"):
            return [], "â¸ï¸ CoinGlass æ•°æ®æºå·²ä¸‹çº¿ï¼Œç›¸å…³æ¦œå•æš‚ä¸å¯ç”¨"
        if not cache:
            return [], "ğŸ”„ æ•°æ®æ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åé‡è¯•"
        if key in cache:
            cache_age = time.time() - cache[key]['timestamp']
            logger.info(f"è¿”å›å†…å­˜ç¼“å­˜æ•°æ®: {key} (ç¼“å­˜å¹´é¾„: {cache_age:.1f}ç§’)")
            return cache[key]['data'], None
        if fallback_message is None:
            fallback_message = "ğŸ”„ æ•°æ®æ­£åœ¨åå°åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•\nğŸ’¡ æœºå™¨äººåˆšå¯åŠ¨æ—¶éœ€è¦å‡ ç§’é’ŸåŠ è½½æ•°æ®"
        logger.warning(f"ç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®: {key}")
        return [], fallback_message
    
    def dynamic_align_format(self, data_rows, left_align_cols: int = 2, align_override=None):
        """
        æ•°æ®å¯¹é½ï¼šé»˜è®¤å‰ left_align_cols åˆ—å·¦å¯¹é½ï¼Œå…¶ä½™å³å¯¹é½ï¼›æ”¯æŒä¼ å…¥å¯¹é½åˆ—è¡¨ ["L","R",...]
        é€»è¾‘æ¥è‡ªã€Šæ•°æ®å¯¹é½.mdã€‹ï¼Œåˆ—å®½å–å½“å‰æ•°æ®çš„æœ€å¤§é•¿åº¦ï¼Œåˆ—é—´ä»…ä¿ç•™å•ç©ºæ ¼ã€‚
        """
        if not data_rows:
            return "æš‚æ— æ•°æ®"

        col_cnt = max(len(row) for row in data_rows)
        if not all(len(row) == col_cnt for row in data_rows):
            raise ValueError("åˆ—æ•°éœ€ä¸€è‡´ï¼Œå…ˆæ¸…æ´—æˆ–è¡¥é½è¾“å…¥æ•°æ®")

        if align_override:
            align = (list(align_override) + ["R"] * (col_cnt - len(align_override)))[:col_cnt]
        else:
            align = ["L"] * min(left_align_cols, col_cnt) + ["R"] * max(col_cnt - left_align_cols, 0)

        widths = [max(len(str(row[i])) for row in data_rows) for i in range(col_cnt)]

        def fmt(row):
            cells = []
            for idx, cell in enumerate(row):
                cell_str = str(cell)
                cells.append(cell_str.ljust(widths[idx]) if align[idx] == "L" else cell_str.rjust(widths[idx]))
            return " ".join(cells)

        return "\n".join(fmt(r) for r in data_rows)

    def get_current_time_display(self):
        """è·å–å½“å‰æ—¶é—´æ˜¾ç¤º"""
        # åŒ—äº¬æ—¶é—´ UTC+8
        now = datetime.now(timezone(timedelta(hours=8)))
        return {
            'full': format_beijing_time(get_beijing_time().isoformat(), '%Y-%m-%d %H:%M:%S'),
            'time_only': format_beijing_time(get_beijing_time().isoformat(), '%H:%M'),
            'hour_min': f"{now.hour}æ—¶{now.minute}åˆ†"
        }
    
    def get_main_menu_text(self):
        """è·å–ä¸»èœå•æ–‡æœ¬"""
        time_info = self.get_current_time_display()

        return (
            "âš¡ï¸ åœŸå—é‡åŒ–ç³»ç»Ÿ\n\n"
            "ğŸ“Š æ•°æ®é¢æ¿\n"
            "â”œâ”€ åŸºç¡€æ•°æ®ï¼šMACD/RSI/å¸ƒæ—å¸¦/æ”¯æ’‘é˜»åŠ›/èµ„é‡‘æµå‘/\n"
            "â”œâ”€ åˆçº¦æ•°æ®ï¼šOIç³»åˆ—/ä¸»åŠ¨ä¹°å–æ¯”/æŒä»“å˜åŠ¨/æ³¢åŠ¨ç‡/\n"
            "â””â”€ é«˜çº§æ•°æ®ï¼šEMA/Kçº¿å½¢æ€/VPVR/VWAP/æµåŠ¨æ€§/è¶‹åŠ¿/\n\n"
            "ğŸš¨ ä¿¡å·é¢æ¿\n"
            "â”œâ”€ å¼‚å¸¸ç›‘æ§\n"
            "â””â”€ è‡ªé€‰æ¨é€\n\n"
            "ğŸ¤– AIåˆ†æ\n"
            "â”œâ”€ æ·±åº¦æŠ¥å‘Š\n"
            "â””â”€ ç‚¹ä½é€Ÿè§ˆ\n\n"
            "ğŸ’³ æœåŠ¡\n"
            "â”œâ”€ å……å€¼\n"
            "â”œâ”€ ç”¨æˆ·ä¸­å¿ƒ\n"
            "â””â”€ å¸®åŠ©/æŒ‡å¼•\n\n"
            f"â° æ›´æ–°æ—¶é—´ï¼š{time_info['full']}ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰\n"
            "ğŸ‘‡ ç‚¹å‡»æŒ‰é’®å¼€å§‹"
        )

    def get_main_menu_keyboard(self):
        """è·å–ä¸»èœå•é”®ç›˜"""
        keyboard = [
            [
                InlineKeyboardButton("ğŸ“Š æ•°æ®é¢æ¿", callback_data="ranking_menu"),
                InlineKeyboardButton("ğŸš¨ ä¿¡å·", callback_data="aggregated_alerts"),
                # ğŸ¤– AIåˆ†æå ä½ï¼šä»…æç¤ºæœªå¼€å‘
                InlineKeyboardButton("ğŸ¤– AIåˆ†æ", callback_data="start_coin_analysis"),
            ],
            [
                InlineKeyboardButton("ğŸ’³ å……å€¼", callback_data="recharge"),
                InlineKeyboardButton("ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ", callback_data="user_center"),
                InlineKeyboardButton("â„¹ï¸ å¸®åŠ©", callback_data="help"),
            ],
        ]
        return InlineKeyboardMarkup(keyboard)

    # ===== åŸºç¡€è¡Œæƒ…å ä½ï¼Œé¿å…ç¼ºå¤±æ–¹æ³•å¯¼è‡´æŠ¥é”™ =====
    def get_basic_market(self, sort_type='change', period='24h', sort_order='desc', limit=10, market_type='futures'):
        """AIåˆ†æå ä½ï¼Œä¿æŒæ¥å£ä¸æŠ¥é”™"""
        return "ğŸ¤– AIåˆ†æåŠŸèƒ½æš‚æœªå¼€æ”¾ï¼Œè¯·ç¨åé‡è¯•ã€‚"

    def get_basic_market_keyboard(
        self,
        current_sort_type='change',
        current_period='24h',
        current_sort_order='desc',
        current_limit=10,
        current_market_type='futures'
    ):
        """åŸºç¡€è¡Œæƒ…é”®ç›˜ï¼ˆå ä½ç‰ˆï¼‰"""
        return InlineKeyboardMarkup([
            [
                InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"),
                InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="basic_market"),
            ]
        ])

    def _build_card_button(self, card) -> InlineKeyboardButton:
        return InlineKeyboardButton(card.button_text, callback_data=card.entry_callback)

    def _chunk_buttons(self, buttons: List[InlineKeyboardButton], chunk_size: int = 3) -> List[List[InlineKeyboardButton]]:
        rows: List[List[InlineKeyboardButton]] = []
        for idx in range(0, len(buttons), chunk_size):
            rows.append(buttons[idx:idx + chunk_size])
        return rows

    @staticmethod
    def _card_group(card) -> str:
        """æ ¹æ®æ¨¡å—è·¯å¾„åˆ¤å®šå¡ç‰‡æ‰€å±åˆ†ç»„"""
        mod = getattr(card, "__module__", "")
        if ".futures." in mod:
            return "futures"
        if ".advanced." in mod:
            return "advanced"
        if ".basic." in mod:
            return "basic"
        return "basic"  # é»˜è®¤å½’å…¥åŸºç¡€


    def get_ranking_menu_keyboard(self) -> InlineKeyboardMarkup:
        """æ’è¡Œæ¦œäºŒçº§èœå•ï¼šåˆ—å‡ºæ‰€æœ‰å·²æ³¨å†Œçš„æ’è¡Œæ¦œå¡ç‰‡"""
        registry = self.card_registry or ensure_ranking_registry()
        current_group = self.user_states.get("ranking_group", "basic")

        buttons: List[InlineKeyboardButton] = []
        if registry:
            cards = [c for c in registry.iter_cards() if self._card_group(c) == current_group]
            cards.sort(key=lambda c: (c.priority, c.button_text))
            buttons = [self._build_card_button(card) for card in cards]

        rows = self._chunk_buttons(buttons, chunk_size=3) if buttons else []

        # æç¤ºè¡Œ
        rows.append([
            InlineKeyboardButton("ğŸ‘‡æ˜¾ç¤ºç‚¹å‡»ä¸‹æ–¹æŒ‰é’®é€‰æ‹©æ›´å¤šæ•°æ®", callback_data="ranking_menu_nop")
        ])

        # åˆ†ç»„åˆ‡æ¢è¡Œ
        def _group_btn(label: str, value: str) -> InlineKeyboardButton:
            active = current_group == value
            prefix = "âœ…" if active else ""
            return InlineKeyboardButton(f"{prefix}{label}", callback_data=f"ranking_menu_group_{value}")

        rows.append([
            _group_btn("åŸºç¡€æ•°æ®", "basic"),
            _group_btn("åˆçº¦æ•°æ®", "futures"),
            _group_btn("é«˜çº§æ•°æ®", "advanced"),
        ])

        rows.append([
            InlineKeyboardButton("ğŸ  ä¸»èœå•", callback_data="main_menu"),
            InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="ranking_menu"),
        ])
        return InlineKeyboardMarkup(rows)
    
    def get_reply_keyboard(self):
        """è·å–å¸¸é©»å›å¤é”®ç›˜ - æ°¸ä¹…æ˜¾ç¤ºç‰ˆæœ¬"""
        keyboard = [
            [
                KeyboardButton("ğŸ“Š æ•°æ®é¢æ¿"),
                KeyboardButton("ğŸš¨ ä¿¡å·"),
                KeyboardButton("ğŸ¤– AIåˆ†æ")
            ],
            [
                KeyboardButton("ğŸ’³ å……å€¼"),
                KeyboardButton("ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ"),
                KeyboardButton("â„¹ï¸ å¸®åŠ©")
            ]
        ]
        return ReplyKeyboardMarkup(
            keyboard, 
            resize_keyboard=True,           # è‡ªåŠ¨è°ƒæ•´é”®ç›˜å¤§å°
            is_persistent=True,             # é”®ç›˜æŒä¹…åŒ–
            one_time_keyboard=False,        # ä¸æ˜¯ä¸€æ¬¡æ€§é”®ç›˜ï¼Œæ°¸ä¹…æ˜¾ç¤º
            selective=False                 # å¯¹æ‰€æœ‰ç”¨æˆ·æ˜¾ç¤º
        )
    
    async def send_with_persistent_keyboard(self, update, text, parse_mode='Markdown'):
        """
        å‘é€æ¶ˆæ¯å¹¶ä¿æŒå¸¸é©»é”®ç›˜
        Args:
            update: Telegram Updateå¯¹è±¡
            text: è¦å‘é€çš„æ–‡æœ¬å†…å®¹
            parse_mode: è§£ææ¨¡å¼ï¼Œé»˜è®¤Markdown
        """
        reply_keyboard = self.get_reply_keyboard()
        
        # å‘é€å†…å®¹ï¼Œä½¿ç”¨å¸¸é©»é”®ç›˜
        await update.message.reply_text(
            text,
            reply_markup=reply_keyboard,
            parse_mode=parse_mode
        )
    
    def get_position_ranking(self, limit=10, sort_order='desc', period='24h', sort_field: str = "position"):
        """è·å–æŒä»“é‡æ’è¡Œæ¦œ - å§”æ‰˜ç»™TradeCatBotå¤„ç†"""
        global bot
        if bot:
            return bot.get_position_ranking(limit=limit, sort_order=sort_order, period=period, sort_field=sort_field)
        else:
            # å¦‚æœå…¨å±€botä¸å¯ç”¨ï¼Œåˆ›å»ºä¸´æ—¶å®ä¾‹
            try:
                temp_bot = TradeCatBot()
                return temp_bot.get_position_ranking(limit=limit, sort_order=sort_order, period=period, sort_field=sort_field)
            except Exception as e:
                logger.error(f"åˆ›å»ºä¸´æ—¶botå®ä¾‹å¤±è´¥: {e}")
                return "ğŸ”„ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨åé‡è¯•"

    def get_position_ranking_keyboard(self, current_sort='desc', current_limit=10, current_period='24h'):
        """è·å–æŒä»“é‡æ’è¡Œæ¦œé”®ç›˜ - å§”æ‰˜ç»™TradeCatBotå¤„ç†"""
        global bot
        if bot:
            return bot.get_position_ranking_keyboard(
                current_sort=current_sort, 
                current_limit=current_limit, 
                current_period=current_period
            )
        else:
            # å¦‚æœå…¨å±€botä¸å¯ç”¨ï¼Œåˆ›å»ºä¸´æ—¶å®ä¾‹
            try:
                temp_bot = TradeCatBot()
                return temp_bot.get_position_ranking_keyboard(
                    current_sort=current_sort, 
                    current_limit=current_limit, 
                    current_period=current_period
                )
            except Exception as e:
                logger.error(f"åˆ›å»ºä¸´æ—¶botå®ä¾‹å¤±è´¥: {e}")
                # å›é€€é”®ç›˜
                keyboard = [
                    [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                ]
                return InlineKeyboardMarkup(keyboard)
    
    def get_funding_rate_ranking(self, limit=10, sort_order='desc', sort_type='funding_rate'):
        """èµ„é‡‘è´¹ç‡æ’è¡Œå·²ä¸‹çº¿å ä½ã€‚"""
        return "â¸ï¸ èµ„é‡‘è´¹ç‡æ’è¡ŒåŠŸèƒ½å·²ä¸‹çº¿ï¼Œæ•¬è¯·æœŸå¾…æ›¿ä»£æ–¹æ¡ˆã€‚"

    def get_coinglass_futures_data(self):
        """CoinGlass æ•°æ®æºå·²ä¸‹çº¿ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚"""
        return []

    def get_funding_rate_keyboard(self, current_sort='desc', current_limit=10, current_sort_type='funding_rate'):
        """èµ„é‡‘è´¹ç‡æ’è¡Œå·²ä¸‹çº¿çš„å ä½é”®ç›˜ã€‚"""
        return InlineKeyboardMarkup([
            [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
        ])
    
    def get_volume_ranking(self, limit=10, period='24h', sort_order='desc', market_type='futures', sort_field: str = "volume"):
        """è·å–äº¤æ˜“é‡æ’è¡Œæ¦œ"""
        if market_type == 'futures':
            return self.get_futures_volume_ranking(limit, period, sort_order, sort_field=sort_field)
        elif market_type == 'spot':
            return self.get_spot_volume_ranking(limit, period, sort_order, sort_field=sort_field)
        else:
            return "âŒ ä¸æ”¯æŒçš„å¸‚åœºç±»å‹"

    @staticmethod
    def _format_usd_value(value: float) -> str:
        if value >= 1e9:
            return f"${value/1e9:.2f}B"
        if value >= 1e6:
            return f"${value/1e6:.2f}M"
        if value >= 1e3:
            return f"${value/1e3:.2f}K"
        return f"${value:.0f}"

    @staticmethod
    def _format_price_value(price: float) -> str:
        if price >= 1000:
            return f"${price:,.0f}"
        if price >= 1:
            return f"${price:.3f}"
        return f"${price:.6f}"

    @staticmethod
    def _format_flow_value(value: float) -> str:
        prefix = "+" if value >= 0 else ""
        abs_value = abs(value)
        if abs_value >= 1e9:
            return f"{prefix}${abs_value/1e9:.2f}B"
        if abs_value >= 1e6:
            return f"{prefix}${abs_value/1e6:.2f}M"
        if abs_value >= 1e3:
            return f"{prefix}${abs_value/1e3:.2f}K"
        return f"{prefix}${abs_value:.0f}"

    def get_futures_volume_ranking(self, limit=10, period='24h', sort_order='desc', sort_field: str = "volume"):
        """åŸºäºTimescaleDBç”Ÿæˆåˆçº¦äº¤æ˜“é‡æ’è¡Œæ¦œ"""
        allowed_periods = {'5m', '15m', '30m', '1h', '4h', '12h', '24h'}
        if period not in allowed_periods:
            period = '24h'

        service = getattr(self, 'metric_service', None)
        if service is None:
            return "âŒ æ•°æ®æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"

        rows = service.è·å–äº¤æ˜“é‡æ’è¡Œ('futures', period, sort_order, limit * 2)
        processed = []
        for row in rows:
            symbol = row.get('symbol', '')
            if not symbol or symbol in self.blocked_symbols:
                continue
            volume = float(row.get('quote_volume') or 0)
            price = float(row.get('last_close') or 0)
            change_percent = float(row.get('price_change_percent') or 0)
            if volume <= 0 or price <= 0:
                continue
            processed.append((symbol, volume, price, change_percent))

        if not processed:
            return "ğŸ”„ æ­£åœ¨èšåˆåˆçº¦äº¤æ˜“é‡æ•°æ®ï¼Œè¯·ç¨åæŸ¥çœ‹"

        reverse_sort = (sort_order == 'desc')

        def _key(item):
            if sort_field in {"price"}:
                return item[2]
            if sort_field in {"change", "change_percent"}:
                return item[3]
            return item[1]

        processed.sort(key=_key, reverse=reverse_sort)
        selected = processed[:limit]

        data_rows = []
        for idx, (symbol, volume, price, change_percent) in enumerate(selected, 1):
            volume_str = self._format_usd_value(volume)
            price_str = self._format_price_value(price)
            change_str = f"+{change_percent:.2f}%" if change_percent >= 0 else f"{change_percent:.2f}%"
            data_rows.append([f"{idx}.", symbol, volume_str, price_str, change_str])

        aligned_data = self.dynamic_align_format(data_rows)
        time_info = self.get_current_time_display()
        period_display = {
            '5m': '5åˆ†é’Ÿ', '15m': '15åˆ†é’Ÿ', '30m': '30åˆ†é’Ÿ',
            '1h': '1å°æ—¶', '4h': '4å°æ—¶', '12h': '12å°æ—¶', '24h': '24å°æ—¶'
        }
        period_text = period_display.get(period, period)
        sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
        sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"

        return f"""ğŸ“ˆ æˆäº¤é‡æ’è¡Œ - æˆäº¤é¢çƒ­åº¦æ¦œ ğŸ“ˆ
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº {period_text}äº¤æ˜“é‡(USDT)({sort_symbol}) / {sort_text}
æ’å/å¸ç§/{period_text}äº¤æ˜“é‡/ä»·æ ¼/{period_text}æ¶¨è·Œ
```
{aligned_data}
```
ğŸ’¡ æ•°æ®æ¥æºï¼šBinance åˆçº¦ + TimescaleDB
â° æœ€åæ›´æ–° {time_info['full']}"""
    

    def get_spot_volume_ranking(self, limit=10, period='24h', sort_order='desc', sort_field: str = "volume"):
        """åŸºäºTimescaleDBç”Ÿæˆç°è´§äº¤æ˜“é‡æ’è¡Œæ¦œ"""
        allowed_periods = {'5m', '15m', '30m', '1h', '4h', '12h', '24h', '1w'}
        if period not in allowed_periods:
            period = '24h'

        service = getattr(self, 'metric_service', None)
        if service is None:
            return "âŒ æ•°æ®æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"

        rows = service.è·å–äº¤æ˜“é‡æ’è¡Œ('spot', period, sort_order, limit * 2)
        processed = []
        for row in rows:
            symbol = row.get('symbol', '')
            if not symbol or symbol in self.blocked_symbols:
                continue
            volume = float(row.get('quote_volume') or 0)
            price = float(row.get('last_close') or 0)
            change_percent = float(row.get('price_change_percent') or 0)
            if volume <= 0 or price <= 0:
                continue
            processed.append((symbol, volume, price, change_percent))

        if not processed:
            return "ğŸ”„ ç°è´§äº¤æ˜“é‡æ•°æ®æ­£åœ¨èšåˆï¼Œè¯·ç¨åå†è¯•"

        reverse_sort = (sort_order == 'desc')

        def _key(item):
            if sort_field in {"price"}:
                return item[2]
            if sort_field in {"change", "change_percent"}:
                return item[3]
            return item[1]

        processed.sort(key=_key, reverse=reverse_sort)
        selected = processed[:limit]

        data_rows = []
        for idx, (symbol, volume, price, change_percent) in enumerate(selected, 1):
            volume_str = self._format_usd_value(volume)
            price_str = self._format_price_value(price)
            change_str = f"+{change_percent:.2f}%" if change_percent >= 0 else f"{change_percent:.2f}%"
            data_rows.append([f"{idx}.", symbol, volume_str, price_str, change_str])

        aligned_data = self.dynamic_align_format(data_rows)
        time_info = self.get_current_time_display()
        period_display = {
            '5m': '5åˆ†é’Ÿ', '15m': '15åˆ†é’Ÿ', '30m': '30åˆ†é’Ÿ',
            '1h': '1å°æ—¶', '4h': '4å°æ—¶', '12h': '12å°æ—¶', '24h': '24å°æ—¶', '1w': '1å‘¨'
        }
        period_text = period_display.get(period, period)
        sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
        sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"

        return (
            f"""ğŸ’¹ {period_text}ç°è´§äº¤æ˜“é‡æ’è¡Œæ¦œ ğŸ’¹
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº {period_text}äº¤æ˜“é‡(USDT)({sort_symbol}) / {sort_text}
æ’å/å¸ç§/{period_text}äº¤æ˜“é‡/ä»·æ ¼/{period_text}æ¶¨è·Œ
```
{aligned_data}
```
ğŸ’¡ æ•°æ®æ¥æºï¼šBinance ç°è´§ + TimescaleDB
â° æœ€åæ›´æ–° {time_info['full']}"""
        )


    def get_position_market_ratio(self, limit=10, sort_order='desc'):
        """è·å–æŒä»“/å¸‚å€¼æ¯”æ’è¡Œæ¦œ"""
        # è·å–å¸‚åœºç¼“å­˜æ•°æ®
        coinglass_data = self.get_coinglass_cache_data()

        if not coinglass_data:
            return "âŒ è·å–å¸‚åœºæ•°æ®å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        
        # è®¡ç®—æŒä»“/å¸‚å€¼æ¯”
        ratio_data = []
        for coin in coinglass_data:
            symbol = coin.get('symbol', '')
            if not symbol or symbol in self.blocked_symbols:
                continue
            
            # ä½¿ç”¨æŒä»“å¸‚å€¼æ¯”å­—æ®µ
            ratio = coin.get('open_interest_market_cap_ratio', 0)
            if ratio <= 0:
                continue
            
            # è·å–å…¶ä»–æ•°æ®
            current_price = coin.get('current_price', 0)
            market_cap = coin.get('market_cap_usd', 0)
            open_interest = coin.get('open_interest_usd', 0)
            
            ratio_data.append({
                'symbol': symbol,
                'ratio': ratio,
                'current_price': current_price,
                'market_cap': market_cap,
                'open_interest': open_interest
            })
        
        # æ’åº
        reverse_sort = (sort_order == 'desc')
        sorted_data = sorted(ratio_data, key=lambda x: x['ratio'], reverse=reverse_sort)[:limit]
        
        # å‡†å¤‡æ•°æ®è¡Œ
        data_rows = []
        for i, item in enumerate(sorted_data, 1):
            symbol = item['symbol']
            ratio = item['ratio']
            open_interest = item['open_interest']
            
            # æ ¼å¼åŒ–æ¯”ç‡
            ratio_str = f"{ratio:.4f}"
            
            # æ ¼å¼åŒ–æŒä»“é‡
            if open_interest >= 1e9:
                value_str = f"${open_interest/1e9:.2f}B"
            elif open_interest >= 1e6:
                value_str = f"${open_interest/1e6:.2f}M"
            else:
                value_str = f"${open_interest/1e3:.2f}K"
            
            data_rows.append([
                f"{i}.",
                symbol,
                value_str,
                ratio_str
            ])
        
        # åŠ¨æ€å¯¹é½æ ¼å¼åŒ–
        aligned_data = self.dynamic_align_format(data_rows)
        
        time_info = self.get_current_time_display()
        
        # æ’åºæ–¹å¼æ˜¾ç¤º
        sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
        sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"
        
        text = f"""ğŸ“Š æŒä»“/å¸‚å€¼æ¯”æ’è¡Œæ¦œ ğŸ“Š
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº æ¯”ç‡({sort_symbol}) / {sort_text}
æ’å/å¸ç§/æŒä»“é‡/æ¯”ç‡
```
{aligned_data}
```
ğŸ’¡ æŒä»“/å¸‚å€¼æ¯” = æŒä»“é‡ / å¸‚å€¼
ğŸ“Š æ¯”ç‡è¶Šé«˜ï¼Œå¸‚åœºæ æ†è¶Šå¤§ï¼Œé£é™©è¶Šé«˜
âš ï¸ é«˜æ¯”ç‡å¯èƒ½é¢„ç¤ºç€ä»·æ ¼æ³¢åŠ¨åŠ å‰§
â° æœ€åæ›´æ–° {time_info['full']}"""
        
        return text
    
    def get_volume_market_ratio(self, limit=10, sort_order='desc'):
        """è·å–äº¤æ˜“é‡/å¸‚å€¼æ¯”æ’è¡Œæ¦œ"""
        # è·å–å¸‚åœºç¼“å­˜æ•°æ®
        coinglass_data = self.get_coinglass_cache_data()

        if not coinglass_data:
            return "âŒ è·å–å¸‚åœºæ•°æ®å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        
        # è®¡ç®—äº¤æ˜“é‡/å¸‚å€¼æ¯”
        ratio_data = []
        for coin in coinglass_data:
            symbol = coin.get('symbol', '')
            if not symbol or symbol in self.blocked_symbols:
                continue
            
            # è®¡ç®—äº¤æ˜“é‡/å¸‚å€¼æ¯”
            market_cap = coin.get('market_cap_usd', 0)
            open_interest = coin.get('open_interest_usd', 0)
            oi_volume_ratio = coin.get('open_interest_volume_ratio', 0)
            
            if market_cap <= 0 or oi_volume_ratio <= 0:
                continue
            
            # æ ¹æ® æŒä»“é‡/äº¤æ˜“é‡æ¯” è®¡ç®—äº¤æ˜“é‡
            volume_24h = open_interest / oi_volume_ratio if oi_volume_ratio > 0 else 0
            
            if volume_24h <= 0:
                continue
            
            # è®¡ç®—äº¤æ˜“é‡/å¸‚å€¼æ¯”
            ratio = volume_24h / market_cap
            
            # è·å–å…¶ä»–æ•°æ®
            current_price = coin.get('current_price', 0)
            
            ratio_data.append({
                'symbol': symbol,
                'ratio': ratio,
                'current_price': current_price,
                'market_cap': market_cap,
                'volume_24h': volume_24h
            })
        
        # æ’åº
        reverse_sort = (sort_order == 'desc')
        sorted_data = sorted(ratio_data, key=lambda x: x['ratio'], reverse=reverse_sort)[:limit]
        
        # å‡†å¤‡æ•°æ®è¡Œ
        data_rows = []
        for i, item in enumerate(sorted_data, 1):
            symbol = item['symbol']
            ratio = item['ratio']
            volume_24h = item['volume_24h']
            
            # æ ¼å¼åŒ–æ¯”ç‡
            ratio_str = f"{ratio:.4f}"
            
            # æ ¼å¼åŒ–äº¤æ˜“é‡
            if volume_24h >= 1e9:
                value_str = f"${volume_24h/1e9:.2f}B"
            elif volume_24h >= 1e6:
                value_str = f"${volume_24h/1e6:.2f}M"
            else:
                value_str = f"${volume_24h/1e3:.2f}K"
            
            data_rows.append([
                f"{i}.",
                symbol,
                value_str,
                ratio_str
            ])
        
        # åŠ¨æ€å¯¹é½æ ¼å¼åŒ–
        aligned_data = self.dynamic_align_format(data_rows)
        
        time_info = self.get_current_time_display()
        
        # æ’åºæ–¹å¼æ˜¾ç¤º
        sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
        sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"
        
        text = f"""ğŸ“Š äº¤æ˜“é‡/å¸‚å€¼æ¯”æ’è¡Œæ¦œ ğŸ“Š
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº æ¯”ç‡({sort_symbol}) / {sort_text}
æ’å/å¸ç§/äº¤æ˜“é‡/æ¯”ç‡
```
{aligned_data}
```
ğŸ’¡ äº¤æ˜“é‡/å¸‚å€¼æ¯” = 24häº¤æ˜“é‡ / å¸‚å€¼
ğŸ“Š æ¯”ç‡è¶Šé«˜ï¼Œå¸‚åœºæ´»è·ƒåº¦è¶Šé«˜
âš ï¸ é«˜æ¯”ç‡è¡¨ç¤ºå¸‚åœºäº¤æ˜“æ´»è·ƒ
â° æœ€åæ›´æ–° {time_info['full']}"""
        
        return text
    
    def get_volume_oi_ratio(self, limit=10, sort_order='desc'):
        """è·å–äº¤æ˜“é‡/æŒä»“é‡æ¯”æ’è¡Œæ¦œ"""
        # è·å–å¸‚åœºç¼“å­˜æ•°æ®
        coinglass_data = self.get_coinglass_cache_data()

        if not coinglass_data:
            return "âŒ è·å–å¸‚åœºæ•°æ®å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        
        # è®¡ç®—äº¤æ˜“é‡/æŒä»“é‡æ¯”
        ratio_data = []
        for coin in coinglass_data:
            symbol = coin.get('symbol', '')
            if not symbol or symbol in self.blocked_symbols:
                continue
            
            # ä½¿ç”¨æŒä»“äº¤æ˜“é‡æ¯”å­—æ®µçš„å€’æ•°
            oi_volume_ratio = coin.get('open_interest_volume_ratio', 0)
            
            if oi_volume_ratio <= 0:
                continue
            
            # äº¤æ˜“é‡/æŒä»“é‡æ¯” = 1 / (æŒä»“é‡/äº¤æ˜“é‡æ¯”)
            ratio = 1 / oi_volume_ratio
            
            # è·å–å…¶ä»–æ•°æ®
            current_price = coin.get('current_price', 0)
            open_interest = coin.get('open_interest_usd', 0)
            
            # è®¡ç®—äº¤æ˜“é‡
            volume_24h = open_interest / oi_volume_ratio if oi_volume_ratio > 0 else 0
            
            ratio_data.append({
                'symbol': symbol,
                'ratio': ratio,
                'current_price': current_price,
                'open_interest': open_interest,
                'volume_24h': volume_24h
            })
        
        # æ’åº
        reverse_sort = (sort_order == 'desc')
        sorted_data = sorted(ratio_data, key=lambda x: x['ratio'], reverse=reverse_sort)[:limit]
        
        # å‡†å¤‡æ•°æ®è¡Œ
        data_rows = []
        for i, item in enumerate(sorted_data, 1):
            symbol = item['symbol']
            ratio = item['ratio']
            volume_24h = item['volume_24h']
            
            # æ ¼å¼åŒ–æ¯”ç‡
            ratio_str = f"{ratio:.4f}"
            
            # æ ¼å¼åŒ–äº¤æ˜“é‡
            if volume_24h >= 1e9:
                value_str = f"${volume_24h/1e9:.2f}B"
            elif volume_24h >= 1e6:
                value_str = f"${volume_24h/1e6:.2f}M"
            else:
                value_str = f"${volume_24h/1e3:.2f}K"
            
            data_rows.append([
                f"{i}.",
                symbol,
                value_str,
                ratio_str
            ])
        
        # åŠ¨æ€å¯¹é½æ ¼å¼åŒ–
        aligned_data = self.dynamic_align_format(data_rows)
        
        time_info = self.get_current_time_display()
        
        # æ’åºæ–¹å¼æ˜¾ç¤º
        sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
        sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"
        
        text = f"""ğŸ“Š äº¤æ˜“é‡/æŒä»“é‡æ¯”æ’è¡Œæ¦œ ğŸ“Š
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº æ¯”ç‡({sort_symbol}) / {sort_text}
æ’å/å¸ç§/äº¤æ˜“é‡/æ¯”ç‡
```
{aligned_data}
```
ğŸ’¡ äº¤æ˜“é‡/æŒä»“é‡æ¯” = 24häº¤æ˜“é‡ / æŒä»“é‡
ğŸ“Š æ¯”ç‡è¶Šé«˜ï¼Œèµ„é‡‘æµåŠ¨æ€§è¶Šå¼º
âš ï¸ é«˜æ¯”ç‡è¡¨ç¤ºå¸‚åœºæ¢æ‰‹ç‡é«˜
â° æœ€åæ›´æ–° {time_info['full']}"""
        
        return text
    
    def calculate_historical_ratio(self, coin, period):
        """è®¡ç®—å†å²æ—¶é—´ç‚¹çš„æŒä»“/å¸‚å€¼æ¯”"""
        try:
            # è·å–ä»·æ ¼å˜åŒ–å’ŒæŒä»“é‡å˜åŒ–
            price_change_key = f'price_change_percent_{period}'
            oi_change_key = f'open_interest_change_percent_{period}'
            
            price_change = coin.get(price_change_key, 0)
            oi_change = coin.get(oi_change_key, 0)
            
            # å½“å‰å€¼
            current_price = coin.get('current_price', 0)
            current_market_cap = coin.get('market_cap_usd', 0)
            current_oi = coin.get('open_interest_usd', 0)
            
            if current_price <= 0 or current_market_cap <= 0 or current_oi <= 0:
                return None
            
            # è®¡ç®—å†å²ä»·æ ¼å’ŒæŒä»“é‡
            historical_price = current_price / (1 + price_change / 100)
            historical_oi = current_oi / (1 + oi_change / 100)
            
            # è®¡ç®—å†å²å¸‚å€¼ï¼ˆå‡è®¾æµé€šé‡ä¸å˜ï¼‰
            historical_market_cap = current_market_cap * (historical_price / current_price)
            
            # è®¡ç®—å†å²æ¯”ç‡
            if historical_market_cap > 0:
                historical_ratio = historical_oi / historical_market_cap
                return historical_ratio
            
            return None
            
        except Exception as e:
            return None
    
    def get_coinglass_cache_data(self):
        """CoinGlass ç¼“å­˜å·²ä¸‹çº¿ï¼Œè¿”å›ç©ºåˆ—è¡¨ã€‚"""
        return []
    
    def get_unified_ratio_keyboard(self, current_sort='desc', current_limit=10, current_ratio_type='position_market'):
        """è·å–ç»Ÿä¸€çš„æ¯”ç‡é”®ç›˜å¸ƒå±€"""
        # ç¬¬ä¸€è¡Œï¼šæ¯”ç‡ç±»å‹æŒ‰é’®
        ratio_buttons = [
            InlineKeyboardButton("âœ…æŒä»“/å¸‚å€¼" if current_ratio_type == 'position_market' else "æŒä»“/å¸‚å€¼", callback_data="ratio_type_position_market"),
            InlineKeyboardButton("âœ…äº¤æ˜“é‡/å¸‚å€¼" if current_ratio_type == 'volume_market' else "äº¤æ˜“é‡/å¸‚å€¼", callback_data="ratio_type_volume_market"),
            InlineKeyboardButton("âœ…äº¤æ˜“é‡/æŒä»“" if current_ratio_type == 'volume_oi' else "äº¤æ˜“é‡/æŒä»“", callback_data="ratio_type_volume_oi")
        ]
        
        # ç¬¬äºŒè¡Œï¼šæ’åºæŒ‰é’®å’Œæ•°é‡æŒ‰é’®åˆå¹¶ä¸ºä¸€è¡Œ
        sort_limit_buttons = []
        
        # æ’åºæŒ‰é’®
        if current_sort == 'desc':
            sort_limit_buttons.append(InlineKeyboardButton("âœ…é™åº", callback_data="unified_ratio_sort_desc"))
            sort_limit_buttons.append(InlineKeyboardButton("å‡åº", callback_data="unified_ratio_sort_asc"))
        else:
            sort_limit_buttons.append(InlineKeyboardButton("é™åº", callback_data="unified_ratio_sort_desc"))
            sort_limit_buttons.append(InlineKeyboardButton("âœ…å‡åº", callback_data="unified_ratio_sort_asc"))
        
        # æ•°é‡æŒ‰é’®
        limits = [10, 20, 30]
        for limit_val in limits:
            if limit_val == current_limit:
                sort_limit_buttons.append(InlineKeyboardButton(f"âœ…{limit_val}æ¡", callback_data=f"unified_ratio_{limit_val}"))
            else:
                sort_limit_buttons.append(InlineKeyboardButton(f"{limit_val}æ¡", callback_data=f"unified_ratio_{limit_val}"))
        
        # ç¬¬ä¸‰è¡Œï¼šè¿”å›å’Œåˆ·æ–°æŒ‰é’®
        control_buttons = [
            InlineKeyboardButton("ğŸ”™ è¿”å›ä¸»èœå•", callback_data="main_menu"),
            InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="unified_ratio_refresh")
        ]
        
        keyboard = [
            ratio_buttons,
            sort_limit_buttons,
            control_buttons
        ]
        
        return InlineKeyboardMarkup(keyboard)

    def get_position_market_ratio_keyboard(self, current_sort='desc', current_limit=10):
        """è·å–æŒä»“/å¸‚å€¼æ¯”é”®ç›˜ - å…¼å®¹æ€§ä¿æŒ"""
        return self.get_unified_ratio_keyboard(current_sort, current_limit, 'position_market')
    
    def get_volume_market_ratio_keyboard(self, current_sort='desc', current_limit=10):
        """è·å–äº¤æ˜“é‡/å¸‚å€¼æ¯”é”®ç›˜ - å…¼å®¹æ€§ä¿æŒ"""
        return self.get_unified_ratio_keyboard(current_sort, current_limit, 'volume_market')
    
    def get_volume_oi_ratio_keyboard(self, current_sort='desc', current_limit=10):
        """è·å–äº¤æ˜“é‡/æŒä»“é‡æ¯”é”®ç›˜ - å…¼å®¹æ€§ä¿æŒ"""
        return self.get_unified_ratio_keyboard(current_sort, current_limit, 'volume_oi')
    
    def get_money_flow(self, limit=10, period='24h', sort_order='desc', flow_type='absolute', market='futures'):
        """è·å–èµ„é‡‘æµå‘æ’è¡Œæ¦œ - æ”¯æŒåˆçº¦å’Œç°è´§æ•°æ®"""
        if market == 'spot':
            # ç°è´§æ•°æ®æ”¯æŒå¤šæ—¶é—´å‘¨æœŸ
            return self.get_spot_money_flow(limit, sort_order, flow_type, period)
        else:
            # åˆçº¦æ•°æ®ï¼ˆåŸæœ‰é€»è¾‘ï¼‰
            return self.get_futures_money_flow(limit, period, sort_order, flow_type)
    
    def get_option_money_flow(self, limit=10, sort_order='desc', flow_type='absolute'):
        """è·å–æœŸæƒèµ„é‡‘æµå‘æ’è¡Œæ¦œ"""
        option_data, error = self.get_cached_data_safely('coinglass_option_flow_data')
        
        if error:
            return "âŒ æœŸæƒæ•°æ®è·å–å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•"
        
        if not option_data:
            return "ğŸ”„ æœŸæƒæ•°æ®æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•"
        
        # è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯
        cache_info = ""
        try:
            cache_file = os.path.join(DATA_DIR, "cache", "coinglass_option_flow_data.json")
            if os.path.exists(cache_file):
                cache_data = DataManager.load_json(cache_file)
                if cache_data and 'last_update' in cache_data:
                    cache_info = f"\nğŸ“„ ç¼“å­˜æ—¶é—´: {cache_data['last_update']}"
        except:
            pass
        
        # æ ¹æ®æµå‘ç±»å‹è¿‡æ»¤å’Œæ’åºæ•°æ®
        if flow_type == 'inflow':
            # åªæ˜¾ç¤ºèµ„é‡‘æµå…¥çš„å¸ç§
            filtered_data = [item for item in option_data if item['net_flow_usd'] > 0]
            sorted_data = sorted(filtered_data, key=lambda x: x['net_flow_usd'], reverse=True)[:limit]
        elif flow_type == 'outflow':
            # åªæ˜¾ç¤ºèµ„é‡‘æµå‡ºçš„å¸ç§
            filtered_data = [item for item in option_data if item['net_flow_usd'] < 0]
            sorted_data = sorted(filtered_data, key=lambda x: x['net_flow_usd'], reverse=False)[:limit]
        else:  # flow_type == 'absolute'
            # æ˜¾ç¤ºæ‰€æœ‰å¸ç§ï¼ŒæŒ‰ç»å¯¹å€¼æ’åº
            reverse_sort = (sort_order == 'desc')
            sorted_data = sorted(option_data, key=lambda x: abs(x['net_flow_usd']), reverse=reverse_sort)[:limit]
        
        # å‡†å¤‡æ•°æ®è¡Œ
        data_rows = []
        for i, item in enumerate(sorted_data, 1):
            symbol = item['symbol'].replace('USDT', '')
            net_flow = item['net_flow_usd']
            oi_change = item['oi_change_24h']
            volume_change = item['volume_change_24h']
            
            # æ ¼å¼åŒ–å‡€æµé‡
            if abs(net_flow) >= 1e9:
                flow_str = f"+{net_flow/1e9:.2f}B" if net_flow >= 0 else f"{net_flow/1e9:.2f}B"
            elif abs(net_flow) >= 1e6:
                flow_str = f"+{net_flow/1e6:.2f}M" if net_flow >= 0 else f"{net_flow/1e6:.2f}M"
            elif abs(net_flow) >= 1e3:
                flow_str = f"+{net_flow/1e3:.2f}K" if net_flow >= 0 else f"{net_flow/1e3:.2f}K"
            else:
                flow_str = f"+{net_flow:.0f}" if net_flow >= 0 else f"{net_flow:.0f}"
            
            # æŒä»“é‡å˜åŒ–
            oi_str = f"+{oi_change:.2f}%" if oi_change >= 0 else f"{oi_change:.2f}%"
            
            # æˆäº¤é‡å˜åŒ–
            vol_str = f"+{volume_change:.1f}%" if volume_change >= 0 else f"{volume_change:.1f}%"
            
            data_rows.append([
                f"{i}.",
                symbol,
                flow_str,
                oi_str,
                vol_str
            ])
        
        # åŠ¨æ€å¯¹é½æ ¼å¼åŒ–
        aligned_data = self.dynamic_align_format(data_rows)
        
        time_info = self.get_current_time_display()
        
        # æ ¹æ®æµå‘ç±»å‹è®¾ç½®æ ‡é¢˜å’Œè¯´æ˜
        if flow_type == 'inflow':
            title = "ğŸ’° æœŸæƒèµ„é‡‘æµå…¥æ’è¡Œæ¦œ ğŸ’°"
            sort_desc = "èµ„é‡‘æµå…¥å¼ºåº¦(ğŸ”½)"
            type_desc = "ğŸŸ¢ ä»…æ˜¾ç¤ºèµ„é‡‘æµå…¥çš„å¸ç§"
            flow_desc = "ğŸ’¡ æ‰€æœ‰æ•°å€¼å‡ä¸ºæ­£å€¼ï¼Œè¡¨ç¤ºèµ„é‡‘å‡€æµå…¥"
        elif flow_type == 'outflow':
            title = "ğŸ’° æœŸæƒèµ„é‡‘æµå‡ºæ’è¡Œæ¦œ ğŸ’°"
            sort_desc = "èµ„é‡‘æµå‡ºå¼ºåº¦(ğŸ”¼)"
            type_desc = "ğŸ”´ ä»…æ˜¾ç¤ºèµ„é‡‘æµå‡ºçš„å¸ç§"
            flow_desc = "ğŸ’¡ æ‰€æœ‰æ•°å€¼å‡ä¸ºè´Ÿå€¼ï¼Œè¡¨ç¤ºèµ„é‡‘å‡€æµå‡º"
        else:  # flow_type == 'absolute'
            title = "ğŸ’° æœŸæƒèµ„é‡‘æµå‘æ’è¡Œæ¦œ ğŸ’°"
            sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
            sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"
            sort_desc = f"èµ„é‡‘æµå‘å¼ºåº¦({sort_symbol}) / {sort_text}"
            type_desc = "ğŸ“Š æŒ‰ç»å¯¹å€¼æ’åºï¼Œæ˜¾ç¤ºæ‰€æœ‰å¸ç§"
            flow_desc = "ğŸ’¡ +è¡¨ç¤ºèµ„é‡‘æµå…¥ï¼Œ-è¡¨ç¤ºæµå‡º"
        
        text = f"""{title}
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº {sort_desc}
æ’å/å¸ç§/å‡€æµé‡/æŒä»“å˜åŒ–/æˆäº¤é‡å˜åŒ–
```
{aligned_data}
```
{type_desc}
{flow_desc}
ğŸ’¡ å‡€æµé‡ = æŒä»“é‡å˜åŒ–(70%) + æˆäº¤é‡å˜åŒ–(30%)
ğŸ“ˆ æŒä»“é‡å¢åŠ é€šå¸¸è¡¨ç¤ºçœ‹æ¶¨/çœ‹è·Œæƒ…ç»ªå¢å¼º
â° æœ€åæ›´æ–° {time_info['full']}{cache_info}"""
        
        return text
    


    def get_futures_money_flow(self, limit=10, period='24h', sort_order='desc', flow_type='absolute'):
        """åŸºäºTimescaleDBçš„åˆçº¦èµ„é‡‘æµå‘æ’è¡Œæ¦œï¼ˆCVDï¼‰"""
        allowed_periods = {'5m', '15m', '30m', '1h', '4h', '12h', '24h'}
        if period not in allowed_periods:
            period = '24h'

        service = getattr(self, 'metric_service', None)
        if service is None:
            return "âŒ æ•°æ®æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"

        raw_rows = service.è·å–èµ„é‡‘æµæ’è¡Œ('futures', period, limit * 4, flow_type, sort_order)
        rows = []
        for row in raw_rows:
            symbol = row.get('symbol', '')
            if not symbol or symbol in self.blocked_symbols:
                continue
            net_flow = float(row.get('net_quote_flow') or 0)
            buy_quote = float(row.get('buy_quote') or 0)
            sell_quote = max(float(row.get('sell_quote') or 0), 0.0)
            quote_volume = float(row.get('quote_volume') or 0)
            change_percent = float(row.get('price_change_percent') or 0)
            rows.append((symbol, net_flow, buy_quote, sell_quote, quote_volume, change_percent))

        if not rows:
            return "ğŸ”„ æ­£åœ¨èšåˆåˆçº¦CVDï¼Œè¯·ç¨åæŸ¥çœ‹"

        def _filter_by_type(data):
            if flow_type == 'inflow':
                return [item for item in data if item[1] > 0]
            if flow_type == 'outflow':
                return [item for item in data if item[1] < 0]
            return data

        filtered = _filter_by_type(rows)
        if not filtered:
            return "ğŸ“­ å½“å‰å‘¨æœŸæš‚æ— åŒ¹é…çš„èµ„é‡‘æµå‘æ•°æ®"

        if flow_type == 'volume':
            reverse_sort = (sort_order == 'desc')
            filtered.sort(key=lambda item: item[4], reverse=reverse_sort)
        else:
            reverse_sort = (sort_order == 'desc')
            filtered.sort(key=lambda item: abs(item[1]) if flow_type == 'absolute' else item[1], reverse=reverse_sort)

        selected = filtered[:limit]
        data_rows = []
        for idx, (symbol, net_flow, buy_quote, sell_quote, _, change_percent) in enumerate(selected, 1):
            flow_str = self._format_flow_value(net_flow)
            if sell_quote <= 0:
                ratio_str = "âˆ" if buy_quote > 0 else "--"
            else:
                ratio_str = f"{buy_quote / sell_quote:.2f}"
            change_str = f"+{change_percent:.2f}%" if change_percent >= 0 else f"{change_percent:.2f}%"
            data_rows.append([f"{idx}.", symbol, flow_str, ratio_str, change_str])

        aligned_data = self.dynamic_align_format(data_rows)
        time_info = self.get_current_time_display()
        period_names = {
            '5m': '5åˆ†é’Ÿ', '15m': '15åˆ†é’Ÿ', '30m': '30åˆ†é’Ÿ', '1h': '1å°æ—¶',
            '4h': '4å°æ—¶', '12h': '12å°æ—¶', '24h': '24å°æ—¶'
        }
        period_name = period_names.get(period, period)
        sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
        sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"

        if flow_type == 'inflow':
            title = f"ğŸŸ¢ åˆçº¦å¤šå¤´èµ„é‡‘æµå…¥({period_name})"
            desc = "ä»…ä¿ç•™å¤šå¤´å ä¼˜ï¼ŒæŒ‰å‡€æµé™åº"
        elif flow_type == 'outflow':
            title = f"ğŸ”´ åˆçº¦ç©ºå¤´èµ„é‡‘æµå‡º({period_name})"
            desc = "ä»…ä¿ç•™ç©ºå¤´å ä¼˜ï¼ŒæŒ‰å‡€æµå‡åº"
        elif flow_type == 'volume':
            title = f"ğŸ“¦ åˆçº¦äº¤æ˜“é‡æ’è¡Œ({period_name})"
            desc = "æŒ‰è¯¥å‘¨æœŸæˆäº¤é¢æ’åº"
        else:
            title = f"ğŸ’§ èµ„é‡‘æµå‘æ’è¡Œ - åˆçº¦({period_name})"
            desc = f"æŒ‰ |CVD| ({sort_symbol}) / {sort_text}"

        return (
            f"""{title}
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº {desc}
æ’å/å¸ç§/å‡€æµ(CVD)/ä¹°å–æ¯”/æ¶¨è·Œå¹…
```
{aligned_data}
```
ğŸ’¡ å‡€æµ(CVD)=Takerä¹°å…¥ - Takerå–å‡ºï¼Œæ•°æ®æ¥è‡ª Binance åˆçº¦
â° æœ€åæ›´æ–° {time_info['full']}"""
        )

    def get_spot_money_flow(self, limit=10, period='24h', sort_order='desc', flow_type='absolute'):
        """åŸºäºTimescaleDBçš„ç°è´§èµ„é‡‘æµå‘æ’è¡Œæ¦œ"""
        allowed_periods = {'5m', '15m', '30m', '1h', '4h', '12h', '24h', '1w'}
        if period not in allowed_periods:
            period = '24h'

        service = getattr(self, 'metric_service', None)
        if service is None:
            return "âŒ æ•°æ®æœåŠ¡ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"

        raw_rows = service.è·å–èµ„é‡‘æµæ’è¡Œ('spot', period, limit * 4, flow_type, sort_order)
        rows = []
        for row in raw_rows:
            symbol = row.get('symbol', '')
            if not symbol or symbol in self.blocked_symbols:
                continue
            net_flow = float(row.get('net_quote_flow') or 0)
            buy_quote = float(row.get('buy_quote') or 0)
            sell_quote = max(float(row.get('sell_quote') or 0), 0.0)
            quote_volume = float(row.get('quote_volume') or 0)
            change_percent = float(row.get('price_change_percent') or 0)
            rows.append((symbol, net_flow, buy_quote, sell_quote, quote_volume, change_percent))

        if not rows:
            return "ğŸ”„ æ­£åœ¨èšåˆç°è´§CVDï¼Œè¯·ç¨åæŸ¥çœ‹"

        def _filter_by_type(data):
            if flow_type == 'inflow':
                return [item for item in data if item[1] > 0]
            if flow_type == 'outflow':
                return [item for item in data if item[1] < 0]
            return data

        filtered = _filter_by_type(rows)
        if not filtered:
            return "ğŸ“­ å½“å‰å‘¨æœŸæš‚æ— åŒ¹é…çš„ç°è´§èµ„é‡‘æµå‘"

        if flow_type == 'volume':
            reverse_sort = (sort_order == 'desc')
            filtered.sort(key=lambda item: item[4], reverse=reverse_sort)
        else:
            reverse_sort = (sort_order == 'desc')
            filtered.sort(key=lambda item: abs(item[1]) if flow_type == 'absolute' else item[1], reverse=reverse_sort)

        selected = filtered[:limit]
        data_rows = []
        for idx, (symbol, net_flow, buy_quote, sell_quote, _, change_percent) in enumerate(selected, 1):
            flow_str = self._format_flow_value(net_flow)
            if sell_quote <= 0:
                ratio_str = "âˆ" if buy_quote > 0 else "--"
            else:
                ratio_str = f"{buy_quote / sell_quote:.2f}"
            change_str = f"+{change_percent:.2f}%" if change_percent >= 0 else f"{change_percent:.2f}%"
            data_rows.append([f"{idx}.", symbol, flow_str, ratio_str, change_str])

        aligned_data = self.dynamic_align_format(data_rows)
        time_info = self.get_current_time_display()
        period_names = {
            '5m': '5åˆ†é’Ÿ', '15m': '15åˆ†é’Ÿ', '30m': '30åˆ†é’Ÿ', '1h': '1å°æ—¶',
            '4h': '4å°æ—¶', '12h': '12å°æ—¶', '24h': '24å°æ—¶', '1w': '1å‘¨'
        }
        period_name = period_names.get(period, period)
        sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
        sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"

        if flow_type == 'inflow':
            title = f"ğŸŸ¢ ç°è´§å¤šå¤´èµ„é‡‘æµå…¥({period_name})"
            desc = "ä»…ä¿ç•™å¤šå¤´å ä¼˜"
        elif flow_type == 'outflow':
            title = f"ğŸ”´ ç°è´§ç©ºå¤´èµ„é‡‘æµå‡º({period_name})"
            desc = "ä»…ä¿ç•™ç©ºå¤´å ä¼˜"
        elif flow_type == 'volume':
            title = f"ğŸ“¦ ç°è´§äº¤æ˜“é‡æ’è¡Œ({period_name})"
            desc = "æŒ‰æˆäº¤é¢æ’åº"
        else:
            title = f"ğŸ’§ ç°è´§èµ„é‡‘æµå‘æ’è¡Œ({period_name})"
            desc = f"æŒ‰ |CVD| ({sort_symbol}) / {sort_text}"

        return (
            f"""{title}
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº {desc}
æ’å/å¸ç§/å‡€æµ(CVD)/ä¹°å–æ¯”/æ¶¨è·Œå¹…
```
{aligned_data}
```
ğŸ’¡ å‡€æµ(CVD)=Takerä¹°å…¥ - Takerå–å‡ºï¼Œæ•°æ®æ¥è‡ª Binance ç°è´§
â° æœ€åæ›´æ–° {time_info['full']}"""
        )


    def get_money_flow_keyboard(self, current_period='24h', current_sort='desc', current_limit=10, current_flow_type='absolute', current_market='futures'):
        """è·å–èµ„é‡‘æµå‘é”®ç›˜"""
        # ç¬¬ä¸€è¡Œï¼šå¸‚åœºç±»å‹é€‰æ‹©æŒ‰é’®ï¼ˆç°è´§/åˆçº¦ï¼‰
        market_buttons = []
        if current_market == 'spot':
            market_buttons.append(InlineKeyboardButton("âœ…ç°è´§", callback_data="money_flow_market_spot"))
            market_buttons.append(InlineKeyboardButton("åˆçº¦", callback_data="money_flow_market_futures"))
        else:  # current_market == 'futures' 
            market_buttons.append(InlineKeyboardButton("ç°è´§", callback_data="money_flow_market_spot"))
            market_buttons.append(InlineKeyboardButton("âœ…åˆçº¦", callback_data="money_flow_market_futures"))
        
        # ç¬¬äºŒè¡Œï¼šæµå‘ç±»å‹é€‰æ‹©æŒ‰é’®
        flow_type_buttons = []
        if current_market == 'spot':
            # ç°è´§æ”¯æŒç»å¯¹å€¼ã€æµå…¥ã€æµå‡ºã€å¸‚å€¼
            if current_flow_type == 'absolute':
                flow_type_buttons.append(InlineKeyboardButton("âœ…ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("å¸‚å€¼", callback_data="money_flow_type_volume"))
            elif current_flow_type == 'inflow':
                flow_type_buttons.append(InlineKeyboardButton("ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("âœ…æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("å¸‚å€¼", callback_data="money_flow_type_volume"))
            elif current_flow_type == 'outflow':
                flow_type_buttons.append(InlineKeyboardButton("ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("âœ…æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("å¸‚å€¼", callback_data="money_flow_type_volume"))
            elif current_flow_type == 'volume':
                flow_type_buttons.append(InlineKeyboardButton("ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("âœ…å¸‚å€¼", callback_data="money_flow_type_volume"))
            else:  # å¦‚æœæ˜¯å…¶ä»–ç±»å‹ï¼Œé‡ç½®ä¸ºabsolute
                flow_type_buttons.append(InlineKeyboardButton("âœ…ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("å¸‚å€¼", callback_data="money_flow_type_volume"))
        else:
            # åˆçº¦æ”¯æŒæ‰€æœ‰ç±»å‹
            if current_flow_type == 'absolute':
                flow_type_buttons.append(InlineKeyboardButton("âœ…ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("å¸‚å€¼", callback_data="money_flow_type_volume"))
            elif current_flow_type == 'inflow':
                flow_type_buttons.append(InlineKeyboardButton("ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("âœ…æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("å¸‚å€¼", callback_data="money_flow_type_volume"))
            elif current_flow_type == 'outflow':
                flow_type_buttons.append(InlineKeyboardButton("ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("âœ…æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("å¸‚å€¼", callback_data="money_flow_type_volume"))
            else:  # current_flow_type == 'volume'
                flow_type_buttons.append(InlineKeyboardButton("ç»å¯¹å€¼", callback_data="money_flow_type_absolute"))
                flow_type_buttons.append(InlineKeyboardButton("æµå…¥", callback_data="money_flow_type_inflow"))
                flow_type_buttons.append(InlineKeyboardButton("æµå‡º", callback_data="money_flow_type_outflow"))
                flow_type_buttons.append(InlineKeyboardButton("âœ…å¸‚å€¼", callback_data="money_flow_type_volume"))
        
        # ç¬¬ä¸‰è¡Œï¼šæ’åºæŒ‰é’®ï¼ˆåœ¨ç»å¯¹å€¼å’Œå¸‚å€¼æ¨¡å¼ä¸‹æ˜¾ç¤ºï¼‰
        sort_buttons = []
        if current_flow_type in ['absolute', 'volume']:
            if current_sort == 'desc':
                sort_buttons.append(InlineKeyboardButton("âœ…é™åº", callback_data="money_flow_sort_desc"))
                sort_buttons.append(InlineKeyboardButton("å‡åº", callback_data="money_flow_sort_asc"))
            else:
                sort_buttons.append(InlineKeyboardButton("é™åº", callback_data="money_flow_sort_desc"))
                sort_buttons.append(InlineKeyboardButton("âœ…å‡åº", callback_data="money_flow_sort_asc"))
        
        # ç¬¬ä¸‰è¡Œï¼šæ—¶é—´å‘¨æœŸæŒ‰é’®ï¼ˆç°è´§å’Œåˆçº¦æ¨¡å¼éƒ½æ˜¾ç¤ºï¼‰
        period_buttons = []
        if current_market in ['spot', 'futures']:
            if current_market == 'spot':
                # ç°è´§æ”¯æŒæ‰€æœ‰æ—¶é—´å‘¨æœŸ
                periods = [
                    ('5m', '5åˆ†'),
                    ('15m', '15åˆ†'),
                    ('30m', '30åˆ†'),
                    ('1h', '1æ—¶'),
                    ('4h', '4æ—¶'),
                    ('12h', '12æ—¶'),
                    ('24h', '24æ—¶'),
                    ('1w', '1å‘¨')
                ]
            else:  # futures
                # åˆçº¦æ”¯æŒä¸»è¦æ—¶é—´å‘¨æœŸ
                periods = [
                    ('5m', '5åˆ†'),
                    ('15m', '15åˆ†'),
                    ('30m', '30åˆ†'),
                    ('1h', '1æ—¶'),
                    ('4h', '4æ—¶'),
                    ('12h', '12æ—¶'),
                    ('24h', '24æ—¶')
                ]
            
            for period_val, period_name in periods:
                if period_val == current_period:
                    period_buttons.append(InlineKeyboardButton(f"âœ…{period_name}", callback_data=f"money_flow_period_{period_val}"))
                else:
                    period_buttons.append(InlineKeyboardButton(f"{period_name}", callback_data=f"money_flow_period_{period_val}"))
        
        # æ’åºå’Œæ•°é‡æŒ‰é’®åˆå¹¶ä¸ºä¸€è¡Œ
        sort_limit_buttons = []
        
        # æ’åºæŒ‰é’®ï¼ˆåœ¨ç»å¯¹å€¼å’Œå¸‚å€¼æ¨¡å¼ä¸‹æ˜¾ç¤ºï¼‰
        if current_flow_type in ['absolute', 'volume']:
            if current_sort == 'desc':
                sort_limit_buttons.append(InlineKeyboardButton("âœ…é™åº", callback_data="money_flow_sort_desc"))
                sort_limit_buttons.append(InlineKeyboardButton("å‡åº", callback_data="money_flow_sort_asc"))
            else:
                sort_limit_buttons.append(InlineKeyboardButton("é™åº", callback_data="money_flow_sort_desc"))
                sort_limit_buttons.append(InlineKeyboardButton("âœ…å‡åº", callback_data="money_flow_sort_asc"))
        
        # æ•°é‡æŒ‰é’®
        limits = [10, 20, 30]
        for limit_val in limits:
            if limit_val == current_limit:
                sort_limit_buttons.append(InlineKeyboardButton(f"âœ…{limit_val}æ¡", callback_data=f"money_flow_{limit_val}"))
            else:
                sort_limit_buttons.append(InlineKeyboardButton(f"{limit_val}æ¡", callback_data=f"money_flow_{limit_val}"))
        
        # æ„å»ºé”®ç›˜å¸ƒå±€
        keyboard = [
            # ç¬¬ä¸€è¡Œï¼šå¸‚åœºç±»å‹é€‰æ‹©
            market_buttons,
            # ç¬¬äºŒè¡Œï¼šæµå‘ç±»å‹é€‰æ‹©
            flow_type_buttons,
        ]
        
        # ç¬¬ä¸‰è¡Œï¼šæ—¶é—´å‘¨æœŸé€‰æ‹©ï¼ˆä»…åœ¨ç°è´§æ¨¡å¼ä¸‹æ˜¾ç¤ºï¼‰
        if period_buttons:
            # åˆ†æˆä¸¤è¡Œæ˜¾ç¤ºï¼Œæ¯è¡Œ4ä¸ªæŒ‰é’®
            keyboard.append(period_buttons[:4])  # 5åˆ†ã€15åˆ†ã€30åˆ†ã€1æ—¶
            keyboard.append(period_buttons[4:])  # 4æ—¶ã€12æ—¶ã€24æ—¶ã€1å‘¨
        
        # æ’åºå’Œæ•°é‡é€‰æ‹©åˆå¹¶ä¸ºä¸€è¡Œ
        if sort_limit_buttons:
            keyboard.append(sort_limit_buttons)
        
        # ç¬¬å››è¡Œï¼šåŠŸèƒ½æŒ‰é’®
        keyboard.append([
            InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"),
            InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="money_flow")
        ])
        
        return InlineKeyboardMarkup(keyboard)
    
    def get_market_depth(self, limit=10, sort_type='ratio', sort_order='desc'):
        """å¸‚åœºæ·±åº¦æ’è¡Œå·²ä¸‹çº¿å ä½ã€‚"""
        return "â¸ï¸ å¸‚åœºæ·±åº¦æ’è¡ŒåŠŸèƒ½å·²ä¸‹çº¿ï¼Œæ•¬è¯·æœŸå¾…æ›¿ä»£æ–¹æ¡ˆã€‚"
    
    def get_market_depth_keyboard(self, current_limit=10, current_sort_type='ratio', current_sort='desc'):
        """å¸‚åœºæ·±åº¦æ’è¡Œå·²ä¸‹çº¿çš„å ä½é”®ç›˜ã€‚"""
        return InlineKeyboardMarkup([
            [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
        ])

    def get_market_sentiment(self):
        """å¸‚åœºæƒ…ç»ªï¼ˆåŸºäºBinanceè¡Œæƒ…ï¼‰å·²ä¸‹çº¿å ä½ã€‚"""
        return "â¸ï¸ å¸‚åœºæƒ…ç»ªæ¦œå•å·²ä¸‹çº¿ï¼Œæ•¬è¯·æœŸå¾…æ–°çš„æŒ‡æ ‡é¢æ¿ã€‚"

    def get_market_sentiment_keyboard(self):
        """å¸‚åœºæƒ…ç»ªå ä½é”®ç›˜ã€‚"""
        return InlineKeyboardMarkup([
            [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
        ])

class TradeCatBot:
    def __init__(self):
        self.futures_client = BinanceFuturesClient()
        self._active_symbols = None
        self._active_symbols_timestamp = 0
        self._is_initialized = False
        self._initialization_lock = asyncio.Lock() if 'asyncio' in globals() else None
        # åŒç¼“å­˜æ–‡ä»¶æœºåˆ¶
        self.cache_file_primary = CACHE_FILE_PRIMARY
        self.cache_file_secondary = CACHE_FILE_SECONDARY
        self._current_cache_file = self.cache_file_primary  # å½“å‰ä½¿ç”¨çš„ç¼“å­˜æ–‡ä»¶
        self._is_updating = False  # æ˜¯å¦æ­£åœ¨æ›´æ–°ç¼“å­˜
        # éœ€è¦å±è”½çš„å¸ç§åˆ—è¡¨
        self.blocked_symbols = {'BNXUSDT', 'ALPACAUSDT'}
        self.metric_service = BINANCE_DB_METRIC_SERVICE
        if self.metric_service is None:
            logger.warning("âš ï¸ å¸å®‰æ•°æ®åº“æŒ‡æ ‡æœåŠ¡æœªå°±ç»ªï¼Œéƒ¨åˆ†æ’è¡Œæ¦œå°†å›é€€è‡³ç¼“å­˜é€»è¾‘")
        
        # åˆå§‹åŒ–ä¿¡å·æ ¼å¼åŒ–å™¨
        try:
            SignalFormatter = _load_signal_formatter()
            self.signal_formatter = SignalFormatter()
            logger.info("âœ… ä¿¡å·æ ¼å¼åŒ–å™¨åˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"âŒ ä¿¡å·æ ¼å¼åŒ–å™¨åˆå§‹åŒ–å¤±è´¥: {e}")
            self.signal_formatter = None
    
    def filter_blocked_symbols(self, data_list):
        """è¿‡æ»¤æ‰è¢«å±è”½çš„å¸ç§"""
        if not data_list:
            return data_list
        
        filtered_data = []
        for item in data_list:
            symbol = item.get('symbol', '')
            if symbol not in self.blocked_symbols:
                filtered_data.append(item)
        
        return filtered_data
    
    def get_available_cache_files(self):
        """è·å–å¯ç”¨çš„ç¼“å­˜æ–‡ä»¶åˆ—è¡¨ï¼ŒæŒ‰ä¿®æ”¹æ—¶é—´æ’åº"""
        cache_files = []
        
        # æ£€æŸ¥ä¸»ç¼“å­˜æ–‡ä»¶
        if os.path.exists(self.cache_file_primary):
            mtime = os.path.getmtime(self.cache_file_primary)
            cache_files.append((self.cache_file_primary, mtime))
        
        # æ£€æŸ¥å¤‡ä»½ç¼“å­˜æ–‡ä»¶
        if os.path.exists(self.cache_file_secondary):
            mtime = os.path.getmtime(self.cache_file_secondary)
            cache_files.append((self.cache_file_secondary, mtime))
        
        # æŒ‰ä¿®æ”¹æ—¶é—´é™åºæ’åºï¼ˆæœ€æ–°çš„åœ¨å‰é¢ï¼‰
        cache_files.sort(key=lambda x: x[1], reverse=True)
        
        return [file_path for file_path, _ in cache_files]
    
    def load_cache_from_file(self):
        """ä»æ–‡ä»¶åŠ è½½ç¼“å­˜æ•°æ® - æ”¯æŒåŒç¼“å­˜æ–‡ä»¶æœºåˆ¶"""
        global cache
        
        available_files = self.get_available_cache_files()
        if not available_files:
            logger.info("ğŸ“„ æ²¡æœ‰æ‰¾åˆ°ç¼“å­˜æ–‡ä»¶ï¼Œå°†åˆ›å»ºæ–°çš„ç¼“å­˜")
            return False
        
        # å°è¯•ä»æœ€æ–°çš„ç¼“å­˜æ–‡ä»¶åŠ è½½
        for cache_file in available_files:
            try:
                logger.info(f"ğŸ“„ å°è¯•ä»ç¼“å­˜æ–‡ä»¶åŠ è½½: {cache_file}")
                with open(cache_file, 'r', encoding='utf-8') as f:
                    file_cache = json.load(f)
                
                # æ£€æŸ¥ç¼“å­˜æ˜¯å¦è¿‡æœŸ
                now = time.time()
                valid_cache = {}
                total_items = len(file_cache)
                
                for key, cache_item in file_cache.items():
                    if isinstance(cache_item, dict) and 'timestamp' in cache_item:
                        # æ£€æŸ¥ç¼“å­˜æ˜¯å¦åœ¨æœ‰æ•ˆæœŸå†…ï¼ˆæ‰©å±•åˆ°10åˆ†é’Ÿï¼Œå…è®¸æ›´é•¿çš„ä½¿ç”¨æ—¶é—´ï¼‰
                        cache_age = now - cache_item['timestamp']
                        if cache_age < 600:  # 10åˆ†é’Ÿæœ‰æ•ˆæœŸ
                            valid_cache[key] = cache_item
                            logger.debug(f"ä»æ–‡ä»¶åŠ è½½æœ‰æ•ˆç¼“å­˜: {key} (å¹´é¾„: {cache_age:.1f}ç§’)")
                        else:
                            logger.debug(f"æ–‡ä»¶ç¼“å­˜å·²è¿‡æœŸ: {key} (å¹´é¾„: {cache_age:.1f}ç§’)")
                    else:
                        logger.warning(f"æ— æ•ˆçš„ç¼“å­˜æ ¼å¼: {key}")
                
                if valid_cache:
                    cache.update(valid_cache)
                    logger.info(f"âœ… ä»æ–‡ä»¶ {cache_file} åŠ è½½äº† {len(valid_cache)}/{total_items} ä¸ªæœ‰æ•ˆç¼“å­˜é¡¹")
                    self._current_cache_file = cache_file
                    return True
                else:
                    logger.info(f"ğŸ“„ ç¼“å­˜æ–‡ä»¶ {cache_file} ä¸­æ²¡æœ‰æœ‰æ•ˆæ•°æ®")
                    
            except Exception as e:
                logger.error(f"âŒ åŠ è½½ç¼“å­˜æ–‡ä»¶å¤±è´¥ {cache_file}: {e}")
                continue
        
        logger.warning("âŒ æ‰€æœ‰ç¼“å­˜æ–‡ä»¶éƒ½æ— æ³•åŠ è½½æˆ–å·²è¿‡æœŸ")
        return False
    
    def save_cache_to_file(self, force_new_file=False):
        """ä¿å­˜ç¼“å­˜æ•°æ®åˆ°æ–‡ä»¶ - åŒç¼“å­˜æ–‡ä»¶æœºåˆ¶"""
        global cache
        try:
            # åˆ›å»ºä¸€ä¸ªå¯åºåˆ—åŒ–çš„ç¼“å­˜å‰¯æœ¬
            serializable_cache = {}
            for key, cache_item in cache.items():
                if isinstance(cache_item, dict) and 'data' in cache_item and 'timestamp' in cache_item:
                    # ç¡®ä¿æ•°æ®å¯ä»¥åºåˆ—åŒ–
                    try:
                        json.dumps(cache_item['data'])  # æµ‹è¯•åºåˆ—åŒ–
                        serializable_cache[key] = cache_item
                    except (TypeError, ValueError) as e:
                        logger.warning(f"ç¼“å­˜é¡¹ {key} æ— æ³•åºåˆ—åŒ–ï¼Œè·³è¿‡: {e}")
                        continue
            
            if not serializable_cache:
                logger.warning("âš ï¸ æ²¡æœ‰å¯åºåˆ—åŒ–çš„ç¼“å­˜æ•°æ®")
                return False
            
            # é€‰æ‹©è¦å†™å…¥çš„ç¼“å­˜æ–‡ä»¶
            if force_new_file or self._is_updating:
                # å¦‚æœæ­£åœ¨æ›´æ–°æˆ–å¼ºåˆ¶ä½¿ç”¨æ–°æ–‡ä»¶ï¼Œåˆ™ä½¿ç”¨å¤‡ç”¨æ–‡ä»¶
                if self._current_cache_file == self.cache_file_primary:
                    target_file = self.cache_file_secondary
                else:
                    target_file = self.cache_file_primary
            else:
                # å¦åˆ™ä½¿ç”¨å½“å‰æ–‡ä»¶
                target_file = self._current_cache_file
            
            # å†™å…¥ä¸´æ—¶æ–‡ä»¶ï¼Œç„¶åé‡å‘½åï¼Œç¡®ä¿åŸå­æ€§æ“ä½œ
            temp_file = target_file + '.tmp'
            with open(temp_file, 'w', encoding='utf-8') as f:
                json.dump(serializable_cache, f, ensure_ascii=False, indent=2)
            
            # åŸå­æ€§é‡å‘½å
            if os.path.exists(target_file):
                os.remove(target_file)
            os.rename(temp_file, target_file)
            
            # æ›´æ–°å½“å‰ä½¿ç”¨çš„ç¼“å­˜æ–‡ä»¶
            if force_new_file or self._is_updating:
                self._current_cache_file = target_file
                logger.info(f"âœ… ç¼“å­˜å·²ä¿å­˜åˆ°æ–°æ–‡ä»¶: {target_file} ({len(serializable_cache)} ä¸ªé¡¹ç›®)")
                
                # æ¸…ç†æ—§çš„ç¼“å­˜æ–‡ä»¶ï¼ˆä¿ç•™æœ€æ–°çš„ä¸¤ä¸ªæ–‡ä»¶ï¼‰
                self.cleanup_old_cache_files()
            else:
                logger.info(f"âœ… ç¼“å­˜å·²æ›´æ–°åˆ°æ–‡ä»¶: {target_file} ({len(serializable_cache)} ä¸ªé¡¹ç›®)")
            
            return True
                
        except Exception as e:
            logger.error(f"âŒ ä¿å­˜ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
            # æ¸…ç†ä¸´æ—¶æ–‡ä»¶
            temp_file = target_file + '.tmp' if 'target_file' in locals() else None
            if temp_file and os.path.exists(temp_file):
                try:
                    os.remove(temp_file)
                except:
                    pass
        
        return False
    
    def cleanup_old_cache_files(self):
        """æ¸…ç†æ—§çš„ç¼“å­˜æ–‡ä»¶ï¼Œåªä¿ç•™æœ€æ–°çš„ä¸¤ä¸ª"""
        try:
            available_files = self.get_available_cache_files()
            
            # å¦‚æœè¶…è¿‡2ä¸ªæ–‡ä»¶ï¼Œåˆ é™¤æœ€æ—§çš„
            if len(available_files) > 2:
                files_to_delete = available_files[2:]  # ä¿ç•™å‰ä¸¤ä¸ªï¼ˆæœ€æ–°çš„ï¼‰
                for file_path in files_to_delete:
                    try:
                        os.remove(file_path)
                        logger.info(f"ğŸ—‘ï¸ å·²åˆ é™¤æ—§ç¼“å­˜æ–‡ä»¶: {file_path}")
                    except Exception as e:
                        logger.warning(f"âš ï¸ åˆ é™¤æ—§ç¼“å­˜æ–‡ä»¶å¤±è´¥ {file_path}: {e}")
                        
        except Exception as e:
            logger.error(f"âŒ æ¸…ç†ç¼“å­˜æ–‡ä»¶å¤±è´¥: {e}")
        
    def get_cached_data(self, key, fetch_func, *args, **kwargs):
        """è·å–ç¼“å­˜æ•°æ®æˆ–é‡æ–°è·å–"""
        global cache
        now = time.time()
        if key in cache and now - cache[key]['timestamp'] < CACHE_DURATION:
            logger.info(f"ä½¿ç”¨ç¼“å­˜æ•°æ®: {key}")
            return cache[key]['data']
        
        try:
            logger.info(f"è·å–æ–°æ•°æ®: {key}")
            data = fetch_func(*args, **kwargs)
            if data:  # åªç¼“å­˜æœ‰æ•ˆæ•°æ®
                cache[key] = {'data': data, 'timestamp': now}
                logger.info(f"æ•°æ®ç¼“å­˜æˆåŠŸ: {key}, æ¡æ•°: {len(data) if isinstance(data, list) else 1}")
            return data
        except Exception as e:
            logger.error(f"è·å–æ•°æ®å¤±è´¥ {key}: {e}")
            # è¿”å›æ—§ç¼“å­˜æ•°æ®ä½œä¸ºå¤‡é€‰
            old_data = cache.get(key, {}).get('data', [])
            if old_data:
                logger.info(f"è¿”å›æ—§ç¼“å­˜æ•°æ®: {key}")
            return old_data

    async def initialize_cache(self):
        """åˆå§‹åŒ–ç¼“å­˜ - é¢„åŠ è½½æ‰€æœ‰æ•°æ®"""
        if self._is_initialized:
            return
        
        logger.info("ğŸš€ å¼€å§‹åˆå§‹åŒ–ç¼“å­˜ï¼Œé¢„åŠ è½½æ‰€æœ‰æ•°æ®...")
        
        # é¦–å…ˆå°è¯•ä»æ–‡ä»¶åŠ è½½ç¼“å­˜
        cache_loaded = self.load_cache_from_file()
        if cache_loaded:
            logger.info("ğŸ“„ ä½¿ç”¨æ–‡ä»¶ç¼“å­˜æ•°æ®ï¼Œè·³è¿‡éƒ¨åˆ†ç½‘ç»œè¯·æ±‚")
        else:
            logger.info("ğŸŒ æ–‡ä»¶ç¼“å­˜æ— æ•ˆï¼Œå°†é‡æ–°è·å–æ‰€æœ‰æ•°æ®")
        
        # é¢„åŠ è½½æ•°æ®çš„ä»»åŠ¡åˆ—è¡¨ - æ‰©å±•æ›´å¤šç¼“å­˜
        cache_tasks = [
            # æ ¸å¿ƒæ•°æ®æº
            ('ticker_24hr_data', self.fetch_24hr_ticker_data),
            ('funding_rate_data', self.fetch_funding_rate_data),
            ('open_interest_data', self.fetch_open_interest_data),
            ('market_depth_data', self.fetch_market_depth_data),
            ('liquidation_data', self.fetch_liquidation_data),
            
            # å¤šç©ºæ¯”æ•°æ®ï¼ˆä¸åŒå‘¨æœŸï¼‰
            ('long_short_ratio_data_1d', lambda: self.fetch_long_short_ratio_data('1d')),
            ('long_short_ratio_data_4h', lambda: self.fetch_long_short_ratio_data('4h')),
            ('long_short_ratio_data_1h', lambda: self.fetch_long_short_ratio_data('1h')),
            
            # æŒä»“é‡å†å²æ•°æ®ï¼ˆä¸åŒå‘¨æœŸï¼‰
            ('open_interest_hist_24h', lambda: self.fetch_open_interest_hist_data('24h')),
            ('open_interest_hist_4h', lambda: self.fetch_open_interest_hist_data('4h')),
            ('open_interest_hist_1h', lambda: self.fetch_open_interest_hist_data('1h')),
            ('open_interest_hist_15m', lambda: self.fetch_open_interest_hist_data('15m')),
            
            # Kçº¿äº¤æ˜“é‡æ•°æ®ï¼ˆä¸åŒå‘¨æœŸï¼‰
            ('volume_kline_data_24h', lambda: self.fetch_kline_volume_data('24h')),
            ('volume_kline_data_12h', lambda: self.fetch_kline_volume_data('12h')),
            ('volume_kline_data_4h', lambda: self.fetch_kline_volume_data('4h')),
            ('volume_kline_data_1h', lambda: self.fetch_kline_volume_data('1h')),
            ('volume_kline_data_15m', lambda: self.fetch_kline_volume_data('15m')),
            
            # é¢„è®¡ç®—çš„å¸‚åœºæŒ‡æ ‡ï¼ˆå‡å°‘å®æ—¶è®¡ç®—å‹åŠ›ï¼‰
            ('market_sentiment_cache', self.compute_market_sentiment_data),
            ('top_gainers_cache', lambda: self.compute_top_movers_data('gainers')),
            ('top_losers_cache', lambda: self.compute_top_movers_data('losers')),
            ('active_symbols_cache', lambda: self.get_active_symbols(force_refresh=True)),
        ]
        
        # é¢„åŠ è½½æ´»è·ƒäº¤æ˜“å¯¹
        try:
            logger.info("ğŸ“Š é¢„åŠ è½½æ´»è·ƒäº¤æ˜“å¯¹...")
            self.get_active_symbols(force_refresh=True)
            logger.info("âœ… æ´»è·ƒäº¤æ˜“å¯¹åŠ è½½å®Œæˆ")
        except Exception as e:
            logger.error(f"âŒ æ´»è·ƒäº¤æ˜“å¯¹åŠ è½½å¤±è´¥: {e}")
        
        # ä½¿ç”¨å¼‚æ­¥æ–¹å¼é¢„åŠ è½½æ‰€æœ‰æ•°æ®ï¼ˆé¿å…é˜»å¡ï¼‰
        async def load_cache_async(key, fetch_func):
            """å¼‚æ­¥åŠ è½½ç¼“å­˜æ•°æ®"""
            try:
                # æ£€æŸ¥æ˜¯å¦å·²æœ‰æœ‰æ•ˆç¼“å­˜
                if key in cache:
                    now = time.time()
                    if now - cache[key]['timestamp'] < CACHE_DURATION:
                        logger.info(f"âœ… {key} ç¼“å­˜ä»ç„¶æœ‰æ•ˆï¼Œè·³è¿‡ç½‘ç»œè¯·æ±‚")
                        return
                
                logger.info(f"ğŸ“Š é¢„åŠ è½½ {key}...")
                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡
                loop = asyncio.get_event_loop()
                data = await loop.run_in_executor(None, fetch_func)
                
                if data:
                    cache[key] = {'data': data, 'timestamp': time.time()}
                    logger.info(f"âœ… {key} åŠ è½½å®Œæˆï¼Œæ•°æ®é‡: {len(data) if isinstance(data, list) else 1}")
                else:
                    logger.warning(f"âš ï¸ {key} æ•°æ®ä¸ºç©º")
                    
            except Exception as e:
                logger.error(f"âŒ {key} åŠ è½½å¤±è´¥: {e}")
        
        # åˆ†æ‰¹å¹¶å‘åŠ è½½ï¼Œé¿å…è¿‡å¤šå¹¶å‘è¯·æ±‚
        batch_size = 4
        for i in range(0, len(cache_tasks), batch_size):
            batch = cache_tasks[i:i+batch_size]
            tasks = [load_cache_async(key, func) for key, func in batch]
            await asyncio.gather(*tasks, return_exceptions=True)
            
            # æ‰¹æ¬¡é—´ç¨ä½œä¼‘æ¯
            if i + batch_size < len(cache_tasks):
                await asyncio.sleep(0.3)
        
        # ä¿å­˜ç¼“å­˜åˆ°æ–‡ä»¶ï¼ˆå¼‚æ­¥æ‰§è¡Œï¼‰
        loop = asyncio.get_event_loop()
        await loop.run_in_executor(None, self.save_cache_to_file)
        
        self._is_initialized = True
        logger.info("ğŸ‰ ç¼“å­˜åˆå§‹åŒ–å®Œæˆï¼æ‰€æœ‰æ•°æ®å·²é¢„åŠ è½½å¹¶ä¿å­˜åˆ°æ–‡ä»¶")
        
        # å¯åŠ¨å¿«é€Ÿé¢„çƒ­æ¨¡å¼ï¼Œç¡®ä¿æœ€å…³é”®æ•°æ®ç«‹å³å¯ç”¨
        await self.quick_warmup_cache()

    async def quick_warmup_cache(self):
        """å¿«é€Ÿé¢„çƒ­å…³é”®ç¼“å­˜ - ç¡®ä¿ç”¨æˆ·ç«‹å³å¯ä»¥ä½¿ç”¨æœ€é‡è¦çš„åŠŸèƒ½"""
        logger.info("ğŸ”¥ å¼€å§‹å¿«é€Ÿé¢„çƒ­å…³é”®ç¼“å­˜...")
        
        # æœ€é«˜ä¼˜å…ˆçº§ï¼šç«‹å³ç¡®ä¿è¿™äº›æ•°æ®å¯ç”¨
        if BINANCE_API_DISABLED:
            logger.info("â¸ï¸ BINANCE_API_DISABLED=1ï¼Œè·³è¿‡å…³é”®æ•°æ®é¢„çƒ­")
            return
        critical_tasks = [
            ('ticker_24hr_data', self.fetch_24hr_ticker_data),
            ('funding_rate_data', self.fetch_funding_rate_data),
        ]
        
        # å¦‚æœè¿™äº›å…³é”®æ•°æ®ä¸åœ¨ç¼“å­˜ä¸­ï¼Œç«‹å³è·å–
        for key, fetch_func in critical_tasks:
            if key not in cache or not cache[key].get('data'):
                logger.info(f"ğŸš¨ å…³é”®æ•°æ®ç¼ºå¤±ï¼Œç«‹å³è·å–: {key}")
                try:
                    loop = asyncio.get_event_loop()
                    data = await loop.run_in_executor(None, fetch_func)
                    if data:
                        cache[key] = {'data': data, 'timestamp': time.time()}
                        logger.info(f"âœ… å…³é”®æ•°æ®é¢„çƒ­å®Œæˆ: {key}")
                    else:
                        logger.warning(f"âš ï¸ å…³é”®æ•°æ®é¢„çƒ­å¤±è´¥: {key}")
                except Exception as e:
                    logger.error(f"âŒ å…³é”®æ•°æ®é¢„çƒ­å¼‚å¸¸: {key} - {e}")
        
        logger.info("ğŸ”¥ å¿«é€Ÿé¢„çƒ­å®Œæˆï¼Œæœºå™¨äººå¯ç«‹å³å“åº”ç”¨æˆ·è¯·æ±‚ï¼")

    def get_cached_data_only(self, key):
        """ä»…è·å–ç¼“å­˜æ•°æ®ï¼Œä¸è¿›è¡Œç½‘ç»œè¯·æ±‚"""
        global cache
        if key in cache:
            cache_age = time.time() - cache[key]['timestamp']
            logger.info(f"è¿”å›ç¼“å­˜æ•°æ®: {key} (ç¼“å­˜å¹´é¾„: {cache_age:.1f}ç§’)")
            return cache[key]['data']
        else:
            logger.warning(f"ç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®: {key}")
            return []
    
    def get_cached_data_with_fallback(self, key, fallback_message=None):
        """è·å–ç¼“å­˜æ•°æ®ï¼Œå¦‚æœæ²¡æœ‰åˆ™è¿”å›å‹å¥½æç¤º"""
        global cache
        if key in cache:
            cache_age = time.time() - cache[key]['timestamp']
            logger.info(f"è¿”å›ç¼“å­˜æ•°æ®: {key} (ç¼“å­˜å¹´é¾„: {cache_age:.1f}ç§’)")
            return cache[key]['data'], None
        else:
            logger.warning(f"ç¼“å­˜ä¸­æ²¡æœ‰æ•°æ®: {key}")
            if fallback_message is None:
                fallback_message = "ğŸ”„ æ•°æ®æ­£åœ¨åå°åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•\nğŸ’¡ æœºå™¨äººåˆšå¯åŠ¨æ—¶éœ€è¦å‡ ç§’é’ŸåŠ è½½æ•°æ®"
            return [], fallback_message
    
    def get_cache_status(self):
        """è·å–ç¼“å­˜çŠ¶æ€ä¿¡æ¯"""
        global cache
        if not cache:
            return "âŒ ç¼“å­˜ä¸ºç©º"
        
        status_info = []
        current_time = time.time()
        
        for key, data in cache.items():
            age = current_time - data['timestamp']
            data_count = len(data['data']) if isinstance(data['data'], list) else 1
            status_info.append(f"- {key}: {data_count}æ¡æ•°æ®, {age:.1f}ç§’å‰")
        
        return f"ğŸ“Š ç¼“å­˜çŠ¶æ€:\n" + "\n".join(status_info)

    async def refresh_cache_background(self):
        """ğŸš€ æè½»é‡çº§åå°åˆ·æ–° - å®Œå…¨éé˜»å¡ï¼Œç”¨æˆ·ä½“éªŒä¼˜å…ˆ"""
        update_interval = 120  # åŸºç¡€æ›´æ–°é—´éš”2åˆ†é’Ÿï¼Œè¿›ä¸€æ­¥å‡å°‘é¢‘ç‡
        consecutive_failures = 0
        last_user_activity = time.time()
        
        while True:
            try:
                # æ™ºèƒ½è°ƒæ•´æ›´æ–°é—´éš”ï¼Œå¤±è´¥æ—¶å»¶é•¿é—´éš”
                current_interval = min(update_interval * (1 + consecutive_failures * 0.5), 600)  # æœ€å¤§10åˆ†é’Ÿ
                
                # æ ¹æ®ç³»ç»Ÿè´Ÿè½½åŠ¨æ€è°ƒæ•´
                import psutil
                cpu_percent = psutil.cpu_percent(interval=0.1)
                if cpu_percent > 80:
                    current_interval *= 1.5  # CPUé«˜è´Ÿè½½æ—¶å»¶é•¿é—´éš”
                
                await asyncio.sleep(current_interval)
                
                # ğŸ”§ å…³é”®ä¿®å¤ï¼šä½¿ç”¨è½»é‡çº§æ›´æ–°ï¼Œå®Œå…¨éé˜»å¡
                logger.info(f"ğŸš€ å¯åŠ¨æè½»é‡çº§ç¼“å­˜åˆ·æ–°... (é—´éš”: {current_interval:.0f}ç§’, CPU: {cpu_percent:.1f}%)")
                
                try:
                    # ä½¿ç”¨è½»é‡çº§å¼‚æ­¥æ›´æ–°ï¼Œä¸è®¾ç½®é˜»å¡æ ‡å¿—
                    await self.update_cache_lightweight()
                    consecutive_failures = 0  # é‡ç½®å¤±è´¥è®¡æ•°
                    logger.info("âœ… æ™ºèƒ½åå°ç¼“å­˜åˆ·æ–°å®Œæˆ")
                except Exception as update_error:
                    logger.error(f"âŒ åå°ç¼“å­˜æ›´æ–°å¤±è´¥: {update_error}")
                    consecutive_failures += 1
                
            except Exception as e:
                logger.error(f"âŒ åå°ç¼“å­˜åˆ·æ–°å¤±è´¥: {e}")
                consecutive_failures += 1
                
                # å¤±è´¥åç­‰å¾…æ—¶é—´é€’å¢ï¼Œä½†ä¿æŒè¾ƒçŸ­
                wait_time = min(5 * consecutive_failures, 30)  # æœ€å¤§30ç§’
                await asyncio.sleep(wait_time)
    
    async def update_cache_lightweight(self):
        """è½»é‡çº§ç¼“å­˜æ›´æ–° - ä¸è®¾ç½®é˜»å¡æ ‡å¿—ï¼Œç¡®ä¿ç”¨æˆ·è¯·æ±‚ä¸å—å½±å“"""
        global cache
        if BINANCE_API_DISABLED:
            logger.info("â¸ï¸ BINANCE_API_DISABLED=1ï¼Œè·³è¿‡è½»é‡çº§ç¼“å­˜æ›´æ–°")
            return
        logger.info("ğŸ“Š å¼€å§‹è½»é‡çº§éé˜»å¡ç¼“å­˜æ›´æ–°...")
        
        # ğŸ”§ ä¸è®¾ç½® self._is_updating = Trueï¼Œç¡®ä¿ç”¨æˆ·è¯·æ±‚ä¸è¢«é˜»å¡
        
        # åˆ›å»ºæ–°çš„ç¼“å­˜æ•°æ®
        new_cache_data = {}
        
        # è½»é‡çº§å¼‚æ­¥åŒ…è£…å™¨
        async def fetch_lightweight(key, fetch_func):
            """è½»é‡çº§å¼‚æ­¥åŒ…è£…å™¨ï¼Œä¼˜å…ˆä¿è¯ç”¨æˆ·ä½“éªŒ"""
            try:
                logger.info(f"ğŸ”„ è½»é‡çº§æ›´æ–° {key}...")
                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œè®¾ç½®è¾ƒçŸ­è¶…æ—¶
                loop = asyncio.get_event_loop()
                
                # è®¾ç½®30ç§’è¶…æ—¶ï¼Œé¿å…é•¿æ—¶é—´é˜»å¡
                try:
                    data = await asyncio.wait_for(
                        loop.run_in_executor(None, fetch_func), 
                        timeout=30.0
                    )
                except asyncio.TimeoutError:
                    logger.warning(f"â° {key} æ›´æ–°è¶…æ—¶ï¼Œä¿ç•™æ—§ç¼“å­˜")
                    # ä¿ç•™æ—§ç¼“å­˜
                    if key in cache:
                        return key, cache[key]
                    return key, None
                
                if data:
                    logger.info(f"âœ… {key} è½»é‡çº§æ›´æ–°å®Œæˆ")
                    return key, {'data': data, 'timestamp': time.time()}
                else:
                    logger.warning(f"âš ï¸ {key} æ•°æ®ä¸ºç©ºï¼Œä¿ç•™æ—§ç¼“å­˜")
                    if key in cache:
                        return key, cache[key]
                    return key, None
                    
            except Exception as e:
                logger.error(f"âŒ è½»é‡çº§æ›´æ–° {key} å¤±è´¥: {e}")
                # ä¿ç•™æ—§ç¼“å­˜æ•°æ®
                if key in cache:
                    logger.info(f"ğŸ”„ ä¿ç•™ {key} çš„æ—§ç¼“å­˜æ•°æ®")
                    return key, cache[key]
                return key, None
        
        # åªæ›´æ–°æœ€å…³é”®çš„æ•°æ®ï¼Œå‡å°‘æ›´æ–°æ—¶é—´
        critical_tasks = [
            ('ticker_24hr_data', self.fetch_24hr_ticker_data),
            ('funding_rate_data', self.fetch_funding_rate_data),
        ]
        
        # åˆ†æ‰¹æ‰§è¡Œï¼Œæ¯æ‰¹ä¹‹é—´æœ‰å»¶è¿Ÿï¼Œç¡®ä¿ç”¨æˆ·è¯·æ±‚æœ‰æœºä¼šå¤„ç†
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œå…³é”®ä»»åŠ¡...")
        for i, (key, func) in enumerate(critical_tasks):
            try:
                # æ¯ä¸ªä»»åŠ¡å•ç‹¬æ‰§è¡Œï¼Œå¤±è´¥ä¸å½±å“å…¶ä»–ä»»åŠ¡
                result = await fetch_lightweight(key, func)
                if result[1] is not None:
                    new_cache_data[result[0]] = result[1]
                
                # ä»»åŠ¡é—´ä¼‘æ¯ï¼Œè®©ç”¨æˆ·äº¤äº’æœ‰æœºä¼šå¤„ç†
                if i < len(critical_tasks) - 1:
                    await asyncio.sleep(0.5)
                    
            except Exception as e:
                logger.error(f"å…³é”®ä»»åŠ¡ {key} å¼‚å¸¸: {e}")
                continue
        
        # å¦‚æœæœ‰æ•°æ®æ›´æ–°æˆåŠŸï¼ŒåŸå­æ€§æ›´æ–°å…¨å±€ç¼“å­˜
        if new_cache_data:
            # å¿«é€ŸåŸå­æ€§æ›´æ–°
            cache.update(new_cache_data)
            
            # å¼‚æ­¥ä¿å­˜åˆ°æ–‡ä»¶ï¼Œä¸ç­‰å¾…å®Œæˆ
            try:
                loop = asyncio.get_event_loop()
                # åå°çº¿ç¨‹å†™ç›˜ï¼šæ— éœ€å†å°è£… create_taskï¼Œrun_in_executor å·²è¿”å› Future
                loop.run_in_executor(None, lambda: self.save_cache_to_file(force_new_file=False))
            except Exception as save_error:
                logger.warning(f"ç¼“å­˜ä¿å­˜ä»»åŠ¡åˆ›å»ºå¤±è´¥: {save_error}")
            
            logger.info(f"ğŸ‰ è½»é‡çº§ç¼“å­˜æ›´æ–°å®Œæˆï¼æ›´æ–°äº† {len(new_cache_data)} ä¸ªæ•°æ®æº")
        else:
            logger.warning("âš ï¸ æœ¬æ¬¡è½»é‡çº§æ›´æ–°æ²¡æœ‰è·å–åˆ°æ–°æ•°æ®")
    
    async def update_cache_non_blocking(self):
        """çœŸæ­£éé˜»å¡çš„ç¼“å­˜æ›´æ–° - é‡å®šå‘åˆ°è½»é‡çº§æ›´æ–°ï¼ˆä¿ç•™å…¼å®¹æ€§ï¼‰"""
        await self.update_cache_lightweight()
        return  # æå‰è¿”å›ï¼Œé¿å…æ‰§è¡ŒåŸæ¥çš„é‡å‹æ›´æ–°é€»è¾‘
        
        # åŸæ¥çš„é‡å‹æ›´æ–°é€»è¾‘ä¿ç•™ä½†ä¸æ‰§è¡Œ
        global cache
        logger.info("ğŸ“Š å¼€å§‹çœŸæ­£éé˜»å¡ç¼“å­˜æ›´æ–°...")
        
        # åˆ›å»ºæ–°çš„ç¼“å­˜æ•°æ®
        new_cache_data = {}
        
        # å°†æ‰€æœ‰åŒæ­¥å‡½æ•°åŒ…è£…ä¸ºå¼‚æ­¥ä»»åŠ¡
        async def fetch_async(key, fetch_func):
            """å¼‚æ­¥åŒ…è£…å™¨ï¼Œåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡ŒåŒæ­¥APIè°ƒç”¨"""
            try:
                logger.info(f"ğŸ”„ æ›´æ–° {key}...")
                # åœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶å¾ªç¯
                loop = asyncio.get_event_loop()
                data = await loop.run_in_executor(None, fetch_func)
                
                if data:
                    logger.info(f"âœ… {key} æ›´æ–°å®Œæˆï¼Œæ•°æ®é‡: {len(data) if isinstance(data, list) else 1}")
                    return key, {'data': data, 'timestamp': time.time()}
                else:
                    logger.warning(f"âš ï¸ {key} æ•°æ®ä¸ºç©ºï¼Œä¿ç•™æ—§ç¼“å­˜")
                    # ä¿ç•™æ—§ç¼“å­˜æ•°æ®
                    if key in cache:
                        return key, cache[key]
                    return key, None
                    
            except Exception as e:
                logger.error(f"âŒ æ›´æ–° {key} å¤±è´¥: {e}")
                # ä¿ç•™æ—§ç¼“å­˜æ•°æ®
                if key in cache:
                    logger.info(f"ğŸ”„ ä¿ç•™ {key} çš„æ—§ç¼“å­˜æ•°æ®")
                    return key, cache[key]
                return key, None
        
        # åˆ†ç»„ä»»åŠ¡ - æŒ‰ä¼˜å…ˆçº§å’Œä¾èµ–å…³ç³»åˆ†æ‰¹å¤„ç†
        high_priority_tasks = [
            ('ticker_24hr_data', self.fetch_24hr_ticker_data),
            ('funding_rate_data', self.fetch_funding_rate_data),
        ]
        
        medium_priority_tasks = [
            ('open_interest_data', self.fetch_open_interest_data),
            ('market_depth_data', self.fetch_market_depth_data),
            ('liquidation_data', self.fetch_liquidation_data),
        ]
        
        low_priority_tasks = [
            # å¤šç©ºæ¯”æ•°æ®
            ('long_short_ratio_data_1d', lambda: self.fetch_long_short_ratio_data('1d')),
            ('long_short_ratio_data_4h', lambda: self.fetch_long_short_ratio_data('4h')),
            ('long_short_ratio_data_1h', lambda: self.fetch_long_short_ratio_data('1h')),
            
            # æŒä»“é‡å†å²æ•°æ®
            ('open_interest_hist_24h', lambda: self.fetch_open_interest_hist_data('24h')),
            ('open_interest_hist_4h', lambda: self.fetch_open_interest_hist_data('4h')),
            ('open_interest_hist_1h', lambda: self.fetch_open_interest_hist_data('1h')),
            ('open_interest_hist_15m', lambda: self.fetch_open_interest_hist_data('15m')),
            
            # Kçº¿äº¤æ˜“é‡æ•°æ®
            ('volume_kline_data_24h', lambda: self.fetch_kline_volume_data('24h')),
            ('volume_kline_data_12h', lambda: self.fetch_kline_volume_data('12h')),
            ('volume_kline_data_4h', lambda: self.fetch_kline_volume_data('4h')),
            ('volume_kline_data_1h', lambda: self.fetch_kline_volume_data('1h')),
            ('volume_kline_data_15m', lambda: self.fetch_kline_volume_data('15m')),
            
            # é¢„è®¡ç®—æ•°æ®
            ('market_sentiment_cache', self.compute_market_sentiment_data),
            ('top_gainers_cache', lambda: self.compute_top_movers_data('gainers')),
            ('top_losers_cache', lambda: self.compute_top_movers_data('losers')),
            ('active_symbols_cache', lambda: self.get_active_symbols(force_refresh=True)),
        ]
        
        # ç¬¬ä¸€æ‰¹ï¼šé«˜ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆå¹¶å‘æ‰§è¡Œï¼‰
        logger.info("ğŸš€ å¼€å§‹æ‰§è¡Œé«˜ä¼˜å…ˆçº§ä»»åŠ¡...")
        tasks = [fetch_async(key, func) for key, func in high_priority_tasks]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"é«˜ä¼˜å…ˆçº§ä»»åŠ¡å¼‚å¸¸: {result}")
            elif result[1] is not None:
                new_cache_data[result[0]] = result[1]
        
        # ä¸­é—´ä¼‘æ¯ï¼Œè®©ç”¨æˆ·äº¤äº’æœ‰æœºä¼šå¤„ç†
        await asyncio.sleep(0.1)
        
        # ç¬¬äºŒæ‰¹ï¼šä¸­ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆå¹¶å‘æ‰§è¡Œï¼‰
        logger.info("âš¡ å¼€å§‹æ‰§è¡Œä¸­ä¼˜å…ˆçº§ä»»åŠ¡...")
        tasks = [fetch_async(key, func) for key, func in medium_priority_tasks]
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        for result in results:
            if isinstance(result, Exception):
                logger.error(f"ä¸­ä¼˜å…ˆçº§ä»»åŠ¡å¼‚å¸¸: {result}")
            elif result[1] is not None:
                new_cache_data[result[0]] = result[1]
        
        # ä¸­é—´ä¼‘æ¯ï¼Œè®©ç”¨æˆ·äº¤äº’æœ‰æœºä¼šå¤„ç†
        await asyncio.sleep(0.1)
        
        # ç¬¬ä¸‰æ‰¹ï¼šä½ä¼˜å…ˆçº§ä»»åŠ¡ï¼ˆåˆ†å°æ‰¹æ¬¡æ‰§è¡Œï¼‰
        logger.info("ğŸ”„ å¼€å§‹æ‰§è¡Œä½ä¼˜å…ˆçº§ä»»åŠ¡...")
        batch_size = 3  # æ¯æ‰¹3ä¸ªä»»åŠ¡
        
        for i in range(0, len(low_priority_tasks), batch_size):
            batch = low_priority_tasks[i:i+batch_size]
            tasks = [fetch_async(key, func) for key, func in batch]
            results = await asyncio.gather(*tasks, return_exceptions=True)
            
            for result in results:
                if isinstance(result, Exception):
                    logger.error(f"ä½ä¼˜å…ˆçº§ä»»åŠ¡å¼‚å¸¸: {result}")
                elif result[1] is not None:
                    new_cache_data[result[0]] = result[1]
            
            # æ¯æ‰¹æ¬¡ä¹‹é—´ä¼‘æ¯ï¼Œç¡®ä¿ç”¨æˆ·äº¤äº’æµç•…
            if i + batch_size < len(low_priority_tasks):
                await asyncio.sleep(0.2)
        
        # ç»Ÿè®¡æ›´æ–°ç»“æœ
        updated_count = len([k for k, v in new_cache_data.items() if v is not None and k not in cache or cache[k] != v])
        
        # å¦‚æœæœ‰æ•°æ®æ›´æ–°æˆåŠŸï¼Œåˆ™æ›´æ–°å…¨å±€ç¼“å­˜å¹¶ä¿å­˜åˆ°æ–°æ–‡ä»¶
        if new_cache_data:
            # åŸå­æ€§æ›´æ–°å…¨å±€ç¼“å­˜
            cache.update(new_cache_data)
            
            # å¼‚æ­¥ä¿å­˜åˆ°æ–°çš„ç¼“å­˜æ–‡ä»¶ï¼ˆåœ¨çº¿ç¨‹æ± ä¸­æ‰§è¡Œï¼‰
            loop = asyncio.get_event_loop()
            await loop.run_in_executor(None, lambda: self.save_cache_to_file(force_new_file=True))
            
            logger.info(f"ğŸ‰ çœŸæ­£éé˜»å¡ç¼“å­˜æ›´æ–°å®Œæˆï¼æˆåŠŸæ›´æ–° {updated_count} ä¸ªæ•°æ®æº")
        else:
            logger.warning("âš ï¸ æ²¡æœ‰æ•°æ®æ›´æ–°æˆåŠŸï¼Œä¿æŒç°æœ‰ç¼“å­˜")
    
    def get_cache_file_info(self):
        """è·å–ç¼“å­˜æ–‡ä»¶ä¿¡æ¯"""
        info = []
        available_files = self.get_available_cache_files()
        
        for i, file_path in enumerate(available_files):
            try:
                mtime = os.path.getmtime(file_path)
                size = os.path.getsize(file_path)
                # è½¬æ¢ä¸ºåŒ—äº¬æ—¶é—´ UTC+8
                mtime_str = datetime.fromtimestamp(mtime, timezone(timedelta(hours=8))).strftime('%Y-%m-%d %H:%M:%S')
                size_str = f"{size/1024:.1f}KB" if size < 1024*1024 else f"{size/(1024*1024):.1f}MB"
                
                status = "å½“å‰ä½¿ç”¨" if file_path == self._current_cache_file else "å¤‡ä»½æ–‡ä»¶"
                info.append(f"- {file_path}: {status}, {mtime_str}, {size_str}")
            except Exception as e:
                info.append(f"- {file_path}: è¯»å–å¤±è´¥ - {e}")
        
        return "\n".join(info) if info else "æ²¡æœ‰æ‰¾åˆ°ç¼“å­˜æ–‡ä»¶"

    def get_active_symbols(self, force_refresh=False):
        """è·å–æ´»è·ƒçš„USDTåˆçº¦äº¤æ˜“å¯¹ - æ”¯æŒæ›´å¤šå¸ç§"""
        now = time.time()
        if not force_refresh and self._active_symbols and (now - self._active_symbols_timestamp) < 300:  # 5åˆ†é’Ÿç¼“å­˜
            return self._active_symbols
        
        try:
            # è·å–äº¤æ˜“æ‰€ä¿¡æ¯
            exchange_info = self.futures_client.get_exchange_info()
            if exchange_info and 'symbols' in exchange_info:
                # å…ˆæ”¶é›†æ‰€æœ‰æ´»è·ƒçš„USDTæ°¸ç»­åˆçº¦
                active_symbols = []
                for symbol_info in exchange_info['symbols']:
                    if (symbol_info['status'] == 'TRADING' and 
                        symbol_info['symbol'].endswith('USDT') and
                        symbol_info['contractType'] == 'PERPETUAL' and
                        symbol_info['symbol'] not in self.blocked_symbols):
                        active_symbols.append(symbol_info['symbol'])
                
                # è·å–24å°æ—¶äº¤æ˜“æ•°æ®è¿›è¡Œæ’åº
                try:
                    ticker_data = self.futures_client.get_24hr_ticker()
                    if ticker_data:
                        # åˆ›å»ºäº¤æ˜“é‡æ˜ å°„
                        volume_map = {}
                        for ticker in ticker_data:
                            if ticker['symbol'] in active_symbols:
                                volume_map[ticker['symbol']] = float(ticker.get('quoteVolume', 0))
                        
                        # æŒ‰äº¤æ˜“é‡æ’åºï¼Œä¼˜å…ˆæ´»è·ƒåº¦é«˜çš„å¸ç§
                        active_symbols.sort(key=lambda x: volume_map.get(x, 0), reverse=True)
                        logger.info(f"æŒ‰äº¤æ˜“é‡æ’åºå®Œæˆï¼Œå‰10å: {active_symbols[:10]}")
                
                except Exception as e:
                    logger.warning(f"è·å–äº¤æ˜“é‡æ•°æ®å¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤æ’åº: {e}")
                
                # å¢åŠ æ”¯æŒçš„å¸ç§æ•°é‡åˆ°500ä¸ªï¼ˆä»100ä¸ªå¢åŠ ï¼‰
                self._active_symbols = active_symbols[:500]  # æ”¯æŒæ›´å¤šå¸ç§
                self._active_symbols_timestamp = now
                logger.info(f"âœ… è·å–åˆ° {len(self._active_symbols)} ä¸ªæ´»è·ƒäº¤æ˜“å¯¹ï¼ˆå·²æŒ‰äº¤æ˜“é‡æ’åºï¼‰")
                return self._active_symbols
                
        except Exception as e:
            logger.error(f"è·å–æ´»è·ƒäº¤æ˜“å¯¹å¤±è´¥: {e}")
        
        # è¿”å›æ‰©å±•çš„é»˜è®¤ä¸»æµå¸ç§ï¼Œè¿‡æ»¤æ‰è¢«å±è”½çš„å¸ç§
        default_symbols = [
            # ä¸»æµå¸ç§
            'BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'XRPUSDT', 'SOLUSDT',
            'DOGEUSDT', 'DOTUSDT', 'MATICUSDT', 'LTCUSDT', 'AVAXUSDT', 'LINKUSDT',
            'UNIUSDT', 'ATOMUSDT', 'ETCUSDT', 'XLMUSDT', 'BCHUSDT', 'FILUSDT',
            'TRXUSDT', 'EOSUSDT', 'AAVEUSDT', 'GRTUSDT', 'MKRUSDT', 'COMPUSDT',
            # æ·»åŠ æ›´å¤šçƒ­é—¨å¸ç§
            'SUSHIUSDT', 'YFIUSDT', 'SNXUSDT', 'CRVUSDT', 'ALGOUSDT', 'ZECUSDT',
            'DASHUSDT', 'NEARUSDT', 'FTMUSDT', 'SANDUSDT', 'MANAUSDT', 'ICPUSDT',
            'VETUSDT', 'THETAUSDT', 'AXSUSDT', 'FLOWUSDT', 'XTZUSDT', 'EGLDUSDT',
            'CHZUSDT', 'ENJUSDT', 'HBARUSDT', 'ZILUSDT', 'BATUSDT', 'ZRXUSDT',
            'OMGUSDT', 'LRCUSDT', 'BANDUSDT', 'STORJUSDT', 'KNCUSDT', 'RENUSDT',
            'RLCUSDT', 'FETUSDT', 'CTSIUSDT', 'OCEANUSDT', 'CTKUSDT', 'AKROUSDT',
            'CHRUSDT', 'ANTUSDT', 'RUNEUSDT', 'KAVAUSDT', 'SXPUSDT', 'DEFIUSDT',
            'TRBUSDT', 'ALPHAUSDT', 'ZENUSDT', 'SKLUSDT', '1INCHUSDT', 'ANKRUSDT',
            'BELUSDT', 'RVNUSDT', 'SFPUSDT', 'COTIUSDT', 'ALICEUSDT', 'ONEUSDT',
            'DENTUSDT', 'CELRUSDT', 'HOTUSDT', 'MTLUSDT', 'OGNUSDT', 'NKNUSDT',
            '1000SHIBUSDT', 'BAKEUSDT', 'GTCUSDT', 'IOTXUSDT', 'C98USDT', 'MASKUSDT',
            'ATAUSDT', 'DYDXUSDT', '1000XECUSDT', 'GALAUSDT', 'CELOUSDT', 'ARUSDT',
            'ARPAUSDT', 'LPTUSDT', 'ENSUSDT', 'PEOPLEUSDT', 'ROSEUSDT'
        ]
        # è¿‡æ»¤æ‰è¢«å±è”½çš„å¸ç§
        filtered_symbols = [symbol for symbol in default_symbols if symbol not in self.blocked_symbols]
        self._active_symbols = filtered_symbols
        logger.info(f"ä½¿ç”¨é»˜è®¤å¸ç§åˆ—è¡¨: {len(filtered_symbols)} ä¸ªå¸ç§")
        return filtered_symbols

    def compute_market_sentiment_data(self):
        """é¢„è®¡ç®—å¸‚åœºæƒ…ç»ªæ•°æ®"""
        try:
            # è·å–åŸºç¡€æ•°æ®
            price_data = self.get_cached_data_only('ticker_24hr_data')
            funding_data = self.get_cached_data_only('funding_rate_data')
            
            if not price_data or not funding_data:
                return None
            
            # è®¡ç®—å¸‚åœºæƒ…ç»ªæŒ‡æ ‡
            filtered_price = [item for item in price_data if item['symbol'].endswith('USDT') and item['symbol'] not in self.blocked_symbols]
            total_coins = len(filtered_price)
            rising_coins = len([item for item in filtered_price if float(item['priceChangePercent']) > 0])
            
            # è®¡ç®—èµ„é‡‘è´¹ç‡æƒ…ç»ª
            filtered_funding = [item for item in funding_data if item['symbol'].endswith('USDT') and item['symbol'] not in self.blocked_symbols]
            avg_funding_rate = sum([float(item['lastFundingRate']) for item in filtered_funding]) / len(filtered_funding) if filtered_funding else 0
            
            return {
                'total_coins': total_coins,
                'rising_coins': rising_coins,
                'rising_percentage': (rising_coins / total_coins) * 100 if total_coins > 0 else 0,
                'avg_funding_rate': avg_funding_rate,
                'timestamp': time.time()
            }
        except Exception as e:
            logger.error(f"è®¡ç®—å¸‚åœºæƒ…ç»ªæ•°æ®å¤±è´¥: {e}")
            return None

    def compute_top_movers_data(self, move_type='gainers'):
        """é¢„è®¡ç®—æ¶¨è·Œå¹…æ’è¡Œæ•°æ®"""
        try:
            price_data = self.get_cached_data_only('ticker_24hr_data')
            if not price_data:
                return None
            
            # è¿‡æ»¤æ•°æ®
            filtered_data = [
                item for item in price_data 
                if item['symbol'].endswith('USDT') and float(item['quoteVolume']) > 1000000 and item['symbol'] not in self.blocked_symbols
            ]
            
            # æ’åº
            reverse_sort = (move_type == 'gainers')
            sorted_data = sorted(filtered_data, key=lambda x: float(x['priceChangePercent']), reverse=reverse_sort)
            
            return {
                'data': sorted_data[:50],  # ä¿å­˜å‰50å
                'move_type': move_type,
                'timestamp': time.time()
            }
        except Exception as e:
            logger.error(f"è®¡ç®—æ¶¨è·Œå¹…æ’è¡Œæ•°æ®å¤±è´¥: {e}")
            return None

    def fetch_funding_rate_data(self):
        """è·å–èµ„é‡‘è´¹ç‡æ•°æ® - ä½¿ç”¨æ–°çš„APIæ–¹æ³•"""
        return self.futures_client.get_premium_index()

    def fetch_open_interest_data(self):
        """è·å–æŒä»“é‡æ•°æ® - ä¼˜åŒ–ç‰ˆæœ¬"""
        try:
            active_symbols = self.get_active_symbols()
            if not active_symbols:
                return []
            
            open_interest_data = []
            # æ‰¹é‡è·å–æŒä»“é‡æ•°æ®ï¼Œé™åˆ¶å¹¶å‘æ•°é‡
            batch_size = 20
            for i in range(0, min(len(active_symbols), 50), batch_size):
                batch_symbols = active_symbols[i:i+batch_size]
                
                for symbol in batch_symbols:
                    try:
                        oi_data = self.futures_client.get_open_interest(symbol)
                        if oi_data and 'openInterest' in oi_data:
                            open_interest_data.append(oi_data)
                    except Exception as e:
                        logger.debug(f"è·å–{symbol}æŒä»“é‡å¤±è´¥: {e}")
                        continue
                
                # é¿å…è¯·æ±‚è¿‡äºé¢‘ç¹
                if i + batch_size < min(len(active_symbols), 50):
                    time.sleep(0.1)
            
            return open_interest_data
            
        except Exception as e:
            logger.error(f"è·å–æŒä»“é‡æ•°æ®å¤±è´¥: {e}")
            return []

    def fetch_open_interest_hist_data(self, period='24h'):
        """è·å–æŒä»“é‡å†å²æ•°æ® - æ”¯æŒä¸åŒæ—¶é—´å‘¨æœŸ"""
        try:
            # ä¸»æµå¸ç§ï¼Œè¿‡æ»¤æ‰è¢«å±è”½çš„å¸ç§
            major_symbols = [symbol for symbol in ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'XRPUSDT', 'SOLUSDT', 'DOGEUSDT', 'DOTUSDT'] if symbol not in self.blocked_symbols]
            hist_data = []
            
            # å‘¨æœŸæ˜ å°„
            period_map = {
                '24h': '1d',
                '4h': '4h', 
                '1h': '1h',
                '15m': '15m'
            }
            
            api_period = period_map.get(period, '1d')
            
            for symbol in major_symbols:
                try:
                    data = self.futures_client.get_open_interest_hist(
                        symbol=symbol,
                        period=api_period,
                        limit=1  # åªè·å–æœ€æ–°çš„æ•°æ®
                    )
                    if data:
                        # æ·»åŠ ç¬¦å·æ ‡è¯†
                        for item in data:
                            item['symbol'] = symbol
                        hist_data.extend(data)
                except Exception as e:
                    logger.debug(f"è·å–{symbol}æŒä»“é‡å†å²å¤±è´¥: {e}")
                    continue
            
            return hist_data
        except Exception as e:
            logger.error(f"è·å–æŒä»“é‡å†å²æ•°æ®å¤±è´¥: {e}")
            return []

    def fetch_long_short_ratio_data(self, period='1d'):
        """è·å–å¤šç©ºæ¯”æ•°æ® - æ”¹è¿›ç‰ˆæœ¬"""
        try:
            # è·å–ä¸»æµå¸ç§çš„å¤šç©ºæ¯”æ•°æ®ï¼Œè¿‡æ»¤æ‰è¢«å±è”½çš„å¸ç§
            major_symbols = [symbol for symbol in ['BTCUSDT', 'ETHUSDT', 'BNBUSDT', 'ADAUSDT', 'XRPUSDT'] if symbol not in self.blocked_symbols]
            ratio_data = []
            
            for symbol in major_symbols:
                try:
                    data = self.futures_client.get_global_long_short_account_ratio(
                        symbol=symbol, 
                        period=period, 
                        limit=1
                    )
                    if data:
                        ratio_data.extend(data)
                except Exception as e:
                    logger.debug(f"è·å–{symbol}å¤šç©ºæ¯”å¤±è´¥: {e}")
                    continue
            
            return ratio_data
        except Exception as e:
            logger.error(f"è·å–å¤šç©ºæ¯”æ•°æ®å¤±è´¥: {e}")
            return []

    def fetch_liquidation_data(self):
        """è·å–çˆ†ä»“é£é™©æ•°æ® - åŸºäºå¤šç§æŒ‡æ ‡çš„ç»¼åˆè¯„ä¼°"""
        try:
            price_data = self.futures_client.get_24hr_ticker()
            funding_data = self.fetch_funding_rate_data()
            
            if not price_data or not funding_data:
                return []
            
            # åˆ›å»ºèµ„é‡‘è´¹ç‡æ˜ å°„
            funding_map = {}
            for item in funding_data:
                if 'symbol' in item and 'lastFundingRate' in item:
                    funding_map[item['symbol']] = float(item['lastFundingRate'])
            
            liquidation_risks = []
            for item in price_data:
                if not item.get('symbol', '').endswith('USDT') or item.get('symbol', '') in self.blocked_symbols:
                    continue
                
                try:
                    symbol = item['symbol']
                    change_24h = float(item.get('priceChangePercent', 0))
                    volume = float(item.get('quoteVolume', 0))
                    funding_rate = funding_map.get(symbol, 0)
                    
                    # è®¡ç®—ç»¼åˆé£é™©è¯„åˆ†
                    # 1. æ³¢åŠ¨æ€§é£é™© (24hæ¶¨è·Œå¹…)
                    volatility_risk = abs(change_24h) * 0.4
                    
                    # 2. èµ„é‡‘è´¹ç‡é£é™©
                    funding_risk = abs(funding_rate * 100) * 30
                    
                    # 3. æµåŠ¨æ€§é£é™© (äº¤æ˜“é‡è¶Šå°é£é™©è¶Šé«˜)
                    liquidity_risk = max(0, (1e8 - volume) / 1e8) * 0.2
                    
                    # 4. ä»·æ ¼è¶‹åŠ¿é£é™©
                    trend_risk = abs(change_24h) * 0.1 if abs(change_24h) > 10 else 0
                    
                    risk_score = volatility_risk + funding_risk + liquidity_risk + trend_risk
                    
                    liquidation_risks.append({
                        'symbol': symbol,
                        'risk_score': risk_score,
                        'change_24h': change_24h,
                        'funding_rate': funding_rate * 100,
                        'volume': volume,
                        'volatility_risk': volatility_risk,
                        'funding_risk': funding_risk,
                        'liquidity_risk': liquidity_risk
                    })
                    
                except (ValueError, TypeError, KeyError) as e:
                    logger.debug(f"å¤„ç†{item.get('symbol', 'unknown')}æ•°æ®å¤±è´¥: {e}")
                    continue
            
            return sorted(liquidation_risks, key=lambda x: x['risk_score'], reverse=True)
            
        except Exception as e:
            logger.error(f"è·å–çˆ†ä»“é£é™©æ•°æ®å¤±è´¥: {e}")
            return []

    def fetch_market_depth_data(self):
        """è·å–å¸‚åœºæ·±åº¦æ•°æ® - æ”¯æŒæ›´å¤šå¸ç§"""
        try:
            # ç›´æ¥ä½¿ç”¨å·²ä¼˜åŒ–çš„æ´»è·ƒå¸ç§åˆ—è¡¨
            active_symbols = self.get_active_symbols()
            if not active_symbols:
                logger.error("æ— æ³•è·å–æ´»è·ƒäº¤æ˜“å¯¹åˆ—è¡¨")
                return []
            
            # ä¸ºäº†é¿å…APIé™åˆ¶ï¼Œåˆ†æ‰¹å¤„ç†æ·±åº¦æ•°æ®
            # æ¯æ¬¡è·å–å‰150ä¸ªæœ€æ´»è·ƒçš„å¸ç§çš„æ·±åº¦æ•°æ®ï¼ˆä»100ä¸ªå¢åŠ ï¼‰
            target_symbols = active_symbols[:150]
            
            logger.info(f"ğŸ”„ å¼€å§‹è·å–{len(target_symbols)}ä¸ªå¸ç§çš„å¸‚åœºæ·±åº¦æ•°æ®")
            
            depth_data = []
            success_count = 0
            batch_size = 30  # æ¯æ‰¹å¤„ç†30ä¸ªå¸ç§
            
            for i in range(0, len(target_symbols), batch_size):
                batch_symbols = target_symbols[i:i+batch_size]
                batch_success = 0
                
                for symbol in batch_symbols:
                    try:
                        depth = self.futures_client.get_depth(symbol, limit=20)
                        if depth and 'bids' in depth and 'asks' in depth and depth['bids'] and depth['asks']:
                            # è®¡ç®—ä¹°å–ç›˜æ·±åº¦
                            bid_depth = sum(float(bid[1]) for bid in depth['bids'][:10])
                            ask_depth = sum(float(ask[1]) for ask in depth['asks'][:10])
                            
                            if bid_depth > 0 and ask_depth > 0:  # ç¡®ä¿æ·±åº¦æ•°æ®æœ‰æ•ˆ
                                depth_data.append({
                                    'symbol': symbol,
                                    'bid_depth': bid_depth,
                                    'ask_depth': ask_depth,
                                    'depth_ratio': bid_depth / ask_depth,
                                    'spread': float(depth['asks'][0][0]) - float(depth['bids'][0][0])
                                })
                                success_count += 1
                                batch_success += 1
                    except Exception as e:
                        logger.debug(f"è·å–{symbol}æ·±åº¦æ•°æ®å¤±è´¥: {e}")
                        continue
                
                # æ‰¹æ¬¡ä¹‹é—´æ·»åŠ å°å»¶è¿Ÿï¼Œé¿å…APIé™åˆ¶
                if i + batch_size < len(target_symbols):
                    time.sleep(0.2)  # 200mså»¶è¿Ÿ
                
                logger.debug(f"æ‰¹æ¬¡ {i//batch_size + 1}: æˆåŠŸè·å– {batch_success}/{len(batch_symbols)} ä¸ªå¸ç§æ·±åº¦æ•°æ®")
            
            logger.info(f"âœ… æˆåŠŸè·å–{success_count}ä¸ªå¸ç§çš„å¸‚åœºæ·±åº¦æ•°æ®")
            return depth_data
            
        except Exception as e:
            logger.error(f"è·å–å¸‚åœºæ·±åº¦æ•°æ®å¤±è´¥: {e}")
            return []

    def load_latest_futures_data(self):
        """CoinGlass æœ¬åœ°æ•°æ®å·²ä¸‹çº¿ï¼Œç›´æ¥è¿”å› Noneã€‚"""
        return None

    def validate_and_format_data(self, data_list, required_fields):
        """éªŒè¯å’Œæ ¼å¼åŒ–æ•°æ®"""
        if not data_list:
            return []
        
        valid_data = []
        for item in data_list:
            if all(field in item for field in required_fields):
                try:
                    # éªŒè¯æ•°å€¼å­—æ®µ
                    for field in required_fields:
                        if field in ['lastPrice', 'priceChangePercent', 'quoteVolume', 'lastFundingRate']:
                            float(item[field])
                    valid_data.append(item)
                except (ValueError, TypeError):
                    continue
        
        return valid_data

    def dynamic_align_format(self, data_rows, left_align_cols: int = 2, align_override=None):
        """
        åŠ¨æ€è§†å›¾å¯¹é½ï¼šå‰ left_align_cols åˆ—å·¦å¯¹é½ï¼Œå…¶ä½™å³å¯¹é½ï¼›å¯ä¼ å…¥ align_override=["L","R"...]
        åˆ—å®½å–å½“å‰æ•°æ®æœ€å¤§é•¿åº¦ï¼Œåˆ—é—´å•ç©ºæ ¼ï¼Œå¯¹é½è§„åˆ™ä¸ã€Šæ•°æ®å¯¹é½.mdã€‹ä¸€è‡´ã€‚
        """
        if not data_rows:
            return "æš‚æ— æ•°æ®"

        col_cnt = max(len(row) for row in data_rows)
        if not all(len(row) == col_cnt for row in data_rows):
            raise ValueError("åˆ—æ•°éœ€ä¸€è‡´ï¼Œå…ˆæ¸…æ´—æˆ–è¡¥é½è¾“å…¥æ•°æ®")

        if align_override:
            align = (list(align_override) + ["R"] * (col_cnt - len(align_override)))[:col_cnt]
        else:
            align = ["L"] * min(left_align_cols, col_cnt) + ["R"] * max(col_cnt - left_align_cols, 0)

        widths = [max(len(str(row[i])) for row in data_rows) for i in range(col_cnt)]

        def fmt(row):
            cells = []
            for idx, cell in enumerate(row):
                cell_str = str(cell)
                cells.append(cell_str.ljust(widths[idx]) if align[idx] == "L" else cell_str.rjust(widths[idx]))
            return " ".join(cells)

        return "\n".join(fmt(r) for r in data_rows)

    def get_current_time_display(self):
        """è·å–å½“å‰æ—¶é—´æ˜¾ç¤º"""
        # åŒ—äº¬æ—¶é—´ UTC+8
        now = datetime.now(timezone(timedelta(hours=8)))
        return {
            'full': format_beijing_time(get_beijing_time().isoformat(), '%Y-%m-%d %H:%M:%S'),
            'time_only': format_beijing_time(get_beijing_time().isoformat(), '%H:%M'),
            'hour_min': f"{now.hour}æ—¶{now.minute}åˆ†"
        }
    

    def get_main_menu_text(self):
        """è·å–ä¸»èœå•æ–‡æœ¬"""
        time_info = self.get_current_time_display()
        return (
            "âš¡ï¸ åœŸå—é‡åŒ–ç³»ç»Ÿ\n\n"
            "ğŸ“Š æ•°æ®é¢æ¿\n"
            "â”œâ”€ åŸºç¡€æ•°æ®ï¼šMACD/RSI/å¸ƒæ—å¸¦/æ”¯æ’‘é˜»åŠ›/èµ„é‡‘æµå‘/\n"
            "â”œâ”€ åˆçº¦æ•°æ®ï¼šOIç³»åˆ—/ä¸»åŠ¨ä¹°å–æ¯”/æŒä»“å˜åŠ¨/æ³¢åŠ¨ç‡/\n"
            "â””â”€ é«˜çº§æ•°æ®ï¼šEMA/Kçº¿å½¢æ€/VPVR/VWAP/æµåŠ¨æ€§/è¶‹åŠ¿/\n\n"
            "ğŸš¨ ä¿¡å·é¢æ¿\n"
            "â”œâ”€ å¼‚å¸¸ç›‘æ§\n"
            "â””â”€ è‡ªé€‰æ¨é€\n\n"
            "ğŸ¤– AIåˆ†æ\n"
            "â”œâ”€ æ·±åº¦æŠ¥å‘Š\n"
            "â””â”€ ç‚¹ä½é€Ÿè§ˆ\n\n"
            "ğŸ’³ æœåŠ¡\n"
            "â”œâ”€ å……å€¼\n"
            "â”œâ”€ ç”¨æˆ·ä¸­å¿ƒ\n"
            "â””â”€ å¸®åŠ©/æŒ‡å¼•\n\n"
            f"â° æ›´æ–°æ—¶é—´ï¼š{time_info['full']}ï¼ˆåŒ—äº¬æ—¶é—´ï¼‰\n"
            "ğŸ‘‡ ç‚¹å‡»æŒ‰é’®å¼€å§‹"
        )

    def get_position_ranking(self, limit=10, sort_order='desc', period='24h', sort_field: str = "position"):
        """è·å–æŒä»“é‡æ’è¡Œæ¦œ"""
        # åŠ è½½æœ€æ–°çš„åˆçº¦æ•°æ®
        futures_data = self.load_latest_futures_data()
        
        if not futures_data:
            return "ğŸ”„ æŒä»“æ•°æ®æ­£åœ¨åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•"
        
        # æ˜ å°„æ—¶é—´å‘¨æœŸåˆ°å­—æ®µ
        period_mapping = {
            '5m': '5m',
            '15m': '15m',
            '30m': '30m',
            '1h': '1h',
            '4h': '4h', 
            '24h': '24h'
        }
        
        if period not in period_mapping:
            period = '24h'  # é»˜è®¤ä½¿ç”¨24h
        
        period_suffix = period_mapping[period]
        
        # å¤„ç†æ•°æ®
        processed_data = []
        for item in futures_data:
            try:
                symbol = item.get('symbol', '')
                if not symbol or symbol in self.blocked_symbols:
                    continue
                
                # è·å–åŸºç¡€æŒä»“é‡æ•°æ®
                current_oi_usd = float(item.get('open_interest_usd', 0))
                current_oi_quantity = float(item.get('open_interest_quantity', 0))
                
                if current_oi_usd <= 0:
                    continue
                
                # è·å–æŒ‡å®šå‘¨æœŸçš„å˜åŒ–æ•°æ®
                change_percent = float(item.get(f'open_interest_change_percent_{period_suffix}', 0))
                change_usd = float(item.get(f'open_interest_change_usd_{period_suffix}', 0))
                
                # è·å–ä»·æ ¼æ•°æ®
                current_price = float(item.get('current_price', 0))
                
                processed_data.append({
                    'symbol': symbol,
                    'current_oi_usd': current_oi_usd,
                    'current_oi_quantity': current_oi_quantity,
                    'change_percent': change_percent,
                    'change_usd': change_usd,  # æŒ‡å®šæ—¶é—´å‘¨æœŸå†…çš„å˜åŒ–å€¼
                    'current_price': current_price
                })
                
            except (ValueError, TypeError) as e:
                logger.warning(f"å¤„ç†{symbol}æŒä»“æ•°æ®æ—¶å‡ºé”™: {e}")
                continue
        
        # æ’åº - æ ¹æ®å˜åŒ–é‡‘é¢çš„ç»å¯¹å€¼æ’åº
        reverse_sort = (sort_order == 'desc')

        def _key(item):
            if sort_field in {"volume", "oi", "current_oi_usd"}:
                return item.get('current_oi_usd', 0)
            if sort_field in {"price"}:
                return item.get('current_price', 0)
            if sort_field in {"change_percent", "placeholder"}:
                return abs(item.get('change_percent', 0))
            return abs(item.get('change_usd', 0))

        sorted_data = sorted(processed_data, key=_key, reverse=reverse_sort)[:limit]
        
        # å‡†å¤‡æ•°æ®è¡Œ
        data_rows = []
        for i, item in enumerate(sorted_data, 1):
            symbol = item['symbol']
            change_percent = item['change_percent']
            change_usd = item['change_usd']
            
            # æ ¼å¼åŒ–å˜åŒ–é‡‘é¢
            if abs(change_usd) >= 1e9:
                if change_usd >= 0:
                    change_value_str = f"+${change_usd/1e9:.2f}B"
                else:
                    change_value_str = f"-${abs(change_usd)/1e9:.2f}B"
            elif abs(change_usd) >= 1e6:
                if change_usd >= 0:
                    change_value_str = f"+${change_usd/1e6:.2f}M"
                else:
                    change_value_str = f"-${abs(change_usd)/1e6:.2f}M"
            elif abs(change_usd) >= 1e3:
                if change_usd >= 0:
                    change_value_str = f"+${change_usd/1e3:.2f}K"
                else:
                    change_value_str = f"-${abs(change_usd)/1e3:.2f}K"
            else:
                if change_usd >= 0:
                    change_value_str = f"+${change_usd:.0f}"
                else:
                    change_value_str = f"-${abs(change_usd):.0f}"
            
            # æ˜¾ç¤ºå˜åŒ–ç™¾åˆ†æ¯”
            if change_percent >= 0:
                change_percent_str = f"+{change_percent:.2f}%"
            else:
                change_percent_str = f"{change_percent:.2f}%"
            
            data_rows.append([
                f"{i}.",
                symbol,
                change_value_str,
                change_percent_str
            ])
        
        # åŠ¨æ€å¯¹é½æ ¼å¼åŒ–
        aligned_data = self.dynamic_align_format(data_rows)
        
        time_info = self.get_current_time_display()
        
        # æ—¶é—´å‘¨æœŸæ˜¾ç¤º
        period_display = {
            '5m': '5åˆ†é’Ÿ', '15m': '15åˆ†é’Ÿ', '30m': '30åˆ†é’Ÿ',
            '1h': '1å°æ—¶', '4h': '4å°æ—¶', '24h': '24å°æ—¶'
        }
        period_text = period_display.get(period, period)
        
        # æ’åºæ–¹å¼æ˜¾ç¤º
        sort_symbol = "â¬‡ï¸" if sort_order == 'desc' else "ğŸ”¼"
        sort_text = "é™åº" if sort_order == 'desc' else "å‡åº"
        
        cache_info = ""
        text = f"""ğŸ‹ æŒä»“é‡æ’è¡Œ - å¤§é²¸è¿½è¸ªï¼Œèµ„é‡‘å—…æ¢ ğŸ‹
â° æ›´æ–° {time_info['full']}
ğŸ“Š æ’åº {period_text}å˜åŒ–é‡‘é¢({sort_symbol}) / {sort_text}
æ’å/å¸ç§/{period_text}å˜åŒ–å€¼/{period_text}å˜åŒ–%
```
{aligned_data}
```
ğŸ’¡ æŒ‰{period_text}å†…æŒä»“é‡å˜åŒ–é‡‘é¢æ’åº
ğŸ“ˆ {period_text}å˜åŒ–å€¼: {period_text}å†…æŒä»“é‡å…·ä½“å˜åŒ–é‡‘é¢
â° æœ€åæ›´æ–° {time_info['full']}{cache_info}"""
        
        return text
    def get_position_ranking_keyboard(self, current_sort='desc', current_limit=10, current_period='24h'):
        """è·å–æŒä»“é‡æ’è¡Œæ¦œé”®ç›˜"""
        # æ—¶é—´å‘¨æœŸæŒ‰é’®ï¼ˆç¬¬ä¸€è¡Œå’Œç¬¬äºŒè¡Œï¼‰- æ–°å¢æ›´å¤šå‘¨æœŸ
        period_buttons_row1 = []
        period_buttons_row2 = []
        periods_row1 = [('5m', '5åˆ†'), ('15m', '15åˆ†'), ('30m', '30åˆ†')]
        periods_row2 = [('1h', '1å°æ—¶'), ('4h', '4å°æ—¶'), ('24h', '24å°æ—¶')]
        
        for period_value, period_text in periods_row1:
            if period_value == current_period:
                period_buttons_row1.append(InlineKeyboardButton(f"âœ…{period_text}", callback_data=f"position_period_{period_value}"))
            else:
                period_buttons_row1.append(InlineKeyboardButton(period_text, callback_data=f"position_period_{period_value}"))
        
        for period_value, period_text in periods_row2:
            if period_value == current_period:
                period_buttons_row2.append(InlineKeyboardButton(f"âœ…{period_text}", callback_data=f"position_period_{period_value}"))
            else:
                period_buttons_row2.append(InlineKeyboardButton(period_text, callback_data=f"position_period_{period_value}"))
        
        # æ’åºå’Œæ•°é‡æŒ‰é’®åˆå¹¶ä¸ºä¸€è¡Œï¼ˆç¬¬ä¸‰è¡Œï¼‰
        sort_limit_buttons = []
        
        # æ’åºæŒ‰é’®
        if current_sort == 'desc':
            sort_limit_buttons.append(InlineKeyboardButton("âœ…é™åº", callback_data="position_sort_desc"))
            sort_limit_buttons.append(InlineKeyboardButton("å‡åº", callback_data="position_sort_asc"))
        else:
            sort_limit_buttons.append(InlineKeyboardButton("é™åº", callback_data="position_sort_desc"))
            sort_limit_buttons.append(InlineKeyboardButton("âœ…å‡åº", callback_data="position_sort_asc"))
        
        # æ•°é‡æŒ‰é’®
        limits = [10, 20, 30]
        for limit_val in limits:
            if limit_val == current_limit:
                sort_limit_buttons.append(InlineKeyboardButton(f"âœ…{limit_val}æ¡", callback_data=f"position_{limit_val}"))
            else:
                sort_limit_buttons.append(InlineKeyboardButton(f"{limit_val}æ¡", callback_data=f"position_{limit_val}"))
        
        keyboard = [
            period_buttons_row1,  # ç¬¬ä¸€è¡Œï¼š5åˆ† 15åˆ† 30åˆ†
            period_buttons_row2,  # ç¬¬äºŒè¡Œï¼š1å°æ—¶ 4å°æ—¶ 24å°æ—¶
            sort_limit_buttons,   # ç¬¬ä¸‰è¡Œï¼šæ’åºå’Œæ•°é‡æŒ‰é’®åˆå¹¶
            [                     # ç¬¬å››è¡Œï¼šåŠŸèƒ½æŒ‰é’®
                InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"),
                InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="position_ranking")
            ]
        ]
        return InlineKeyboardMarkup(keyboard)

    def fetch_24hr_ticker_data(self):
        """è·å–24å°æ—¶ä»·æ ¼å˜åŠ¨æ•°æ®"""
        return self.futures_client.get_24hr_ticker()

    def fetch_kline_volume_data(self, period='24h'):
        """è·å–æŒ‡å®šæ—¶é—´å‘¨æœŸçš„Kçº¿äº¤æ˜“é‡æ•°æ®"""
        try:
            # å‘¨æœŸæ˜ å°„åˆ°Kçº¿é—´éš”
            period_map = {
                '24h': '1d',  # 24å°æ—¶
                '12h': '12h', # 12å°æ—¶
                '4h': '4h',   # 4å°æ—¶
                '15m': '15m'  # 15åˆ†é’Ÿ
            }
            
            interval = period_map.get(period, '1d')
            major_symbols = self.get_active_symbols()[:50]  # è·å–å‰50ä¸ªæ´»è·ƒäº¤æ˜“å¯¹
            
            volume_data = []
            
            for symbol in major_symbols:
                try:
                    # è·å–æœ€è¿‘çš„Kçº¿æ•°æ®
                    klines = self.futures_client.get_klines(
                        symbol=symbol,
                        interval=interval,
                        limit=2  # è·å–æœ€è¿‘2æ ¹Kçº¿
                    )
                    
                    if klines and len(klines) >= 1:
                        # Kçº¿æ•°æ®æ ¼å¼: [å¼€ç›˜æ—¶é—´, å¼€ç›˜ä»·, æœ€é«˜ä»·, æœ€ä½ä»·, æ”¶ç›˜ä»·, æˆäº¤é‡, æ”¶ç›˜æ—¶é—´, æˆäº¤é¢, ...]
                        latest_kline = klines[-1]  # æœ€æ–°çš„Kçº¿
                        
                        open_price = float(latest_kline[1])
                        high_price = float(latest_kline[2])
                        low_price = float(latest_kline[3])
                        close_price = float(latest_kline[4])
                        volume = float(latest_kline[5])  # æˆäº¤é‡
                        quote_volume = float(latest_kline[7])  # æˆäº¤é¢(USDT)
                        
                        # è®¡ç®—ä»·æ ¼å˜åŒ–ç™¾åˆ†æ¯”
                        price_change_percent = ((close_price - open_price) / open_price) * 100 if open_price > 0 else 0
                        
                        volume_data.append({
                            'symbol': symbol,
                            'lastPrice': str(close_price),
                            'highPrice': str(high_price),
                            'lowPrice': str(low_price),
                            'volume': str(volume),
                            'quoteVolume': str(quote_volume),
                            'priceChangePercent': str(price_change_percent),
                            'period': period
                        })
                        
                except Exception as e:
                    logger.debug(f"è·å–{symbol} {period}å‘¨æœŸKçº¿æ•°æ®å¤±è´¥: {e}")
                    continue
            
            return volume_data
            
        except Exception as e:
            logger.error(f"è·å–{period}å‘¨æœŸKçº¿äº¤æ˜“é‡æ•°æ®å¤±è´¥: {e}")
            return []

def is_group_mention_required(update: Update) -> bool:
    """ç¾¤ç»„å†…æ˜¯å¦å¿…é¡» @ æ‰å“åº” â€”â€” å·²æ”¾å®½ï¼Œé»˜è®¤ä¸è¦æ±‚ã€‚"""
    return False

async def start(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¯åŠ¨å‘½ä»¤å¤„ç†å™¨"""
    global user_handler, invitation_manager
    print("ğŸš€ æ”¶åˆ° /start å‘½ä»¤")

    # ç™½åå•æ‹¦æˆªï¼šç¾¤/è¯é¢˜ç¦ç”¨æ—¶ä»…å…è®¸ /help
    if not _is_command_allowed(update):
        return
    
    if user_handler is None:
        logger.error("âŒ user_handler æœªåˆå§‹åŒ–")
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return

    # ç¡®ä¿é‚€è¯·ç®¡ç†å™¨å·²åˆå§‹åŒ–ï¼ˆé˜²æ­¢Noneå¯¼è‡´é‚€è¯·ç åŠŸèƒ½å¤±æ•ˆï¼‰
    if invitation_manager is None:
        try:
            invitation_manager = IntegratedInvitationManager()
            logger.info("âœ… invitation_manager å·²è‡ªåŠ¨åˆå§‹åŒ–")
        except Exception as e:
            logger.warning(f"âš ï¸ invitation_manager åˆå§‹åŒ–å¤±è´¥: {e}")

    try:
        logger.info("âœ… user_handler å·²åˆå§‹åŒ–ï¼Œå¼€å§‹å¤„ç† /start å‘½ä»¤")
        
        user = update.effective_user
        user_id = user.id
        
        # æ£€æŸ¥æ˜¯å¦æœ‰é‚€è¯·ç å‚æ•°
        invitation_code = None
        if context.args and len(context.args) > 0:
            invitation_code = context.args[0]
            print(f"ğŸ“¨ æ£€æµ‹åˆ°é‚€è¯·ç : {invitation_code}")
        
        # æ£€æŸ¥ç”¨æˆ·æ˜¯å¦æ˜¯æ–°ç”¨æˆ·ï¼ˆé€šè¿‡æ£€æŸ¥ç”¨æˆ·æ•°æ®ä¸­æ˜¯å¦å·²æœ‰invited_bonus_givenæ ‡è®°ï¼‰
        user_data = DataManager.get_user_data(user_id)
        is_new_user = user_data.get('invited_bonus_given') is None
        
        # å¦‚æœæœ‰é‚€è¯·ç ä¸”æ˜¯æ–°ç”¨æˆ·ï¼Œå¤„ç†é‚€è¯·å…³ç³»å¹¶ç»™äºˆé¢å¤–ç§¯åˆ†
        if invitation_code and is_new_user and invitation_manager:
            try:
                # å¤„ç†é‚€è¯·å…³ç³»
                success = invitation_manager.process_invitation(
                    invitee_id=user_id,
                    invitation_code=invitation_code,
                    invitee_username=user.username or user.first_name or ""
                )
                
                if success:
                    logger.info(f"âœ… é‚€è¯·å…³ç³»å»ºç«‹æˆåŠŸ: {user_id} <- {invitation_code}")
                    
                    # ç»™æ–°ç”¨æˆ·é‚€è¯·å¥–åŠ±
                    old_points = user_data['points']
                    user_data['points'] += 20
                    user_data['invited_bonus_given'] = True  # æ ‡è®°å·²ç»™äºˆé‚€è¯·å¥–åŠ±
                    user_data['invited_by'] = invitation_code  # è®°å½•é‚€è¯·ç 
                    user_data['username'] = user.username or user.first_name or ""
                    user_data['last_active'] = beijing_time_isoformat()
                    
                    # æ›´æ–°ç”¨æˆ·æ•°æ®
                    DataManager.update_user_data(user_id, user_data)
                    
                    # æ·»åŠ ç§¯åˆ†å†å²è®°å½•
                    DataManager.add_points_history(
                        user_id=user_id,
                        change=20,
                        reason=f"é€šè¿‡é‚€è¯·ç {invitation_code}æ³¨å†Œå¥–åŠ±",
                        balance_after=user_data['points']
                    )
                    
                    print(f"ğŸ é‚€è¯·å¥–åŠ±å·²å‘æ”¾: ç”¨æˆ·{user_id}è·å¾—é‚€è¯·å¥–åŠ±ï¼Œæ€»ç§¯åˆ†{user_data['points']}")
                    
                    # å‘é€ç‰¹æ®Šçš„æ¬¢è¿æ¶ˆæ¯
                    await update.message.reply_text(
                        f"ğŸ‰ æ¬¢è¿é€šè¿‡é‚€è¯·åŠ å…¥tukuaiæœºå™¨äººï¼\n\n"
                        f"ğŸ’ æ‚¨å·²è·å¾—é‚€è¯·å¥–åŠ±\n"
                        f"ğŸ’ å½“å‰æ€»ç§¯åˆ†: {user_data['points']}\n\n"
                        f"âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–",
                        reply_markup=user_handler.get_reply_keyboard(),
                        parse_mode='Markdown'
                    )
                else:
                    logger.warning(f"âš ï¸ é‚€è¯·å…³ç³»å»ºç«‹å¤±è´¥: é‚€è¯·ç {invitation_code}æ— æ•ˆæˆ–ç”¨æˆ·{user_id}å·²è¢«é‚€è¯·")
            except Exception as e:
                logger.error(f"âŒ å¤„ç†é‚€è¯·ç å¤±è´¥: {e}")
        
        # ç”Ÿæˆä¸»èœå• - ä½¿ç”¨ä¸åº•éƒ¨ä¸»èœå•æŒ‰é’®ç›¸åŒçš„é€»è¾‘
        print("ğŸ“‹ æ­£åœ¨ç”Ÿæˆä¸»èœå•...")
        text = user_handler.get_main_menu_text()
        inline_keyboard = user_handler.get_main_menu_keyboard()
        reply_keyboard = user_handler.get_reply_keyboard()
        
        # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
        text = ensure_valid_text(text, "âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–")
        
        # å¦‚æœä¸æ˜¯é‚€è¯·æ³¨å†Œï¼Œå‘é€æ™®é€šæ¬¢è¿æ¶ˆæ¯
        if not (invitation_code and is_new_user):
            # å…ˆå‘é€ç®€çŸ­æ¬¢è¿æ¶ˆæ¯å’Œå¸¸é©»é”®ç›˜æ¥æ¿€æ´»å¸¸é©»é”®ç›˜
            await update.message.reply_text(
                "âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–",
                reply_markup=reply_keyboard      # æ¿€æ´»å¸¸é©»é”®ç›˜
            )
        
        # å†å‘é€å®Œæ•´ä¸»èœå•æ–‡æœ¬å’Œå†…è”é”®ç›˜
        await update.message.reply_text(
            text,
            reply_markup=inline_keyboard     # ä½¿ç”¨å†…è”é”®ç›˜
        )
        
        logger.info("âœ… ä¸»èœå•å’Œå¸¸é©»é”®ç›˜å‘é€æˆåŠŸ")
        
    except Exception as e:
        logger.error(f"âŒ /start å‘½ä»¤å¤„ç†å‡ºé”™: {e}")
        import traceback
        traceback.print_exc()
        await update.message.reply_text(
            f"âŒ å¯åŠ¨æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}"
        )

def ensure_valid_text(text, fallback="ğŸ”„ æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•..."):
    """ç¡®ä¿æ–‡æœ¬æœ‰æ•ˆï¼Œä¸ä¸ºç©ºï¼Œå¹¶ä¸”æœ‰å®é™…å†…å®¹"""
    try:
        if text and isinstance(text, str) and len(text.strip()) > 0:
            # è¿›ä¸€æ­¥æ£€æŸ¥æ˜¯å¦åŒ…å«æœ‰æ„ä¹‰çš„å†…å®¹
            if text.strip() not in ["", "None", "null", "undefined"]:
                return text
        # å¦‚æœæ–‡æœ¬æ— æ•ˆï¼Œè¿”å›fallback
        return fallback
    except Exception as e:
        logger.warning(f"âš ï¸ ensure_valid_textå¤„ç†å¼‚å¸¸: {e}")
        return fallback

def mdv2(text: str) -> str:
    """å…¼å®¹æ—§è°ƒç”¨ï¼Œç›´æ¥è¿”å›åŸæ–‡ï¼ˆç»Ÿä¸€ä½¿ç”¨Markdownæ™®é€šæ¨¡å¼ï¼‰"""
    return text or ""
def _build_ranking_menu_text(group: str) -> str:
    """æ ¹æ®åˆ†ç»„è¿”å›æ’è¡Œæ¦œèœå•æ–‡æ¡ˆ"""
    return (
        "ğŸ“Š æ•°æ®é¢æ¿\n"
        "â”œâ”€ é€‰æ¦œå•è¿›å…¥è¯¦æƒ…\n"
        "â”œâ”€ é€‰å‘¨æœŸï¼š1m/5m/15m/1h/4h/1d/1w\n"
        "â”œâ”€ æ’åºï¼šå­—æ®µå‡/é™åºåˆ‡æ¢\n"
        "â””â”€ å­—æ®µï¼šæŒ‰é’®ç‚¹ä¸€ä¸‹å¼€/å…³\n\n"
        "ğŸ‘‡ è¯·é€‰æ‹©è¦æŸ¥çœ‹çš„æ¦œå•"
    )


async def button_callback(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æŒ‰é’®å›è°ƒå¤„ç†å™¨ - ä¼˜åŒ–ç‰ˆæœ¬ï¼šç«‹å³å“åº” + å¼‚æ­¥å¤„ç† + ç‚¹å‡»é¢‘ç‡é™åˆ¶"""
    global user_handler, invitation_manager, subscription_manager

    # ğŸ”§ ä¿®å¤ï¼šç¡®ä¿å¯¼å…¥å¯ç”¨ï¼Œé˜²æ­¢ UnboundLocalError
    from telegram import InlineKeyboardMarkup, InlineKeyboardButton

    query = update.callback_query
    user_id = query.from_user.id
    button_data = query.data
    chat_type = query.message.chat.type
    thread_id = getattr(query.message, "message_thread_id", None)
    retention_seconds = _get_retention(query.message.chat.id) if chat_type in {"group", "supergroup"} else 0
    if retention_seconds > 0:
        # æå‰ä¸ºå½“å‰äº¤äº’æ¶ˆæ¯æŒ‚ä¸Šè‡ªåŠ¨åˆ é™¤ä»»åŠ¡ï¼Œç¡®ä¿æŒ‰é’®å¡ç‰‡ä¹Ÿä¼šè¿‡æœŸæ¸…ç†
        asyncio.create_task(_schedule_auto_delete(context.bot, query.message.chat.id, query.message.message_id, retention_seconds))

    # å…¨å±€ç™½åå•æ‹¦æˆªï¼ˆé™¤ /help ç›¸å…³ä»¥å¤–ï¼‰
    allow, deny_reason = _is_bot_allowed(query.message.chat, thread_id)
    help_related = (
        button_data in {"help", "group_enable", "group_disable", "topic_enable", "topic_disable", "channel_enable", "channel_disable"}
        or button_data.startswith("ttl:")
    )
    if not allow and not help_related:
        # ç¦ç”¨çŠ¶æ€ç»™å‡ºæç¤ºï¼Œé¿å…è¯¯åˆ¤
        try:
            await query.answer(deny_reason or "æœ¬é¢‘é“å·²å…³é—­æœºå™¨äººï¼Œç‚¹å‡»å¼€å¯åå†è¯•ã€‚", show_alert=True)
        except Exception as exc:
            logger.warning("âš ï¸ ç¦ç”¨çŠ¶æ€ä¸‹æ— æ³•æç¤ºç”¨æˆ·: %s", exc)
        return

    # AI å›è°ƒä¼˜å…ˆåˆ†å‘ï¼Œé¿å…è¯¯å…¥é»˜è®¤åˆ†æ”¯
    if button_data in {"start_ai_analysis", "start_coin_analysis"}:
        # æš‚æœªå¼€æ”¾å ä½
        kb = InlineKeyboardMarkup(
            [[
                InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"),
                InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="main_menu")
            ]]
        )
        await query.edit_message_text(
            "ğŸ¤– AIåˆ†æåŠŸèƒ½æš‚æœªå¼€æ”¾",
            reply_markup=kb,
            parse_mode='Markdown',
        )
        return

    # ä¿¡å·å ä½ï¼šåŒæ ·æš‚æœªå¼€æ”¾
    if button_data in {"signal_menu", "aggregated_alerts"}:
        kb = InlineKeyboardMarkup(
            [[
                InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"),
                InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="main_menu")
            ]]
        )
        await query.edit_message_text(
            "ğŸš¨ ä¿¡å·åŠŸèƒ½æš‚æœªå¼€å‘",
            reply_markup=kb,
            parse_mode='Markdown',
        )
        return

    # ğŸ›¡ï¸ ç‚¹å‡»é¢‘ç‡é™åˆ¶æ£€æŸ¥
    can_click, remaining_cooldown = check_click_rate_limit(user_id)
    if not can_click:
        try:
            await query.answer(f"â³ è¯·ç¨ç­‰ 0.1 ç§’", show_alert=True)
            logger.info(f"ğŸ›¡ï¸ ç”¨æˆ· {user_id} ç‚¹å‡»è¿‡å¿«ï¼Œå‰©ä½™: {remaining_cooldown:.2f}ç§’")
            return
        except Exception as e:
            logger.error(f"âŒ å‘é€é¢‘ç‡é™åˆ¶æç¤ºå¤±è´¥: {e}")
            return

    # ğŸš€ ç¬¬ä¸€ä¼˜å…ˆçº§ï¼šç«‹å³å“åº”ç”¨æˆ·ï¼ˆ100mså†…å®Œæˆï¼‰
    start_time = time.time()
    try:
        await query.answer("å¤„ç†ä¸­...")  # ç«‹å³ç¡®è®¤
        immediate_response_time = (time.time() - start_time) * 1000
        logger.info(f"ğŸš€ ç”¨æˆ· {user_id} æŒ‰é’® '{button_data}' ç«‹å³å“åº”: {immediate_response_time:.1f}ms")
    except Exception as answer_error:
        logger.error(f"âŒ ç«‹å³å“åº”å¤±è´¥ ç”¨æˆ·{user_id}: {answer_error}")
        # ç»§ç»­å¤„ç†ï¼Œä¸è¦å› ä¸ºç«‹å³å“åº”å¤±è´¥å°±åœæ­¢
    
    # ğŸ“ ä¼˜åŒ–æ—¥å¿—è®°å½•ï¼ˆä½¿ç”¨loggeræ›¿ä»£printï¼‰
    logger.info(f"ğŸ” æŒ‰é’®å›è°ƒ / ç”¨æˆ·: {user_id} / æŒ‰é’®: {button_data} / èŠå¤©: {chat_type}")
    logger.info(f"ğŸ” user_handlerçŠ¶æ€: {user_handler is not None}")
    
    # âš¡ å¼‚æ­¥æ›´æ–°ç”¨æˆ·æ´»è·ƒæ—¶é—´ï¼ˆä¸é˜»å¡ä¸»æµç¨‹ï¼‰
    asyncio.create_task(update_user_last_active_async(user_id))
    
    # ğŸ”§ ç§èŠä¸“ç”¨ï¼šå¦‚æœæ˜¯ç§èŠï¼Œè·³è¿‡ç¾¤ç»„ç›¸å…³æ£€æŸ¥
    if chat_type == 'private':
        logger.info("âœ… ç§èŠç¯å¢ƒï¼Œè·³è¿‡ç¾¤ç»„æ£€æŸ¥")
    
    # å¤„ç†ç®¡ç†å‘˜å›è°ƒ
    if query.data.startswith("admin_"):
        await handle_admin_callback(update, context, query.data)
        return

    # ---- å•å¸å¿«ç…§æŒ‰é’®å¤„ç† ----
    if button_data.startswith("single_"):
        if user_handler is None:
            await query.edit_message_text("âŒ ç³»ç»Ÿæœªå°±ç»ªï¼Œè¯·ç¨åé‡è¯•", parse_mode='Markdown')
            return
        states = user_handler.user_states.setdefault(user_id, {})
        sym = states.get("single_symbol")
        panel = states.get("single_panel", "basic")
        enabled = states.get("single_periods", {"1m": False, "5m": False, "15m": True, "1h": True, "4h": True, "1d": True, "1w": False})
        enabled_cards = states.get("single_cards", {})
        page = states.get("single_page", 0)
        if not sym:
            await query.edit_message_text("è¯·å…ˆå‘é€ä¾‹å¦‚ btc! è§¦å‘å•å¸æŸ¥è¯¢", parse_mode='Markdown')
            return

        reset_page = False
        if button_data.startswith("single_toggle_"):
            period = button_data.replace("single_toggle_", "")
            if panel == "futures" and period == "1m":
                await query.answer("åˆçº¦è§†å›¾ä¸æ”¯æŒ1m", show_alert=False)
            else:
                enabled[period] = not enabled.get(period, False)
                reset_page = True
        elif button_data.startswith("single_panel_"):
            panel = button_data.replace("single_panel_", "")
            if panel == "futures":
                enabled["1m"] = False
                enabled_cards = {}  # futures é»˜è®¤å…¨éƒ¨å¯ç”¨
            elif panel == "basic":
                enabled_cards = {}  # basic é»˜è®¤å…¨éƒ¨å¯ç”¨
            if panel == "advanced":
                from bot.single_token_snapshot import TABLE_FIELDS
                default_adv = {"EMAæ’è¡Œå¡ç‰‡", "ATRæ’è¡Œå¡ç‰‡", "è¶…çº§ç²¾å‡†è¶‹åŠ¿æ’è¡Œå¡ç‰‡"}
                enabled_cards = {k: (k in default_adv) for k in TABLE_FIELDS.get("advanced", {})}
            reset_page = True
        elif button_data.startswith("single_card_"):
            card = button_data.replace("single_card_", "")
            enabled_cards[card] = not enabled_cards.get(card, True)
            reset_page = True
        elif button_data == "single_refresh":
            reset_page = False
        elif button_data == "single_page_prev":
            page = max(0, page - 1)
        elif button_data == "single_page_next":
            page = page + 1
        else:
            # single_nop ç­‰
            return

        if reset_page:
            page = 0

        states["single_panel"] = panel
        states["single_periods"] = enabled
        states["single_cards"] = enabled_cards
        states["single_page"] = page

        text, keyboard, pages, page_used = render_single_snapshot(sym, panel, enabled, enabled_cards, page=page)
        # å¦‚æœç¿»åˆ°è¶…ç•Œé¡µï¼Œå›é€€æœ€åä¸€é¡µå†æ¸²æŸ“ä¸€æ¬¡
        if page_used >= pages:
            page_used = max(0, pages - 1)
            states["single_page"] = page_used
            text, keyboard, pages, page_used = render_single_snapshot(sym, panel, enabled, enabled_cards, page=page_used)
        try:
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
        except BadRequest as e:
            msg = str(e)
            if "message is not modified" in msg:
                await query.edit_message_reply_markup(reply_markup=keyboard)
            elif "message is too long" in msg.lower():
                max_len = 3500
                parts = [text[i:i+max_len] for i in range(0, len(text), max_len)]
                await query.edit_message_text(parts[0], reply_markup=keyboard, parse_mode='Markdown')
                for p in parts[1:]:
                    await query.message.reply_text(p, parse_mode='Markdown')
            else:
                logger.error("å•å¸å¿«ç…§ç¼–è¾‘å¤±è´¥: %s", e)
                await query.message.reply_text("âŒ åˆ·æ–°å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", parse_mode='Markdown')
        return

    # âš–ï¸ è¶…ä¹°è¶…å–å¡ç‰‡ä¸‹çº¿ä¿æŠ¤
    ratio_callbacks = (
        "position_market_ratio",
        "volume_market_ratio",
        "volume_oi_ratio",
        "unified_ratio",
        "ratio_",
        "ratio_sort_",
        "ratio_limit_",
        "ratio_period_",
        "volume_market_",
        "volume_oi_",
        "position_market_",
    )
    if any(button_data.startswith(prefix) for prefix in ratio_callbacks):
        await query.answer("âš–ï¸ å¡ç‰‡å·²ä¸‹çº¿", show_alert=False)
        await query.message.reply_text(
            "âš–ï¸ è¶…ä¹°è¶…å–å¡ç‰‡å·²ä¸‹çº¿ï¼Œæ•¬è¯·æœŸå¾…æ›¿ä»£æ–¹æ¡ˆã€‚",
            reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]]),
            parse_mode='Markdown'
        )
        return
    
    # ç‰¹æ®Šå¤„ç†ï¼šå¦‚æœç”¨æˆ·åœ¨AIå¯¹è¯ä¸­ç‚¹å‡»äº†å…¶ä»–åŠŸèƒ½æŒ‰é’®ï¼Œå¼ºåˆ¶ç»“æŸAIå¯¹è¯çŠ¶æ€
    if query.data in ["ranking_menu", "ranking_menu_group_basic", "ranking_menu_group_futures", "ranking_menu_group_advanced", "position_ranking", "funding_rate", "volume_ranking", "basic_market", "market_sentiment", "liquidation_ranking", "money_flow", "market_depth"]:
        # æ¸…ç†å¯èƒ½çš„AIå¯¹è¯çŠ¶æ€
        if 'selected_symbol' in context.user_data:
            del context.user_data['selected_symbol']
        if 'selected_interval' in context.user_data:
            del context.user_data['selected_interval']
        if 'waiting_manual_input' in context.user_data:
            del context.user_data['waiting_manual_input']
        if 'symbols_page' in context.user_data:
            del context.user_data['symbols_page']
    
    if user_handler is None:
        logger.warning("âš ï¸ user_handlerä¸ºNoneï¼Œå°è¯•å¤šç§æ–¹å¼é‡æ–°åˆå§‹åŒ–...")
        try:
            # æ–¹æ³•1ï¼šå°è¯•ç›´æ¥åˆå§‹åŒ–
            from crypto_trading_bot import UserRequestHandler
            user_handler = UserRequestHandler(card_registry=ensure_ranking_registry())
            logger.info("âœ… ç›´æ¥åˆå§‹åŒ– user_handler æˆåŠŸ")
        except Exception as e1:
            logger.error(f"âŒ ç›´æ¥åˆå§‹åŒ–å¤±è´¥: {e1}")
            try:
                # æ–¹æ³•2ï¼šä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨
                loop = asyncio.get_event_loop()
                await loop.run_in_executor(None, initialize_bot_sync)
                if user_handler is not None:
                    logger.info("âœ… å¼‚æ­¥æ‰§è¡Œå™¨é‡æ–°åˆå§‹åŒ–æˆåŠŸ")
                else:
                    logger.error("âŒ æ‰€æœ‰åˆå§‹åŒ–æ–¹æ³•éƒ½å¤±è´¥")
                    await query.edit_message_text(
                        "ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...\n\nğŸ’¡ å¦‚æœé—®é¢˜æŒç»­ï¼Œè¯·è”ç³»ç®¡ç†å‘˜",
                        reply_markup=InlineKeyboardMarkup([[
                            InlineKeyboardButton("ğŸ”„ é‡è¯•", callback_data="main_menu")
                        ]])
                    )
                    return
            except Exception as e2:
                logger.error(f"âŒ å¼‚æ­¥é‡æ–°åˆå§‹åŒ–ä¹Ÿå¤±è´¥: {e2}")
                await query.edit_message_text(
                    "âŒ æœºå™¨äººåˆå§‹åŒ–å¤±è´¥ï¼Œè¯·è”ç³»ç®¡ç†å‘˜\n\nğŸ”§ é”™è¯¯ä¿¡æ¯å·²è®°å½•",
                    reply_markup=InlineKeyboardMarkup([[
                        InlineKeyboardButton("ğŸ”„ é‡è¯•", callback_data="main_menu")
                    ]])
                )
                return

    registry = ensure_ranking_registry()
    if registry:
        handled = await registry.dispatch(update, context, {
            "user_handler": user_handler,
            "ensure_valid_text": ensure_valid_text,
        })
        if handled:
            return

    try:
        if query.data == "main_menu":
            try:
                # ğŸ”§ å¼ºåŒ–ä¸»èœå•æ–‡æœ¬å¤„ç†ï¼šç¡®ä¿æ°¸è¿œä¸ä¸ºç©º
                try:
                    text = user_handler.get_main_menu_text()
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ä¸»èœå•æ–‡æœ¬å¤±è´¥: {e}")
                    text = None
                
                # å¼ºåˆ¶æ£€æŸ¥ï¼šå¦‚æœæ–‡æœ¬ä¸ºç©ºæˆ–æ— æ•ˆï¼Œä½¿ç”¨é¢„è®¾æ–‡æœ¬
                if not text or len(str(text).strip()) == 0:
                    logger.warning("âš ï¸ ä¸»èœå•æ–‡æœ¬ä¸ºç©ºï¼Œä½¿ç”¨å¼ºåˆ¶é»˜è®¤æ–‡æœ¬")
                    text = """âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–"""
                
                # å†æ¬¡éªŒè¯æ–‡æœ¬æœ‰æ•ˆæ€§
                text = ensure_valid_text(text, """âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–

ğŸ“Š è¯·é€‰æ‹©æ‚¨éœ€è¦çš„åŠŸèƒ½ï¼š
ğŸ’ æŸ¥çœ‹å„ç§å¸‚åœºæ•°æ®
ğŸ’° ç®¡ç†æ‚¨çš„è´¦æˆ·""")
                
                # å¼ºåŒ–é”®ç›˜å¤„ç†ï¼šç¡®ä¿æ°¸è¿œæœ‰é”®ç›˜
                try:
                    keyboard = user_handler.get_main_menu_keyboard()
                except Exception as e:
                    logger.warning(f"âš ï¸ è·å–ä¸»èœå•é”®ç›˜å¤±è´¥: {e}")
                    keyboard = None
                
                if not keyboard:
                    logger.warning("âš ï¸ ä¸»èœå•é”®ç›˜ä¸ºç©ºï¼Œä½¿ç”¨å¼ºåˆ¶é»˜è®¤é”®ç›˜")
                    keyboard = InlineKeyboardMarkup([
                        [
                            InlineKeyboardButton("ğŸ‹ æŒä»“é‡æ’è¡Œ", callback_data="position_ranking"),
                            InlineKeyboardButton("ğŸ“ˆ æˆäº¤é‡æ’è¡Œ", callback_data="volume_ranking")
                        ],
                        [
                            InlineKeyboardButton("ğŸ’¥ çˆ†ä»“æ’è¡Œ", callback_data="liquidation_ranking"),
                            InlineKeyboardButton("ğŸ“ˆ å¸‚åœºæ€»è§ˆ", callback_data="basic_market"),
                            InlineKeyboardButton("ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ", callback_data="user_center")
                        ],
                        [
                            InlineKeyboardButton("ğŸ”„ åˆ·æ–°ä¸»èœå•", callback_data="main_menu")
                        ]
                    ])
                
                await query.edit_message_text(text, reply_markup=keyboard)
                
            except Exception as e:
                logger.error(f"âŒ ä¸»èœå•å¤„ç†é”™è¯¯: {e}")
                # å‘é€æœ€ç®€å•çš„é”™è¯¯æ¢å¤æ¶ˆæ¯
                try:
                    await query.edit_message_text(
                        "âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–\n\nâœ… ç³»ç»Ÿæ­£å¸¸è¿è¡Œ",
                        reply_markup=InlineKeyboardMarkup([
                            [InlineKeyboardButton("ğŸ”„ é‡è¯•", callback_data="main_menu")]
                        ])
                    )
                except:
                    await query.answer("ç³»ç»Ÿæ­£åœ¨é‡æ–°åŠ è½½ï¼Œè¯·ç¨åé‡è¯•")
            
        elif query.data == "cancel_analysis":
            # å¤„ç†AIç‚¹ä½åˆ†æä¸­çš„"è¿”å›ä¸»èœå•"æŒ‰é’®
            # æ¸…ç†AIå¯¹è¯çŠ¶æ€
            if 'selected_symbol' in context.user_data:
                del context.user_data['selected_symbol']
            if 'selected_interval' in context.user_data:
                del context.user_data['selected_interval']
            if 'waiting_manual_input' in context.user_data:
                del context.user_data['waiting_manual_input']
            if 'symbols_page' in context.user_data:
                del context.user_data['symbols_page']
            
            # ç›´æ¥è¿”å›ä¸»èœå•ï¼Œä¸æ˜¾ç¤ºä¸­é—´æç¤º
            text = user_handler.get_main_menu_text()
            keyboard = user_handler.get_main_menu_keyboard()
            text = ensure_valid_text(text, "âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')

        elif query.data == "ranking_menu_nop":
            # æç¤ºæŒ‰é’®ï¼Œç‚¹å‡»æ— å“åº”
            await query.answer()

        elif query.data == "ranking_menu":
            current_group = user_handler.user_states.get("ranking_group", "basic")
            keyboard = user_handler.get_ranking_menu_keyboard()
            await query.edit_message_text(
                _build_ranking_menu_text(current_group),
                reply_markup=keyboard,
                parse_mode='Markdown'
            )

        elif query.data.startswith("ranking_menu_group_"):
            group = query.data.replace("ranking_menu_group_", "")
            if group in {"basic", "futures", "advanced"}:
                user_handler.user_states["ranking_group"] = group
            current_group = user_handler.user_states.get("ranking_group", "basic")
            keyboard = user_handler.get_ranking_menu_keyboard()
            await query.edit_message_text(
                _build_ranking_menu_text(current_group),
                reply_markup=keyboard,
                parse_mode='Markdown'
            )

        # è¯é¢˜å¯ç”¨å¼€å…³ï¼ˆä»…ç¾¤è¯é¢˜ï¼‰
        elif query.data in {"topic_enable", "topic_disable", "group_enable", "group_disable", "channel_enable", "channel_disable"}:
            chat = query.message.chat
            chat_id = chat.id
            thread_id = getattr(query.message, "message_thread_id", None)
            if chat.type not in {"group", "supergroup"}:
                await query.answer("ä»…ç¾¤è¯é¢˜å¯ç”¨", show_alert=True)
                return

            if not await _is_group_admin(context.bot, chat_id, query.from_user.id):
                await query.answer("éœ€è¦ç®¡ç†å‘˜æƒé™", show_alert=True)
                return

            enabled_want = query.data in {"topic_enable", "group_enable", "channel_enable"}

            # ä¸»é¢‘é“ç‹¬ç«‹å¼€å…³ï¼šå†™å…¥ states["__main__"]ï¼Œä¸å½±å“å­é¢‘é“é»˜è®¤å€¼
            if query.data in {"group_enable", "group_disable"}:
                chat_cfg = _set_group_state(chat_id, enabled_want)
                enabled = enabled_want
                target_thread = MAIN_THREAD_KEY
            else:
                # è¯é¢˜/å­é¢‘é“/ä¸»é¢‘é“å•ç‹¬å¼€å…³
                if query.data in {"topic_enable", "topic_disable"} and thread_id is None:
                    thread_id = None
                target_thread = MAIN_THREAD_KEY if thread_id is None else thread_id
                chat_cfg, enabled = _set_topic_state(chat_id, target_thread, enabled_want)

            logger.info("ğŸ” topic toggle action=%s chat=%s thread=%s enabled=%s cfg=%s",
                        query.data, chat_id, thread_id, enabled, chat_cfg)

            keyboard = _build_help_keyboard(chat_id, thread_id, chat.type)
            # å…ˆå°è¯•æ”¹ reply_markupï¼›å¦‚æç¤ºæœªä¿®æ”¹åˆ™å¿½ç•¥
            try:
                await query.edit_message_reply_markup(reply_markup=keyboard)
            except Exception as exc:
                err_msg = str(exc)
                if "Message is not modified" not in err_msg:
                    try:
                        await query.edit_message_text(
                            query.message.text,
                            reply_markup=keyboard,
                            parse_mode='Markdown'
                        )
                    except Exception:
                        pass

            await query.answer("çŠ¶æ€å·²æ›´æ–°" if enabled else "å·²å…³é—­æœ¬è¯é¢˜", show_alert=False)

        # TTL è®¾ç½®ï¼ˆç¾¤èŠï¼‰
        elif query.data.startswith("ttl:"):
            chat = query.message.chat
            chat_id = chat.id
            thread_id = getattr(query.message, "message_thread_id", None)
            if chat.type not in {"group", "supergroup"}:
                await query.answer("ä»…ç¾¤èŠå¯ç”¨", show_alert=True)
                return

            if not await _is_group_admin(context.bot, chat_id, query.from_user.id):
                await query.answer("éœ€è¦ç®¡ç†å‘˜æƒé™", show_alert=True)
                return

            try:
                seconds = int(query.data.split(":", 1)[1])
            except Exception:
                seconds = 0

            chat_cfg = _set_retention(chat_id, seconds)
            keyboard = _build_help_keyboard(chat_id, thread_id, chat.type)
            try:
                await query.edit_message_reply_markup(reply_markup=keyboard)
            except Exception:
                await query.edit_message_text(
                    query.message.text,
                    reply_markup=keyboard,
                    parse_mode='Markdown'
                )

            label = dict(TTL_OPTIONS).get(chat_cfg.get("retention_seconds", 0), f"{chat_cfg.get('retention_seconds', 0)}ç§’")
            await query.answer(f"å·²è®¾ç½®æ¶ˆæ¯ä¿ç•™ï¼š{label}", show_alert=False)

            # ç«‹å³å¯¹å½“å‰å¸®åŠ©æ¶ˆæ¯åº”ç”¨æ–°çš„ TTLï¼Œé¿å…â€œç‚¹å®ŒæŒ‰é’®æ—§æ¶ˆæ¯ä¸åˆ â€
            if seconds > 0:
                asyncio.create_task(_schedule_auto_delete(context.bot, chat_id, query.message.message_id, seconds))

        elif query.data == "market_sentiment":
            await query.message.reply_text(
                "â¸ï¸ å¸‚åœºæƒ…ç»ªæ¦œå•å·²ä¸‹çº¿ï¼Œæ•¬è¯·æœŸå¾…æ–°çš„æŒ‡æ ‡é¢æ¿ã€‚",
                reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]]),
                parse_mode='Markdown'
            )
            await query.answer()
        
        elif query.data == "basic_market":
            # å…è´¹åŠŸèƒ½ - ç›´æ¥æä¾›æœåŠ¡
            loop = asyncio.get_event_loop()

            # å®‰å…¨è·å–ç”¨æˆ·çŠ¶æ€ï¼Œä½¿ç”¨é»˜è®¤å€¼
            sort_type = user_handler.user_states.get('basic_market_sort_type', 'change')
            period = user_handler.user_states.get('basic_market_period', '24h')
            sort_order = user_handler.user_states.get('basic_market_sort_order', 'desc')
            limit = user_handler.user_states.get('basic_market_limit', 10)
            market_type = user_handler.user_states.get('basic_market_type', 'futures')

            text = await loop.run_in_executor(None, lambda: user_handler.get_basic_market(
                sort_type=sort_type,
                period=period,
                sort_order=sort_order,
                limit=limit,
                market_type=market_type
            ))
            text = ensure_valid_text(text, "ğŸ“Š åŸºç¡€å¸‚åœºæ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_basic_market_keyboard(
                current_sort_type=sort_type,
                current_period=period,
                current_sort_order=sort_order,
                current_limit=limit,
                current_market_type=market_type
            )
            await query.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        elif query.data == "money_flow":
            # ğŸ”§ ä¿®å¤ï¼šä»˜è´¹åŠŸèƒ½ - ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨é¿å…é˜»å¡
            user_id = query.from_user.id
            
            # å¼‚æ­¥æ£€æŸ¥æƒé™
            loop = asyncio.get_event_loop()
            can_access, error_msg = await loop.run_in_executor(
                None, user_handler.check_feature_access, user_id, "money_flow"
            )
            
            if not can_access:
                await query.message.reply_text(error_msg, parse_mode='Markdown')
                return
                
            # å¼‚æ­¥æ‰£é™¤ç§¯åˆ†
            deduct_success = await loop.run_in_executor(
                None, user_handler.deduct_feature_cost, user_id, "money_flow"
            )
            
            if not deduct_success:
                await query.message.reply_text("ğŸ’ ç§¯åˆ†æ‰£é™¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", parse_mode='Markdown')
                return
            
            # å¼‚æ­¥è·å–æ•°æ®
            text = await loop.run_in_executor(
                None, user_handler.get_money_flow,
                user_handler.user_states['money_flow_limit'], 
                user_handler.user_states['money_flow_period'],
                user_handler.user_states['money_flow_sort'], 
                user_handler.user_states['money_flow_type'],
                user_handler.user_states['money_flow_market']
            )
            keyboard = user_handler.get_money_flow_keyboard(
                current_period=user_handler.user_states['money_flow_period'],
                current_sort=user_handler.user_states['money_flow_sort'], 
                current_limit=user_handler.user_states['money_flow_limit'], 
                current_flow_type=user_handler.user_states['money_flow_type'],
                current_market=user_handler.user_states['money_flow_market']
            )
            text = ensure_valid_text(text, "ğŸ’° èµ„é‡‘æµå‘æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            
            await query.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        elif query.data == "market_depth":
            # ğŸ”§ ä¿®å¤ï¼šä»˜è´¹åŠŸèƒ½ - ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨é¿å…é˜»å¡
            user_id = query.from_user.id
            
            # å¼‚æ­¥æ£€æŸ¥æƒé™
            loop = asyncio.get_event_loop()
            can_access, error_msg = await loop.run_in_executor(
                None, user_handler.check_feature_access, user_id, "market_depth"
            )
            
            if not can_access:
                await query.message.reply_text(error_msg, parse_mode='Markdown')
                return
                
            # å¼‚æ­¥æ‰£é™¤ç§¯åˆ†
            deduct_success = await loop.run_in_executor(
                None, user_handler.deduct_feature_cost, user_id, "market_depth"
            )
            
            if not deduct_success:
                await query.message.reply_text("ğŸ’ ç§¯åˆ†æ‰£é™¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", parse_mode='Markdown')
                return
            
            # å¼‚æ­¥è·å–æ•°æ®
            text = await loop.run_in_executor(
                None, user_handler.get_market_depth,
                user_handler.user_states.get('market_depth_limit', 10),
                user_handler.user_states.get('market_depth_sort_type', 'ratio'),
                user_handler.user_states.get('market_depth_sort', 'desc')
            )
            keyboard = user_handler.get_market_depth_keyboard(
                current_limit=user_handler.user_states.get('market_depth_limit', 10),
                current_sort_type=user_handler.user_states.get('market_depth_sort_type', 'ratio'),
                current_sort=user_handler.user_states.get('market_depth_sort', 'desc')
            )
            text = ensure_valid_text(text, "ğŸ“Š å¸‚åœºæ·±åº¦æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            
            await query.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
            

            
        # ğŸ”§ ä¿®å¤ï¼šæ™ºèƒ½æ•°é‡é€‰æ‹©æŒ‰é’®å¤„ç† - ä½¿ç”¨å¼‚æ­¥æ‰§è¡Œå™¨é¿å…é˜»å¡
        # âš ï¸ æ’é™¤å……å€¼/è®¢å•åˆ·æ–°ç­‰åŒååç¼€æŒ‰é’®ï¼Œé¿å…è¯¯åˆ¤å¹¶æŠ¢å å›è°ƒ
        elif (
            "_" in query.data
            and query.data.split("_")[-1] in ["10", "20", "30"]
            and not query.data.startswith(("recharge_", "refresh_order_"))
        ):
            # è§£ææŒ‰é’®ç±»å‹å’Œæ•°é‡
            parts = query.data.split("_")
            limit = int(parts[-1])
            feature_type = "_".join(parts[:-1])
            
            loop = asyncio.get_event_loop()
            
            # æ ¹æ®åŠŸèƒ½ç±»å‹æ›´æ–°ç”¨æˆ·çŠ¶æ€å¹¶è°ƒç”¨ç›¸åº”çš„æ–¹æ³•
            if feature_type == "position":
                user_handler.user_states['position_limit'] = limit
                text = await loop.run_in_executor(
                    None, user_handler.get_position_ranking, 
                    limit, user_handler.user_states['position_sort'], user_handler.user_states['position_period']
                )
                keyboard = user_handler.get_position_ranking_keyboard(current_sort=user_handler.user_states['position_sort'], current_limit=limit, current_period=user_handler.user_states['position_period'])
            elif feature_type == "funding":
                user_handler.user_states['funding_limit'] = limit
                text = await loop.run_in_executor(
                    None, user_handler.get_funding_rate_ranking, 
                    limit, user_handler.user_states['funding_sort']
                )
                keyboard = user_handler.get_funding_rate_keyboard(current_sort=user_handler.user_states['funding_sort'], current_limit=limit)
            elif feature_type == "liquidation":
                user_handler.user_states['liquidation_limit'] = limit
                text = await loop.run_in_executor(
                    None, user_handler.get_liquidation_ranking,
                    limit, 
                    user_handler.user_states['liquidation_sort'],
                    user_handler.user_states['liquidation_period'],
                    user_handler.user_states['liquidation_type']
                )
                keyboard = user_handler.get_liquidation_ranking_keyboard(
                    current_limit=limit, 
                    current_sort=user_handler.user_states['liquidation_sort'],
                    current_period=user_handler.user_states['liquidation_period'],
                    current_type=user_handler.user_states['liquidation_type']
                )

            elif feature_type == "money_flow":
                user_handler.user_states['money_flow_limit'] = limit
                text = await loop.run_in_executor(
                    None, user_handler.get_money_flow,
                    limit, 
                    user_handler.user_states['money_flow_period'],
                    user_handler.user_states['money_flow_sort'], 
                    user_handler.user_states['money_flow_type'],
                    user_handler.user_states['money_flow_market']
                )
                keyboard = user_handler.get_money_flow_keyboard(
                    current_period=user_handler.user_states['money_flow_period'],
                    current_sort=user_handler.user_states['money_flow_sort'], 
                    current_limit=limit, 
                    current_flow_type=user_handler.user_states['money_flow_type'],
                    current_market=user_handler.user_states['money_flow_market']
                )
            elif feature_type == "market_depth":
                user_handler.user_states['market_depth_limit'] = limit
                text = await loop.run_in_executor(
                    None, user_handler.get_market_depth,
                    limit,
                    user_handler.user_states.get('market_depth_sort_type', 'ratio'),
                    user_handler.user_states.get('market_depth_sort', 'desc')
                )
                keyboard = user_handler.get_market_depth_keyboard(
                    current_limit=limit,
                    current_sort_type=user_handler.user_states.get('market_depth_sort_type', 'ratio'),
                    current_sort=user_handler.user_states.get('market_depth_sort', 'desc')
                )

            elif feature_type == "position_market":
                user_handler.user_states['position_market_limit'] = limit
                user_handler.user_states['current_ratio_type'] = 'position_market'
                text = await loop.run_in_executor(
                    None, user_handler.get_unified_ratio_data, 
                    limit, user_handler.user_states['position_market_sort'], 'position_market'
                )
                keyboard = user_handler.get_unified_ratio_keyboard(
                    current_sort=user_handler.user_states['position_market_sort'], 
                    current_limit=limit,
                    current_ratio_type='position_market'
                )
            elif feature_type == "basic_market":
                user_handler.user_states['basic_market_limit'] = limit
                text = await loop.run_in_executor(
                    None, lambda: user_handler.get_basic_market(
                        sort_type=user_handler.user_states['basic_market_sort_type'],
                        period=user_handler.user_states['basic_market_period'],
                        sort_order=user_handler.user_states['basic_market_sort_order'],
                        limit=limit,
                        market_type=user_handler.user_states['basic_market_type']
                    )
                )
                keyboard = user_handler.get_basic_market_keyboard(
                    current_sort_type=user_handler.user_states['basic_market_sort_type'],
                    current_period=user_handler.user_states['basic_market_period'],
                    current_sort_order=user_handler.user_states['basic_market_sort_order'],
                    current_limit=limit,
                    current_market_type=user_handler.user_states['basic_market_type']
                )
            elif feature_type == "unified_ratio":
                # ç»Ÿä¸€æ¯”ç‡æ•°é‡æŒ‰é’®å¤„ç†
                # ä½¿ç”¨å½“å‰æ¯”ç‡ç±»å‹çŠ¶æ€
                current_ratio_type = user_handler.user_states.get('current_ratio_type', 'position_market')
                
                # æ ¹æ®æ¯”ç‡ç±»å‹æ›´æ–°ç›¸åº”çš„æ•°é‡çŠ¶æ€
                if current_ratio_type == 'position_market':
                    current_sort = user_handler.user_states.get('position_market_sort', 'desc')
                    user_handler.user_states['position_market_limit'] = limit
                elif current_ratio_type == 'volume_market':
                    current_sort = user_handler.user_states.get('volume_market_sort', 'desc')
                    user_handler.user_states['volume_market_limit'] = limit
                elif current_ratio_type == 'volume_oi':
                    current_sort = user_handler.user_states.get('volume_oi_sort', 'desc')
                    user_handler.user_states['volume_oi_limit'] = limit
                else:
                    current_sort = 'desc'
                
                text = await loop.run_in_executor(
                    None, user_handler.get_unified_ratio_data,
                    limit, current_sort, current_ratio_type
                )
                keyboard = user_handler.get_unified_ratio_keyboard(
                    current_sort=current_sort, 
                    current_limit=limit,
                    current_ratio_type=current_ratio_type
                )
            else:
                # æœªçŸ¥åŠŸèƒ½ç±»å‹ï¼Œè¿”å›ä¸»èœå•
                loop = asyncio.get_event_loop()
                text = await loop.run_in_executor(None, user_handler.get_main_menu_text)
                keyboard = user_handler.get_main_menu_keyboard()
            
            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            

            
        # æ¯”ç‡ç±»å‹é€‰æ‹©æŒ‰é’®å¤„ç† - ä½¿ç”¨ç»Ÿä¸€æ•°æ®å‡½æ•°
        elif query.data.startswith("ratio_type_"):
            ratio_type = query.data.replace("ratio_type_", "")
            loop = asyncio.get_event_loop()
            
            # è·å–å½“å‰æ¯”ç‡ç±»å‹çš„çŠ¶æ€ï¼Œç”¨äºä¿æŒæ•°é‡è®¾ç½®
            current_ratio_type = user_handler.user_states.get('current_ratio_type', 'position_market')
            
            # è·å–å½“å‰æ˜¾ç¤ºçš„æ•°é‡ï¼ˆä»å½“å‰æ¯”ç‡ç±»å‹ä¸­è·å–ï¼‰
            if current_ratio_type == "position_market":
                current_limit = user_handler.user_states.get('position_market_limit', 10)
            elif current_ratio_type == "volume_market":
                current_limit = user_handler.user_states.get('volume_market_limit', 10)
            elif current_ratio_type == "volume_oi":
                current_limit = user_handler.user_states.get('volume_oi_limit', 10)
            else:
                current_limit = 10
            
            # æ›´æ–°å½“å‰æ¯”ç‡ç±»å‹çŠ¶æ€
            user_handler.user_states['current_ratio_type'] = ratio_type
            
            # è·å–æ–°æ¯”ç‡ç±»å‹çš„æ’åºçŠ¶æ€ï¼Œä½†ä¿æŒå½“å‰çš„æ•°é‡è®¾ç½®
            if ratio_type == "position_market":
                current_sort = user_handler.user_states.get('position_market_sort', 'desc')
                # åŒæ­¥æ•°é‡åˆ°æ–°çš„æ¯”ç‡ç±»å‹
                user_handler.user_states['position_market_limit'] = current_limit
            elif ratio_type == "volume_market":
                current_sort = user_handler.user_states.get('volume_market_sort', 'desc')
                # åŒæ­¥æ•°é‡åˆ°æ–°çš„æ¯”ç‡ç±»å‹
                user_handler.user_states['volume_market_limit'] = current_limit
            elif ratio_type == "volume_oi":
                current_sort = user_handler.user_states.get('volume_oi_sort', 'desc')
                # åŒæ­¥æ•°é‡åˆ°æ–°çš„æ¯”ç‡ç±»å‹
                user_handler.user_states['volume_oi_limit'] = current_limit
            else:
                current_sort = 'desc'
            
            # ä½¿ç”¨ç»Ÿä¸€æ•°æ®å‡½æ•°
            text = await loop.run_in_executor(
                None, user_handler.get_unified_ratio_data,
                current_limit, current_sort, ratio_type
            )
            keyboard = user_handler.get_unified_ratio_keyboard(
                current_sort=current_sort, 
                current_limit=current_limit,
                current_ratio_type=ratio_type
            )
            
            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # ç»Ÿä¸€æ¯”ç‡æ’åºæŒ‰é’®å¤„ç†
        elif query.data.startswith("unified_ratio_sort_"):
            sort_order = query.data.replace("unified_ratio_sort_", "")
            loop = asyncio.get_event_loop()
            
            # ä½¿ç”¨å½“å‰æ¯”ç‡ç±»å‹çŠ¶æ€
            current_ratio_type = user_handler.user_states.get('current_ratio_type', 'position_market')
            
            # æ ¹æ®æ¯”ç‡ç±»å‹æ›´æ–°ç›¸åº”çš„æ’åºçŠ¶æ€
            if current_ratio_type == 'position_market':
                current_limit = user_handler.user_states.get('position_market_limit', 10)
                user_handler.user_states['position_market_sort'] = sort_order
            elif current_ratio_type == 'volume_market':
                current_limit = user_handler.user_states.get('volume_market_limit', 10)
                user_handler.user_states['volume_market_sort'] = sort_order
            elif current_ratio_type == 'volume_oi':
                current_limit = user_handler.user_states.get('volume_oi_limit', 10)
                user_handler.user_states['volume_oi_sort'] = sort_order
            else:
                current_limit = 10
            
            text = await loop.run_in_executor(
                None, user_handler.get_unified_ratio_data,
                current_limit, sort_order, current_ratio_type
            )
            keyboard = user_handler.get_unified_ratio_keyboard(
                current_sort=sort_order, 
                current_limit=current_limit,
                current_ratio_type=current_ratio_type
            )
            
            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            

        # ç»Ÿä¸€æ¯”ç‡åˆ·æ–°æŒ‰é’®å¤„ç†
        elif query.data == "unified_ratio_refresh":
            user_id = query.from_user.id
            
            # å¼‚æ­¥æ£€æŸ¥æƒé™
            loop = asyncio.get_event_loop()
            can_access, error_msg = await loop.run_in_executor(
                None, user_handler.check_feature_access, user_id, "position_market_ratio"
            )
            
            if not can_access:
                await query.message.reply_text(error_msg, parse_mode='Markdown')
                return
                
            # å¼‚æ­¥æ‰£é™¤ç§¯åˆ†
            deduct_success = await loop.run_in_executor(
                None, user_handler.deduct_feature_cost, user_id, "position_market_ratio"
            )
            
            if not deduct_success:
                await query.message.reply_text("ğŸ’ ç§¯åˆ†æ‰£é™¤å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", parse_mode='Markdown')
                return
            
            # ä½¿ç”¨å½“å‰æ¯”ç‡ç±»å‹çŠ¶æ€
            current_ratio_type = user_handler.user_states.get('current_ratio_type', 'position_market')
            
            # æ ¹æ®æ¯”ç‡ç±»å‹è·å–ç›¸åº”çš„çŠ¶æ€
            if current_ratio_type == 'position_market':
                current_limit = user_handler.user_states.get('position_market_limit', 10)
                current_sort = user_handler.user_states.get('position_market_sort', 'desc')
            elif current_ratio_type == 'volume_market':
                current_limit = user_handler.user_states.get('volume_market_limit', 10)
                current_sort = user_handler.user_states.get('volume_market_sort', 'desc')
            elif current_ratio_type == 'volume_oi':
                current_limit = user_handler.user_states.get('volume_oi_limit', 10)
                current_sort = user_handler.user_states.get('volume_oi_sort', 'desc')
            else:
                current_limit = 10
                current_sort = 'desc'
            
            # å¼‚æ­¥è·å–æ•°æ®
            text = await loop.run_in_executor(
                None, user_handler.get_unified_ratio_data,
                current_limit, current_sort, current_ratio_type
            )
            keyboard = user_handler.get_unified_ratio_keyboard(
                current_sort=current_sort, 
                current_limit=current_limit,
                current_ratio_type=current_ratio_type
            )
            
            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # äº¤æ˜“é‡/å¸‚å€¼æ¯”æ’åºæŒ‰é’®å¤„ç†
        elif query.data.startswith("volume_market_sort_"):
            sort_order = query.data.replace("volume_market_sort_", "")
            user_handler.user_states['volume_market_sort'] = sort_order
            loop = asyncio.get_event_loop()
            text = await loop.run_in_executor(
                None, user_handler.get_volume_market_ratio,
                user_handler.user_states.get('volume_market_limit', 10), sort_order
            )
            keyboard = user_handler.get_volume_market_ratio_keyboard(current_sort=sort_order, current_limit=user_handler.user_states.get('volume_market_limit', 10))
            text = ensure_valid_text(text, "ğŸ“Š äº¤æ˜“é‡/å¸‚å€¼æ¯”æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # äº¤æ˜“é‡/å¸‚å€¼æ¯”æ•°é‡æŒ‰é’®å¤„ç†
        elif query.data.startswith("volume_market_") and query.data.replace("volume_market_", "").isdigit():
            limit = int(query.data.replace("volume_market_", ""))
            user_handler.user_states['volume_market_limit'] = limit
            loop = asyncio.get_event_loop()
            text = await loop.run_in_executor(
                None, user_handler.get_volume_market_ratio,
                limit, user_handler.user_states.get('volume_market_sort', 'desc')
            )
            keyboard = user_handler.get_volume_market_ratio_keyboard(current_sort=user_handler.user_states.get('volume_market_sort', 'desc'), current_limit=limit)
            text = ensure_valid_text(text, "ğŸ“Š äº¤æ˜“é‡/å¸‚å€¼æ¯”æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # äº¤æ˜“é‡/æŒä»“é‡æ¯”æ’åºæŒ‰é’®å¤„ç†
        elif query.data.startswith("volume_oi_sort_"):
            sort_order = query.data.replace("volume_oi_sort_", "")
            user_handler.user_states['volume_oi_sort'] = sort_order
            loop = asyncio.get_event_loop()
            text = await loop.run_in_executor(
                None, user_handler.get_volume_oi_ratio,
                user_handler.user_states.get('volume_oi_limit', 10), sort_order
            )
            keyboard = user_handler.get_volume_oi_ratio_keyboard(current_sort=sort_order, current_limit=user_handler.user_states.get('volume_oi_limit', 10))
            text = ensure_valid_text(text, "ğŸ“Š äº¤æ˜“é‡/æŒä»“é‡æ¯”æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # äº¤æ˜“é‡/æŒä»“é‡æ¯”æ•°é‡æŒ‰é’®å¤„ç†
        elif query.data.startswith("volume_oi_") and query.data.replace("volume_oi_", "").isdigit():
            limit = int(query.data.replace("volume_oi_", ""))
            user_handler.user_states['volume_oi_limit'] = limit
            loop = asyncio.get_event_loop()
            text = await loop.run_in_executor(
                None, user_handler.get_volume_oi_ratio,
                limit, user_handler.user_states.get('volume_oi_sort', 'desc')
            )
            keyboard = user_handler.get_volume_oi_ratio_keyboard(current_sort=user_handler.user_states.get('volume_oi_sort', 'desc'), current_limit=limit)
            text = ensure_valid_text(text, "ğŸ“Š äº¤æ˜“é‡/æŒä»“é‡æ¯”æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # æŒä»“/å¸‚å€¼æ¯”æ•°é‡æŒ‰é’®å¤„ç†
        elif query.data.startswith("position_market_") and query.data.replace("position_market_", "").isdigit():
            limit = int(query.data.replace("position_market_", ""))
            user_handler.user_states['position_market_limit'] = limit
            user_handler.user_states['current_ratio_type'] = 'position_market'
            loop = asyncio.get_event_loop()
            text = await loop.run_in_executor(
                None, user_handler.get_unified_ratio_data,
                limit, user_handler.user_states['position_market_sort'], 'position_market'
            )
            keyboard = user_handler.get_unified_ratio_keyboard(
                current_sort=user_handler.user_states['position_market_sort'], 
                current_limit=limit,
                current_ratio_type='position_market'
            )
            text = ensure_valid_text(text, "ğŸ“Š æŒä»“/å¸‚å€¼æ¯”æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # èµ„é‡‘æµå‘å‘¨æœŸé€‰æ‹©æŒ‰é’®å¤„ç†
        # èµ„é‡‘æµå‘ç±»å‹é€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("money_flow_type_"):
            flow_type = query.data.replace("money_flow_type_", "")
            user_handler.user_states['money_flow_type'] = flow_type
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(None, lambda: user_handler.get_money_flow(
                limit=user_handler.user_states['money_flow_limit'],
                period=user_handler.user_states['money_flow_period'], 
                sort_order=user_handler.user_states['money_flow_sort'],
                flow_type=flow_type,
                market=user_handler.user_states['money_flow_market']
            ))

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_money_flow_keyboard(
                current_period=user_handler.user_states['money_flow_period'],
                current_sort=user_handler.user_states['money_flow_sort'], 
                current_limit=user_handler.user_states['money_flow_limit'], 
                current_flow_type=flow_type,
                current_market=user_handler.user_states['money_flow_market']
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # èµ„é‡‘æµå‘å¸‚åœºé€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("money_flow_market_"):
            market = query.data.replace("money_flow_market_", "")
            user_handler.user_states['money_flow_market'] = market
            # ç°è´§æ¨¡å¼ç°åœ¨ä¹Ÿæ”¯æŒå¸‚å€¼æ’åºï¼Œä¸éœ€è¦é‡ç½®
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(None, lambda: user_handler.get_money_flow(
                limit=user_handler.user_states['money_flow_limit'],
                period=user_handler.user_states['money_flow_period'], 
                sort_order=user_handler.user_states['money_flow_sort'],
                flow_type=user_handler.user_states['money_flow_type'],
                market=market
            ))

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_money_flow_keyboard(
                current_period=user_handler.user_states['money_flow_period'],
                current_sort=user_handler.user_states['money_flow_sort'], 
                current_limit=user_handler.user_states['money_flow_limit'], 
                current_flow_type=user_handler.user_states['money_flow_type'],
                current_market=market
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # èµ„é‡‘æµå‘æ’åºé€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("money_flow_sort_"):
            sort_order = query.data.replace("money_flow_sort_", "")
            user_handler.user_states['money_flow_sort'] = sort_order
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(None, lambda: user_handler.get_money_flow(
                limit=user_handler.user_states['money_flow_limit'],
                period=user_handler.user_states['money_flow_period'], 
                sort_order=sort_order,
                flow_type=user_handler.user_states['money_flow_type'],
                market=user_handler.user_states['money_flow_market']
            ))

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_money_flow_keyboard(
                current_period=user_handler.user_states['money_flow_period'],
                current_sort=sort_order, 
                current_limit=user_handler.user_states['money_flow_limit'], 
                current_flow_type=user_handler.user_states['money_flow_type'],
                current_market=user_handler.user_states['money_flow_market']
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # èµ„é‡‘æµå‘æ—¶é—´å‘¨æœŸé€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("money_flow_period_"):
            period = query.data.replace("money_flow_period_", "")
            user_handler.user_states['money_flow_period'] = period
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(None, lambda: user_handler.get_money_flow(
                limit=user_handler.user_states['money_flow_limit'],
                period=period, 
                sort_order=user_handler.user_states['money_flow_sort'],
                flow_type=user_handler.user_states['money_flow_type'],
                market=user_handler.user_states['money_flow_market']
            ))

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_money_flow_keyboard(
                current_period=period,
                current_sort=user_handler.user_states['money_flow_sort'], 
                current_limit=user_handler.user_states['money_flow_limit'], 
                current_flow_type=user_handler.user_states['money_flow_type'],
                current_market=user_handler.user_states['money_flow_market']
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # åŸºç¡€è¡Œæƒ… - å¸‚åœºç±»å‹é€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("basic_market_type_"):
            market_type = query.data.replace("basic_market_type_", "")
            user_handler.user_states['basic_market_type'] = market_type
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(None, lambda: user_handler.get_basic_market(
                sort_type=user_handler.user_states['basic_market_sort_type'],
                period=user_handler.user_states['basic_market_period'],
                sort_order=user_handler.user_states['basic_market_sort_order'],
                limit=user_handler.user_states['basic_market_limit'],
                market_type=market_type
            ))

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_basic_market_keyboard(
                current_sort_type=user_handler.user_states['basic_market_sort_type'],
                current_period=user_handler.user_states['basic_market_period'],
                current_sort_order=user_handler.user_states['basic_market_sort_order'],
                current_limit=user_handler.user_states['basic_market_limit'],
                current_market_type=market_type
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # åŸºç¡€è¡Œæƒ… - æ’åºç±»å‹é€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("basic_market_sort_type_"):
            sort_type = query.data.replace("basic_market_sort_type_", "")
            user_handler.user_states['basic_market_sort_type'] = sort_type
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(None, lambda: user_handler.get_basic_market(
                sort_type=sort_type,
                period=user_handler.user_states['basic_market_period'],
                sort_order=user_handler.user_states['basic_market_sort_order'],
                limit=user_handler.user_states['basic_market_limit'],
                market_type=user_handler.user_states['basic_market_type']
            ))

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_basic_market_keyboard(
                current_sort_type=sort_type,
                current_period=user_handler.user_states['basic_market_period'],
                current_sort_order=user_handler.user_states['basic_market_sort_order'],
                current_limit=user_handler.user_states['basic_market_limit'],
                current_market_type=user_handler.user_states['basic_market_type']
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # åŸºç¡€è¡Œæƒ… - æ—¶é—´å‘¨æœŸé€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("basic_market_period_"):
            period = query.data.replace("basic_market_period_", "")
            user_handler.user_states['basic_market_period'] = period
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(None, lambda: user_handler.get_basic_market(
                sort_type=user_handler.user_states['basic_market_sort_type'],
                period=period,
                sort_order=user_handler.user_states['basic_market_sort_order'],
                limit=user_handler.user_states['basic_market_limit'],
                market_type=user_handler.user_states['basic_market_type']
            ))

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_basic_market_keyboard(
                current_sort_type=user_handler.user_states['basic_market_sort_type'],
                current_period=period,
                current_sort_order=user_handler.user_states['basic_market_sort_order'],
                current_limit=user_handler.user_states['basic_market_limit'],
                current_market_type=user_handler.user_states['basic_market_type']
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # åŸºç¡€è¡Œæƒ… - æ’åºæ–¹å‘é€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("basic_market_sort_order_"):
            sort_order = query.data.replace("basic_market_sort_order_", "")
            user_handler.user_states['basic_market_sort_order'] = sort_order
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(None, lambda: user_handler.get_basic_market(
                sort_type=user_handler.user_states['basic_market_sort_type'],
                period=user_handler.user_states['basic_market_period'],
                sort_order=sort_order,
                limit=user_handler.user_states['basic_market_limit'],
                market_type=user_handler.user_states['basic_market_type']
            ))

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_basic_market_keyboard(
                current_sort_type=user_handler.user_states['basic_market_sort_type'],
                current_period=user_handler.user_states['basic_market_period'],
                current_sort_order=sort_order,
                current_limit=user_handler.user_states['basic_market_limit'],
                current_market_type=user_handler.user_states['basic_market_type']
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # å¸‚åœºæ·±åº¦ - æ’åºç±»å‹é€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("market_depth_sort_type_"):
            sort_type = query.data.replace("market_depth_sort_type_", "")
            user_handler.user_states['market_depth_sort_type'] = sort_type
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(
                None, user_handler.get_market_depth,
                user_handler.user_states.get('market_depth_limit', 10),
                sort_type,
                user_handler.user_states.get('market_depth_sort', 'desc')
            )

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_market_depth_keyboard(
                current_limit=user_handler.user_states.get('market_depth_limit', 10),
                current_sort_type=sort_type,
                current_sort=user_handler.user_states.get('market_depth_sort', 'desc')
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # å¸‚åœºæ·±åº¦ - æ’åºæ–¹å‘é€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("market_depth_sort_"):
            sort_order = query.data.replace("market_depth_sort_", "")
            user_handler.user_states['market_depth_sort'] = sort_order
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(
                None, user_handler.get_market_depth,
                user_handler.user_states.get('market_depth_limit', 10),
                user_handler.user_states.get('market_depth_sort_type', 'ratio'),
                sort_order
            )

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_market_depth_keyboard(
                current_limit=user_handler.user_states.get('market_depth_limit', 10),
                current_sort_type=user_handler.user_states.get('market_depth_sort_type', 'ratio'),
                current_sort=sort_order
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        # çˆ†ä»“æ’è¡Œæ¦œ - æ—¶é—´å‘¨æœŸé€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("liquidation_period_"):
            period = query.data.replace("liquidation_period_", "")
            user_handler.user_states['liquidation_period'] = period
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(
                None, user_handler.get_liquidation_ranking,
                user_handler.user_states['liquidation_limit'],
                user_handler.user_states['liquidation_sort'],
                period,
                user_handler.user_states['liquidation_type']
            )

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_liquidation_ranking_keyboard(
                current_limit=user_handler.user_states['liquidation_limit'], 
                current_sort=user_handler.user_states['liquidation_sort'],
                current_period=period,
                current_type=user_handler.user_states['liquidation_type']
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
        
        # çˆ†ä»“æ’è¡Œæ¦œ - æ•°æ®ç±»å‹é€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("liquidation_type_"):
            liquidation_type = query.data.replace("liquidation_type_", "")
            user_handler.user_states['liquidation_type'] = liquidation_type
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(
                None, user_handler.get_liquidation_ranking,
                user_handler.user_states['liquidation_limit'],
                user_handler.user_states['liquidation_sort'],
                user_handler.user_states['liquidation_period'],
                liquidation_type
            )

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_liquidation_ranking_keyboard(
                current_limit=user_handler.user_states['liquidation_limit'], 
                current_sort=user_handler.user_states['liquidation_sort'],
                current_period=user_handler.user_states['liquidation_period'],
                current_type=liquidation_type
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
        
        # çˆ†ä»“æ’è¡Œæ¦œ - æ’åºé€‰æ‹©æŒ‰é’®å¤„ç†
        elif query.data.startswith("liquidation_sort_"):
            sort_order = query.data.replace("liquidation_sort_", "")
            user_handler.user_states['liquidation_sort'] = sort_order
            loop = asyncio.get_event_loop()

            text = await loop.run_in_executor(
                None, user_handler.get_liquidation_ranking,
                user_handler.user_states['liquidation_limit'],
                sort_order,
                user_handler.user_states['liquidation_period'],
                user_handler.user_states['liquidation_type']
            )

            text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
            keyboard = user_handler.get_liquidation_ranking_keyboard(
                current_limit=user_handler.user_states['liquidation_limit'], 
                current_sort=sort_order,
                current_period=user_handler.user_states['liquidation_period'],
                current_type=user_handler.user_states['liquidation_type']
            )
            await query.edit_message_text(text, reply_markup=keyboard, parse_mode='Markdown')
            
        elif query.data in ["coin_search", "start_coin_analysis", "help", "aggregated_alerts", "subscription", "recharge", "user_center"]:
            feature_names = {
                "coin_search": "ğŸ¤– AIåˆ†æï¼ˆå·²ä¸‹çº¿ï¼‰",
                "start_coin_analysis": "ğŸ¤– AIåˆ†æï¼ˆå·²ä¸‹çº¿ï¼‰",
                "help": "â„¹ï¸ å¸®åŠ©",
                "aggregated_alerts": "ğŸš¨ ä¿¡å·",
                "subscription": "ğŸ’² è®¢é˜…/é‚€è¯·",
                "recharge": "ğŸ’³ å……å€¼",
                "user_center": "ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ"
            }
            
            feature_name = feature_names.get(query.data, query.data)
            
            if query.data == "help":
                await send_help_message(update, context, via_query=True)
            elif query.data == "recharge":
                await show_recharge_menu(update, context)
            elif query.data == "user_center":
                await show_user_center(update, context)
            elif query.data in {"coin_search", "start_coin_analysis"}:
                await query.edit_message_text(
                    AI_FEATURE_NOTICE,
                    reply_markup=build_ai_placeholder_keyboard(),
                    parse_mode='Markdown'
                )
                return
            else:
                await query.message.reply_text(
                    f"ğŸš§ {feature_name} åŠŸèƒ½å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼\n\n"
                    f"ç›®å‰å·²å®Œæˆçš„åŠŸèƒ½ï¼š\n"
                    f"- ğŸ‹ æŒä»“é‡æ’è¡Œ (æŒä»“é‡æ’è¡Œæ¦œ)\n"
                    f"- ğŸ’± èµ„é‡‘è´¹ç‡æ’è¡Œ (èµ„é‡‘è´¹ç‡æ’è¡Œæ¦œ)\n"
                    f"- ğŸ“ˆ æˆäº¤é‡æ’è¡Œ (äº¤æ˜“é‡æ’è¡Œæ¦œ)\n"
                    f"- ğŸ’¥ çˆ†ä»“æ’è¡Œ (çˆ†ä»“é£é™©ç›‘æ§)\n"
                    f"- ğŸ“ˆ æ³¢åŠ¨æ€§ä¸æœºä¼š\n"
                    f"- ğŸ­ å¸‚åœºæƒ…ç»ª (æƒ…ç»ªåˆ†æ)\n"
                    f"- ğŸ“¡ è¡Œæƒ…æ€»è§ˆ (åŸºç¡€è¡Œæƒ…æ€»è§ˆ)\n"
                    f"- ğŸ’§ èµ„é‡‘æµå‘æ’è¡Œ (èµ„é‡‘æµå‘æ’è¡Œæ¦œ)\n"
                    f"- ğŸ§Š å¸‚åœºæ·±åº¦æ’è¡Œ (å¸‚åœºæ·±åº¦åˆ†æ)\n"
                    f"- ğŸ“ˆ ä¸»åŠ¨ä¹°å–æ¯”åˆ†æ\n\n"
                    f"å…¶ä»–åŠŸèƒ½æ­£åœ¨å¿«é€Ÿå¼€å‘ä¸­...",
                    reply_markup=InlineKeyboardMarkup([[
                        InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                    ]]),
                    parse_mode='Markdown'
                )
                await query.message.reply_text(
                    f"ğŸš§ {feature_name} åŠŸèƒ½å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼\n\n"
                    f"ç›®å‰å·²å®Œæˆçš„åŠŸèƒ½ï¼š\n"
                    f"- ğŸ‹ æŒä»“é‡æ’è¡Œ (æŒä»“é‡æ’è¡Œæ¦œ)\n"
                    f"- ğŸ’± èµ„é‡‘è´¹ç‡æ’è¡Œ (èµ„é‡‘è´¹ç‡æ’è¡Œæ¦œ)\n"
                    f"- ğŸ“ˆ æˆäº¤é‡æ’è¡Œ (äº¤æ˜“é‡æ’è¡Œæ¦œ)\n"
                    f"- ğŸ’¥ çˆ†ä»“æ’è¡Œ (çˆ†ä»“é£é™©ç›‘æ§)\n"
                    f"- ğŸ“ˆ æ³¢åŠ¨æ€§ä¸æœºä¼š\n"
                    f"- ğŸ­ å¸‚åœºæƒ…ç»ª (æƒ…ç»ªåˆ†æ)\n"
                    f"- ğŸ“¡ è¡Œæƒ…æ€»è§ˆ (åŸºç¡€è¡Œæƒ…æ€»è§ˆ)\n"
                    f"- ğŸ’§ èµ„é‡‘æµå‘æ’è¡Œ (èµ„é‡‘æµå‘æ’è¡Œæ¦œ)\n"
                    f"- ğŸ§Š å¸‚åœºæ·±åº¦æ’è¡Œ (å¸‚åœºæ·±åº¦åˆ†æ)\n"
                    f"- ğŸ“ˆ ä¸»åŠ¨ä¹°å–æ¯”åˆ†æ\n\n"
                    f"å…¶ä»–åŠŸèƒ½æ­£åœ¨å¿«é€Ÿå¼€å‘ä¸­...",
                    reply_markup=InlineKeyboardMarkup([[
                        InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                    ]]),
                    parse_mode='Markdown'
                )
        
        # ================== æ–°å¢åŠŸèƒ½æŒ‰é’®å¤„ç† ==================
        
        # å……å€¼åŠŸèƒ½å›è°ƒ
        elif query.data == "show_recharge":
            await show_recharge_menu(update, context)
            
        elif query.data.startswith("recharge_"):
            try:
                amount_str = query.data.replace("recharge_", "").strip()
                amount_digits = ''.join(ch for ch in amount_str if ch.isdigit())
                if not amount_digits:
                    raise ValueError("empty amount")
                amount = int(amount_digits)
            except Exception as e:
                logger.error(f"âŒ å……å€¼é‡‘é¢è§£æå¤±è´¥: raw={query.data}, err={e}")
                await query.answer("é‡‘é¢è§£æå¤±è´¥ï¼Œè¯·é‡è¯•", show_alert=True)
                return

            if amount not in RECHARGE_AMOUNTS:
                await query.answer("ä¸æ”¯æŒçš„é‡‘é¢æ¡£ä½", show_alert=True)
                return

            await process_recharge(update, context, amount)
            
        elif query.data.startswith("check_order_"):
            order_id = query.data.replace("check_order_", "")
            # æ£€æŸ¥è®¢å•çŠ¶æ€
            orders = DataManager.load_json(ORDERS_FILE, {})
            if order_id in orders:
                order = orders[order_id]
                if order["status"] == "completed":
                    await query.edit_message_text(
                        f"âœ… è®¢å•å·²å®Œæˆï¼\n\nğŸ“‹ è®¢å•å·ï¼š`{order_id}`\nğŸ’³ å……å€¼é‡‘é¢ï¼š{order['amount']} USDT\nğŸ“ˆ è·å¾—ç§¯åˆ†ï¼š{order['amount'] * 20} åˆ†\n\næ„Ÿè°¢æ‚¨çš„å……å€¼ï¼",
                        reply_markup=InlineKeyboardMarkup([[
                            InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                        ]]),
                        parse_mode='Markdown'
                    )
                else:
                    await query.edit_message_text(
                        f"â³ è®¢å•å¾…å¤„ç†\n\nğŸ“‹ è®¢å•å·ï¼š`{order_id}`\nğŸ’³ å……å€¼é‡‘é¢ï¼š{order['exact_amount']:.4f} USDT\nğŸ“Š çŠ¶æ€ï¼š{order['status']}\n\nè¯·å®Œæˆè½¬è´¦åç­‰å¾…ç¡®è®¤...",
                        reply_markup=InlineKeyboardMarkup([
                            [InlineKeyboardButton("ğŸ”„ å†æ¬¡æ£€æŸ¥", callback_data=f"check_order_{order_id}")],
                            [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                        ]),
                        parse_mode='Markdown'
                    )
            else:
                await query.edit_message_text(
                    "âŒ è®¢å•ä¸å­˜åœ¨æˆ–å·²è¿‡æœŸ",
                    reply_markup=InlineKeyboardMarkup([[
                        InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                    ]]),
                    parse_mode='Markdown'
                )
        
        # ç”¨æˆ·ä¸­å¿ƒå›è°ƒ
        elif query.data == "show_user_center":
            await show_user_center(update, context)
            
        elif query.data == "points_history":
            user_id = update.effective_user.id
            history = DataManager.load_json(POINTS_HISTORY_FILE, [])
            user_history = [h for h in history if h['user_id'] == user_id][-10:]  # æœ€è¿‘10æ¡
            
            if not user_history:
                text = "ğŸ“Š ç§¯åˆ†è®°å½•\n\næš‚æ— ç§¯åˆ†å˜åŠ¨è®°å½•"
            else:
                text = "ğŸ“Š ç§¯åˆ†è®°å½•ï¼ˆæœ€è¿‘10æ¡ï¼‰\n\n"
                for record in reversed(user_history):  # æœ€æ–°çš„åœ¨å‰
                    timestamp = format_beijing_time(record['timestamp'], '%m-%d %H:%M')
                    change = record['change']
                    reason = record['reason']
                    balance_after = record['balance_after']
                    change_text = f"+{change}" if change > 0 else str(change)
                    text += f"- {timestamp} {change_text} åˆ† ({reason})\n  ä½™é¢ï¼š{balance_after} åˆ†\n\n"
            
            await query.edit_message_text(
                text,
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("ğŸ’³ ç«‹å³å……å€¼", callback_data="show_recharge")],
                    [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                ]),
                parse_mode='Markdown'
            )
            
        elif query.data == "invitation_details":
            if not invitation_manager:
                invitation_manager = IntegratedInvitationManager()
            
            user_id = update.effective_user.id
            data = DataManager.load_json(INVITATION_DATA_FILE)
            user_key = str(user_id)
            
            if user_key in data["invitations"]:
                invitation_info = data["invitations"][user_key]
                invitation_code = invitation_info["invitation_code"]
                total_commission = invitation_info["total_commission"]
                available_commission = invitation_info["available_commission"]
                invitees_count = len(invitation_info["invitees"])
                
                text = f"""ğŸ‘¥ é‚€è¯·è¯¦æƒ…

ğŸ æˆ‘çš„é‚€è¯·ç ï¼š`{invitation_code}`
ğŸ“Š é‚€è¯·ç»Ÿè®¡ï¼š
- é‚€è¯·äººæ•°ï¼š{invitees_count} äºº
- ç´¯è®¡ä½£é‡‘ï¼š{total_commission:.2f} USDT
- å¯æç°ï¼š{available_commission:.2f} USDT

ğŸ“® é‚€è¯·é“¾æ¥ï¼š
```
t.me/tradecat_bot?start={invitation_code}
```

ğŸ’¡ ä½£é‡‘è¯´æ˜ï¼š
- è¢«é‚€è¯·äººå……å€¼å¯è·å¾—5%ä½£é‡‘
- ä½£é‡‘å¯ç”³è¯·æç°
- é‚€è¯·è¶Šå¤šæ”¶ç›Šè¶Šé«˜"""
            else:
                invitation_code = invitation_manager.get_user_invitation_code(user_id)
                text = f"""ğŸ‘¥ é‚€è¯·è¯¦æƒ…

ğŸ æˆ‘çš„é‚€è¯·ç ï¼š`{invitation_code}`
ğŸ“Š é‚€è¯·ç»Ÿè®¡ï¼š
- é‚€è¯·äººæ•°ï¼š0 äºº
- ç´¯è®¡ä½£é‡‘ï¼š0.00 USDT
- å¯æç°ï¼š0.00 USDT

ğŸ“® é‚€è¯·é“¾æ¥ï¼š
```
t.me/tradecat_bot?start={invitation_code}
```

ğŸ’¡ å¼€å§‹é‚€è¯·å¥½å‹ï¼Œè·å¾—ä¸°åšä½£é‡‘ï¼"""
            
            await query.edit_message_text(
                text,
                reply_markup=InlineKeyboardMarkup([
                    [InlineKeyboardButton("ğŸ’° ç”³è¯·æç°", callback_data="withdrawal_request")],
                    [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                ]),
                parse_mode='Markdown'
            )
            

        
        # ä¿¡å·è®¢é˜…å›è°ƒ
        elif query.data == "show_subscription":
            await show_subscription_settings(update, context)

        elif query.data == "show_subscription_settings":
            await show_subscription_settings(update, context)
            
        elif query.data == "signal_history":
            await query.edit_message_text(
                "ğŸ“Š ä¿¡å·å†å²\n\nğŸš§ ä¿¡å·å†å²æŸ¥çœ‹åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­\n\nå³å°†æ”¯æŒæŸ¥çœ‹å†å²æ¨é€çš„ä¿¡å·è®°å½•",
                reply_markup=InlineKeyboardMarkup([[
                    InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                ]]),
                parse_mode='Markdown'
            )
            
        elif query.data == "subscription_config":
            await query.edit_message_text(
                "âš™ï¸ è®¢é˜…è®¾ç½®\n\nğŸš§ è®¢é˜…è®¾ç½®åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­\n\nå³å°†æ”¯æŒï¼š\n- ä¿¡å·ç±»å‹é€‰æ‹©\n- æ¨é€æ—¶é—´è®¾ç½®\n- é£é™©ç­‰çº§é…ç½®",
                reply_markup=InlineKeyboardMarkup([[
                    InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                ]]),
                parse_mode='Markdown'
            )
        
        # ================== AIå¸ç§æŸ¥è¯¢å›è°ƒå¤„ç†ï¼ˆå·²ä¸‹çº¿ï¼‰ ==================
        elif query.data in ["start_coin_analysis", "start_ai_analysis", "start_basis_analysis", "start_batch_analysis"]:
            await query.edit_message_text(
                AI_FEATURE_NOTICE,
                reply_markup=build_ai_placeholder_keyboard(),
                parse_mode='Markdown'
            )
            return

        # AIåˆ†é¡µ/å¸ç§åˆ—è¡¨å¯¼èˆªå…œåº•å¤„ç†ï¼ˆä¼šè¯æœªæ¿€æ´»æ—¶é¿å…è½å…¥â€œå¼€å‘ä¸­â€ï¼‰
        elif query.data in {
            "symbols_prev_page", "symbols_next_page", "show_all_symbols",
            "manual_input", "manual_input_text", "back_to_coin_selection",
            "coin_page_prev", "coin_page_next", "analysis_depth", "analysis_point",
            "refresh_main_menu"
        } or query.data.startswith(("page_", "reanalyze_", "coin_", "sort_", "interval_")):
            await query.answer("ğŸ¤– AIåˆ†ææš‚æœªå¼€æ”¾", show_alert=True)
            return

            
        elif query.data == "subscription_help":
            await query.edit_message_text(
                """â“ ä¿¡å·è®¢é˜…å¸®åŠ©

ğŸ“ˆ æœåŠ¡å†…å®¹ï¼š
- AIæŠ€æœ¯åˆ†æä¿¡å·ï¼šåŸºäºå¤šæŒ‡æ ‡ç»¼åˆåˆ†æ
- èµ„é‡‘è´¹ç‡ç›‘æ§ï¼šå¼‚å¸¸è´¹ç‡æé†’
- æŒä»“é‡å¼‚åŠ¨ï¼šå¤§é¢æŒä»“å˜åŒ–æé†’
- è½¬è´¦ç›‘æ§ï¼šå¤§é¢è½¬è´¦å®æ—¶æ¨é€
- çˆ†ä»“é¢„è­¦ï¼šæ½œåœ¨çˆ†ä»“é£é™©æç¤º

ğŸ’° è´¹ç”¨è¯´æ˜ï¼š
- éœ€ç§¯åˆ†
- 1 USDT = 20 ç§¯åˆ†
- ç§¯åˆ†ä¸è¶³æœåŠ¡è‡ªåŠ¨æš‚åœ

âš ï¸ å…è´£å£°æ˜ï¼š
æ‰€æœ‰ä¿¡å·ä»…ä¾›å‚è€ƒï¼Œä¸æ„æˆæŠ•èµ„å»ºè®®
æŠ•èµ„æœ‰é£é™©ï¼Œå†³ç­–éœ€è°¨æ…

ğŸ“ å¦‚æœ‰é—®é¢˜è¯·è”ç³»å®¢æœï¼š@desci0""",
                reply_markup=InlineKeyboardMarkup([[
                    InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                ]]),
                parse_mode='Markdown'
            )
            
        # æ–°å¢ï¼šå¤„ç†å…¨éƒ¨æç°æŒ‰é’®
        elif query.data.startswith("withdraw_all_"):
            if not invitation_manager:
                invitation_manager = IntegratedInvitationManager()
            
            user_id = update.effective_user.id
            invitation_data = invitation_manager.get_user_invitation_data(user_id)
            available_commission = invitation_data.get("available_commission", 0.0)
            
            if available_commission >= 1.0:
                # è®°å½•æç°è¯·æ±‚
                from datetime import datetime
                withdrawal_request = {
                    "user_id": user_id,
                    "username": update.effective_user.username or update.effective_user.first_name,
                    "amount": available_commission,
                    "status": "pending",
                    "created_at": beijing_time_isoformat(),
                    "processed_at": None
                }
                
                # ä¿å­˜æç°è¯·æ±‚åˆ°æ–‡ä»¶
                withdrawals = DataManager.load_json(WITHDRAWAL_REQUESTS_FILE, {"requests": {}})
                request_id = f"WD_{user_id}_{int(get_beijing_time().timestamp())}"
                withdrawals["requests"][request_id] = withdrawal_request
                DataManager.save_json(WITHDRAWAL_REQUESTS_FILE, withdrawals)
                
                await query.edit_message_text(
                    f"""âœ… æç°ç”³è¯·å·²æäº¤

ğŸ“‹ ç”³è¯·ç¼–å·ï¼š{request_id}
ğŸ’° æç°é‡‘é¢ï¼š${available_commission:.2f}
â° ç”³è¯·æ—¶é—´ï¼š{format_beijing_time(get_beijing_time().isoformat(), '%Y-%m-%d %H:%M')}
ğŸ“Š å¤„ç†çŠ¶æ€ï¼šå¾…å®¡æ ¸

ğŸ“¢ å¤„ç†è¯´æ˜ï¼š
- æç°ç”³è¯·å°†åœ¨24å°æ—¶å†…å¤„ç†
- å¦‚æœ‰é—®é¢˜è¯·è”ç³»å®¢æœï¼š@desci0

ğŸ’¡ æç°å°†å‘é€åˆ°æ‚¨æä¾›çš„é’±åŒ…åœ°å€""",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ğŸ“Š è¿”å›ç”¨æˆ·ä¸­å¿ƒ", callback_data="show_user_center"), 
                         InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                    ]),
                    parse_mode='Markdown'
                )
            else:
                await query.edit_message_text(
                    f"""âŒ æç°å¤±è´¥

å¯æç°é‡‘é¢ï¼š${available_commission:.2f}
æœ€ä½æç°ï¼š$1.00

è¯·ç­‰å¾…æ›´å¤šä½£é‡‘ç´¯ç§¯åå†ç”³è¯·æç°""",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                    ]),
                    parse_mode='Markdown'
                )
        
        # å¤„ç†ä¿¡å·è®¢é˜…åŠŸèƒ½åˆ‡æ¢ï¼ˆå·²ç®€åŒ–ï¼Œä¸å†éœ€è¦å•ç‹¬çš„åˆ‡æ¢åŠŸèƒ½ï¼‰
        elif query.data.startswith("toggle_"):
            # ç”±äºç®€åŒ–äº†è®¢é˜…ç³»ç»Ÿï¼Œä¸å†éœ€è¦å•ç‹¬çš„åˆ‡æ¢åŠŸèƒ½
            # ç›´æ¥è¿”å›è®¢é˜…è®¾ç½®ç•Œé¢
            await show_subscription_settings(update, context)
        
        # æ–°å¢ï¼šç¡®è®¤å¼€å§‹è®¢é˜…
        elif query.data == "confirm_subscribe":
            await query.answer("ğŸš§ åŠŸèƒ½å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…", show_alert=True)
            await show_subscription_settings(update, context)
        
        # æ–°å¢ï¼šç¡®è®¤å–æ¶ˆè®¢é˜…
        elif query.data == "confirm_unsubscribe":
            await query.answer("ğŸš§ åŠŸèƒ½å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…", show_alert=True)
            await show_subscription_settings(update, context)
        
        # æ–°å¢ï¼šå¤„ç†åˆ·æ–°è®¢å•åŠŸèƒ½
        elif query.data.startswith("refresh_order_"):
            try:
                # ä»å›è°ƒæ•°æ®ä¸­æå–å……å€¼é‡‘é¢
                amount_str = query.data.replace("refresh_order_", "")
                amount = int(amount_str)
                
                # è°ƒç”¨process_rechargeå‡½æ•°åˆ·æ–°è®¢å•ä¿¡æ¯
                await process_recharge(update, context, amount)
                
            except ValueError:
                await query.edit_message_text(
                    "âŒ åˆ·æ–°è®¢å•å¤±è´¥ï¼šæ•°æ®æ ¼å¼é”™è¯¯",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ğŸ”™ è¿”å›å……å€¼", callback_data="show_recharge")],
                        [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                    ]),
                    parse_mode='Markdown'
                )
            except Exception as e:
                logger.error(f"åˆ·æ–°è®¢å•é”™è¯¯: {e}")
                await query.edit_message_text(
                    f"âŒ åˆ·æ–°è®¢å•å¤±è´¥ï¼š{str(e)}",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ğŸ”™ è¿”å›å……å€¼", callback_data="show_recharge")],
                        [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                    ]),
                    parse_mode='Markdown'
                )

        elif query.data == "withdrawal_request":
            if not invitation_manager:
                invitation_manager = IntegratedInvitationManager()
            
            user_id = update.effective_user.id
            invitation_data = invitation_manager.get_user_invitation_data(user_id)
            available_commission = invitation_data.get("available_commission", 0.0)
            
            if available_commission < 1.0:
                await query.edit_message_text(
                    f"""ğŸ’° æç°ç”³è¯·

âŒ å½“å‰å¯æç°ä½™é¢ä¸è¶³

ğŸ’ å¯æç°é‡‘é¢ï¼š${available_commission:.2f}
âš ï¸ æœ€ä½æç°é‡‘é¢ï¼š$1.00

ğŸ’¡ å¦‚ä½•è·å¾—æ›´å¤šä½£é‡‘ï¼š
- é‚€è¯·å¥½å‹æ³¨å†Œå¹¶å……å€¼
- ä½£é‡‘æ¯”ä¾‹ï¼šå……å€¼é‡‘é¢çš„5%
- è¢«é‚€è¯·äººå……å€¼åå³æ—¶è·å¾—ä½£é‡‘""",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ğŸ“Š è¿”å›ç”¨æˆ·ä¸­å¿ƒ", callback_data="show_user_center"), 
                         InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")],
                        [InlineKeyboardButton("ğŸ‘¥ é‚€è¯·å¥½å‹", callback_data="invitation_details")]
                    ]),
                    parse_mode='Markdown'
                )
            else:
                await query.edit_message_text(
                    f"""ğŸ’° ç”³è¯·æç°

ğŸ’ å¯æç°é‡‘é¢ï¼š${available_commission:.2f}
ğŸ’µ æœ€ä½æç°ï¼š$1.00
â±ï¸ å¤„ç†æ—¶é—´ï¼š24å°æ—¶å†…

ğŸ“ æç°è¯´æ˜ï¼š
- éœ€è¦æä¾›USDT-TRC20åœ°å€
- æç°é‡‘é¢å°†æ‰£é™¤ç½‘ç»œæ‰‹ç»­è´¹
- äººå·¥å®¡æ ¸ï¼Œç¡®ä¿å®‰å…¨

âš ï¸ ç¡®è®¤æç°å…¨éƒ¨å¯ç”¨ä½™é¢ï¼Ÿ""",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton(f"âœ… æç° ${available_commission:.2f}", callback_data=f"confirm_withdrawal_{available_commission:.2f}")],
                        [InlineKeyboardButton("âŒ å–æ¶ˆ", callback_data="show_user_center")]
                    ]),
                    parse_mode='Markdown'
                )
                
        elif query.data.startswith("confirm_withdrawal_"):
            amount_str = query.data.replace("confirm_withdrawal_", "")
            try:
                amount = float(amount_str)
                user_id = update.effective_user.id
                
                # è¿™é‡Œåº”è¯¥å¤„ç†æç°è¯·æ±‚
                await query.edit_message_text(
                    f"""ğŸ“‹ æç°ç”³è¯·å·²æäº¤

ğŸ’° æç°é‡‘é¢ï¼š${amount:.2f}
ğŸ‘¤ ç”³è¯·äººï¼š{user_id}
â° ç”³è¯·æ—¶é—´ï¼š{format_beijing_time(get_beijing_time().isoformat(), '%Y-%m-%d %H:%M')}

ğŸ“ åç»­å¤„ç†ï¼š
- å®¢æœå°†åœ¨24å°æ—¶å†…è”ç³»æ‚¨
- è¯·å‡†å¤‡USDT-TRC20æ”¶æ¬¾åœ°å€
- å®¡æ ¸é€šè¿‡åç«‹å³è½¬è´¦

âœ… ç”³è¯·çŠ¶æ€ï¼šå¾…å¤„ç†

è”ç³»å®¢æœï¼š@desci0""",
                    reply_markup=InlineKeyboardMarkup([
                        [InlineKeyboardButton("ğŸ“Š è¿”å›ç”¨æˆ·ä¸­å¿ƒ", callback_data="show_user_center"), 
                         InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
                    ]),
                    parse_mode='Markdown'
                )
            except ValueError:
                await query.edit_message_text(
                    "âŒ æç°é‡‘é¢æ ¼å¼é”™è¯¯",
                    reply_markup=InlineKeyboardMarkup([[
                        InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                    ]]),
                    parse_mode='Markdown'
                )
        
        # å…¶ä»–æŒ‰é’®å¤„ç†
        else:
            await query.message.reply_text(
                "ğŸš§ è¯¥åŠŸèƒ½æ­£åœ¨å¼€å‘ä¸­ï¼Œæ•¬è¯·æœŸå¾…ï¼\n\nç‚¹å‡»ä¸‹æ–¹æŒ‰é’®è¿”å›ä¸»èœå•ã€‚",
                reply_markup=InlineKeyboardMarkup([[
                    InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                ]]),
                parse_mode='Markdown'
            )
            
    except Exception as e:
        logger.error(f"æŒ‰é’®å›è°ƒå¤„ç†é”™è¯¯: {e}", exc_info=e)
        logger.error(f"âŒ æŸ¥è¯¢æ•°æ®: {query.data}")
        logger.error(f"âŒ user_handlerçŠ¶æ€: {user_handler is not None}")
        # é™é»˜å¤±è´¥ï¼šä¸å‘ç”¨æˆ·æŠ›é”™ï¼Œåªå°è¯•å…³é—­å›è°ƒæç¤º
        try:
            await query.answer()
        except Exception:
            pass

async def help_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¸®åŠ©å‘½ä»¤å¤„ç†å™¨"""
    print("ğŸ“š æ”¶åˆ° /help å‘½ä»¤")
    await send_help_message(update, context, via_query=False)

async def vol_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """äº¤æ˜“é‡æ•°æ®æŸ¥è¯¢æŒ‡ä»¤ /vol"""
    if not _is_command_allowed(update):
        return
    global user_handler
    if user_handler is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    try:
        loop = asyncio.get_event_loop()

        text = await loop.run_in_executor(None, lambda: user_handler.get_volume_ranking(*[user_handler.user_states.get(k, None) for k in ['volume_limit', 'volume_period', 'volume_sort', 'position_limit', 'position_sort', 'funding_limit', 'funding_sort', 'liquidation_limit', 'liquidation_sort', 'liquidation_period', 'liquidation_type', 'money_flow_limit', 'money_flow_period', 'money_flow_sort', 'money_flow_type', 'money_flow_market', 'market_depth_limit', 'market_depth_sort_type', 'market_depth_sort', 'position_market_limit', 'position_market_sort', 'basic_market_sort_type', 'basic_market_period', 'basic_market_sort_order', 'basic_market_limit'] if k is not None][:3]))

        text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
        keyboard = user_handler.get_volume_ranking_keyboard(current_period=user_handler.user_states['volume_period'], current_sort=user_handler.user_states['volume_sort'], current_limit=user_handler.user_states['volume_limit'])
        await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"äº¤æ˜“é‡æ•°æ®æŸ¥è¯¢é”™è¯¯: {e}")
        await update.message.reply_text(
            f"âŒ è·å–äº¤æ˜“é‡æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}",
            parse_mode='Markdown'
        )

async def sentiment_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¸‚åœºæƒ…ç»ªæ•°æ®æŸ¥è¯¢æŒ‡ä»¤ /sentiment"""
    if not _is_command_allowed(update):
        return
    global user_handler
    if user_handler is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    try:
        loop = asyncio.get_event_loop()
        text = await loop.run_in_executor(None, user_handler.get_market_sentiment)
        text = ensure_valid_text(text, "ğŸ˜Š å¸‚åœºæƒ…ç»ªæ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
        keyboard = user_handler.get_market_sentiment_keyboard()
        await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"å¸‚åœºæƒ…ç»ªæ•°æ®æŸ¥è¯¢é”™è¯¯: {e}")
        await update.message.reply_text(
            f"âŒ è·å–å¸‚åœºæƒ…ç»ªæ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}",
            parse_mode='Markdown'
        )

async def market_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """åŸºç¡€è¡Œæƒ…æ•°æ®æŸ¥è¯¢æŒ‡ä»¤ /market"""
    if not _is_command_allowed(update):
        return
    global user_handler
    if user_handler is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    try:
        loop = asyncio.get_event_loop()

        text = await loop.run_in_executor(None, lambda: user_handler.get_basic_market(
            sort_type=user_handler.user_states['basic_market_sort_type'],
            period=user_handler.user_states['basic_market_period'],
            sort_order=user_handler.user_states['basic_market_sort_order'],
            limit=user_handler.user_states['basic_market_limit'],
            market_type=user_handler.user_states['basic_market_type']
        ))

        text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
        keyboard = user_handler.get_basic_market_keyboard(
            current_sort_type=user_handler.user_states['basic_market_sort_type'],
            current_period=user_handler.user_states['basic_market_period'],
            current_sort_order=user_handler.user_states['basic_market_sort_order'],
            current_limit=user_handler.user_states['basic_market_limit'],
            current_market_type=user_handler.user_states['basic_market_type']
        )
        await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"åŸºç¡€è¡Œæƒ…æ•°æ®æŸ¥è¯¢é”™è¯¯: {e}")
        await update.message.reply_text(
            f"âŒ è·å–åŸºç¡€è¡Œæƒ…æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}",
            parse_mode='Markdown'
        )

async def flow_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """èµ„é‡‘æµå‘æ•°æ®æŸ¥è¯¢æŒ‡ä»¤ /flow"""
    if not _is_command_allowed(update):
        return
    global user_handler
    if user_handler is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    try:
        loop = asyncio.get_event_loop()

        text = await loop.run_in_executor(None, lambda: user_handler.get_money_flow(*[user_handler.user_states.get(k, None) for k in ['volume_limit', 'volume_period', 'volume_sort', 'position_limit', 'position_sort', 'funding_limit', 'funding_sort', 'liquidation_limit', 'liquidation_sort', 'liquidation_period', 'liquidation_type', 'money_flow_limit', 'money_flow_period', 'money_flow_sort', 'money_flow_type', 'money_flow_market', 'market_depth_limit', 'market_depth_sort_type', 'market_depth_sort', 'position_market_limit', 'position_market_sort', 'basic_market_sort_type', 'basic_market_period', 'basic_market_sort_order', 'basic_market_limit'] if k is not None][:3]))

        text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
        keyboard = user_handler.get_money_flow_keyboard(current_sort=user_handler.user_states['money_flow_sort'], current_limit=user_handler.user_states['money_flow_limit'], current_flow_type=user_handler.user_states['money_flow_type'])
        await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"èµ„é‡‘æµå‘æ•°æ®æŸ¥è¯¢é”™è¯¯: {e}")
        await update.message.reply_text(
            f"âŒ è·å–èµ„é‡‘æµå‘æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}",
            parse_mode='Markdown'
        )

async def depth_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¸‚åœºæ·±åº¦æ•°æ®æŸ¥è¯¢æŒ‡ä»¤ /depth"""
    if not _is_command_allowed(update):
        return
    global user_handler
    if user_handler is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    try:
        loop = asyncio.get_event_loop()

        text = await loop.run_in_executor(
            None, user_handler.get_market_depth,
            user_handler.user_states.get('market_depth_limit', 10),
            user_handler.user_states.get('market_depth_sort_type', 'ratio'),
            user_handler.user_states.get('market_depth_sort', 'desc')
        )

        text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
        keyboard = user_handler.get_market_depth_keyboard(
            current_limit=user_handler.user_states.get('market_depth_limit', 10),
            current_sort_type=user_handler.user_states.get('market_depth_sort_type', 'ratio'),
            current_sort=user_handler.user_states.get('market_depth_sort', 'desc')
        )
        await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"å¸‚åœºæ·±åº¦æ•°æ®æŸ¥è¯¢é”™è¯¯: {e}")
        await update.message.reply_text(
            f"âŒ è·å–å¸‚åœºæ·±åº¦æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}",
            parse_mode='Markdown'
        )

async def ratio_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æŒä»“/å¸‚å€¼æ¯”æ•°æ®æŸ¥è¯¢æŒ‡ä»¤ /ratio"""
    if not _is_command_allowed(update):
        return
    global user_handler
    if user_handler is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    try:
        loop = asyncio.get_event_loop()

        text = await loop.run_in_executor(None, lambda: user_handler.get_position_market_ratio(
            user_handler.user_states['position_market_limit'],
            user_handler.user_states['position_market_sort']
        ))

        text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
        keyboard = user_handler.get_position_market_ratio_keyboard(current_sort=user_handler.user_states['position_market_sort'], current_limit=user_handler.user_states['position_market_limit'])
        await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
    except Exception as e:
        logger.error(f"æŒä»“/å¸‚å€¼æ¯”æ•°æ®æŸ¥è¯¢é”™è¯¯: {e}")
        await update.message.reply_text(
            f"âŒ è·å–æŒä»“/å¸‚å€¼æ¯”æ•°æ®æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}",
            parse_mode='Markdown'
        )

async def search_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¸ç§æŸ¥è¯¢æŒ‡ä»¤ /search"""
    if not _is_command_allowed(update):
        return
    await update.message.reply_text(
        f"ğŸ’¡ å³å°†æ”¯æŒçš„åŠŸèƒ½ï¼š\n"
        f"- ğŸ“Š ä»·æ ¼èµ°åŠ¿åˆ†æ\n"
        f"- ğŸ’° æŒä»“é‡å˜åŒ–è¶‹åŠ¿\n"
        f"- ğŸ“ˆ æŠ€æœ¯æŒ‡æ ‡åˆ†æ\n"
        f"- ğŸ”” ä»·æ ¼é¢„è­¦è®¾ç½®\n\n"
        f"ğŸ“ å¦‚éœ€å¸®åŠ©è¯·è”ç³»å®¢æœï¼š\n"
        f"- å®¢æœ1: zancy1\n"
                    f"- å®¢æœ2: xiaocaixing\n"
                    f"- å®¢æœ3: wangbw123",
        reply_markup=InlineKeyboardMarkup([[
            InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
        ]]),
        parse_mode='Markdown'
    )

async def recharge_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å……å€¼æŒ‡ä»¤ /recharge"""
    if not _is_command_allowed(update):
        return
    await show_recharge_menu(update, context)

async def user_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ç”¨æˆ·ä¸­å¿ƒæŒ‡ä»¤ /user"""
    if not _is_command_allowed(update):
        return
    await show_user_center(update, context)

async def alerts_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ä¿¡å·è®¢é˜…æŒ‡ä»¤ /alerts"""
    if not _is_command_allowed(update):
        return
    await show_subscription_settings(update, context)

# æ–°å¢å‘½ä»¤å¤„ç†å™¨
async def charge_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å……å€¼æŒ‡ä»¤ /charge"""
    if not _is_command_allowed(update):
        return
    await show_recharge_menu(update, context)

async def subscribe_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ä¿¡å·è®¢é˜…æŒ‡ä»¤ /subscribe"""
    if not _is_command_allowed(update):
        return
    await show_subscription_settings(update, context)

async def status_command_user(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """ç”¨æˆ·ä¸­å¿ƒæŒ‡ä»¤ /status"""
    if not _is_command_allowed(update):
        return
    await show_user_center(update, context)

async def menu_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æ˜¾ç¤ºä¸»èœå•æŒ‡ä»¤ /menu"""
    if not _is_command_allowed(update):
        return
    global user_handler
    if user_handler is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    # å‘é€ä¸»èœå•ï¼Œä¿æŒæ°¸ä¹…å¸¸é©»é”®ç›˜
    reply_keyboard = user_handler.get_reply_keyboard()
    text = user_handler.get_main_menu_text()
    keyboard = user_handler.get_main_menu_keyboard()
    
    # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
    text = ensure_valid_text(text, "âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–")
    
    # å…ˆå‘é€ç®€çŸ­æ¬¢è¿æ¶ˆæ¯å’Œå¸¸é©»é”®ç›˜æ¥æ¿€æ´»å¸¸é©»é”®ç›˜
    await update.message.reply_text(
        "âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–",
        reply_markup=reply_keyboard    # ä½¿ç”¨å¸¸é©»é”®ç›˜
    )
    
    # å†å‘é€å®Œæ•´ä¸»èœå•æ–‡æœ¬å’Œå†…è”é”®ç›˜
    await update.message.reply_text(
        text,
        reply_markup=keyboard          # ä½¿ç”¨å†…è”é”®ç›˜
    )


async def data_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æ•°æ®é¢æ¿æŒ‡ä»¤ /data"""
    if not _is_command_allowed(update):
        return
    global user_handler
    if user_handler is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    text = _build_ranking_menu_text("basic")
    keyboard = user_handler.get_ranking_menu_keyboard()
    await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')


async def ai_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """AIåˆ†ææŒ‡ä»¤ /ai"""
    if not _is_command_allowed(update):
        return
    await update.message.reply_text(
        AI_FEATURE_NOTICE,
        reply_markup=InlineKeyboardMarkup([[
            InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
        ]]),
        parse_mode='Markdown'
    )


async def health_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¥åº·æ£€æŸ¥ /ping"""
    try:
        cache_keys = list(cache.keys())
        latest_cache_ts = max((cache[k]['timestamp'] for k in cache_keys), default=0)
        age_seconds = int(time.time() - latest_cache_ts) if latest_cache_ts else None
        await update.message.reply_text('\n'.join([
            'âœ… pong',
            f'BINANCE_API_DISABLED={BINANCE_API_DISABLED}',
            f'WEBSOCKET_MONITOR={os.getenv("ENABLE_WEBSOCKET_MONITOR", "0")}',
            f'cache_keys={len(cache_keys)}',
            f'cache_age_sec={age_seconds if age_seconds is not None else "n/a"}',
        ]))
    except Exception as e:
        await update.message.reply_text(f'âŒ ping failed: {e}')

async def status_command(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æ˜¾ç¤ºæœºå™¨äººçŠ¶æ€æŒ‡ä»¤ /status"""
    if not _is_command_allowed(update):
        return
    global bot
    if bot is None:
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    try:
        # å®‰å…¨åœ°è·å–ç¼“å­˜ä¿¡æ¯ï¼Œé¿å…Markdownè§£æé”™è¯¯
        def escape_markdown_safe(text):
            """å®‰å…¨è½¬ä¹‰Markdownç‰¹æ®Šå­—ç¬¦"""
            if not text:
                return text
            special_chars = ['_', '*', '[', ']', '(', ')', '~', '`', '>', '#', '+', '-', '=', '/', '{', '}', '.', '!']
            for char in special_chars:
                text = text.replace(char, f'\\{char}')
            return text
        
        cache_info = bot.get_cache_file_info()
        cache_status = bot.get_cache_status()
        
        # å®‰å…¨åœ°æ ¼å¼åŒ–æ‰€æœ‰åŠ¨æ€å†…å®¹
        safe_cache_info = escape_markdown_safe(str(cache_info)) if cache_info else "ç¼“å­˜ä¿¡æ¯è·å–å¤±è´¥"
        safe_cache_status = escape_markdown_safe(str(cache_status)) if cache_status else "ç¼“å­˜çŠ¶æ€è·å–å¤±è´¥"
        safe_current_file = escape_markdown_safe(str(bot._current_cache_file)) if bot._current_cache_file else "æœªçŸ¥"
        
        status_text = f"""ğŸ¤–tukuaiæœºå™¨äººçŠ¶æ€
ğŸ“Š åŠŸèƒ½çŠ¶æ€:
- å·²åˆå§‹åŒ–: {'âœ…' if bot._is_initialized else 'âŒ'}
- åå°æ›´æ–°: {'ğŸ”„ è¿›è¡Œä¸­' if bot._is_updating else 'âœ… ç©ºé—²'}
- å½“å‰ä½¿ç”¨æ–‡ä»¶: {safe_current_file}

ğŸ’¾ ç¼“å­˜æ–‡ä»¶ä¿¡æ¯:
{safe_cache_info}

ğŸ“ˆ ç¼“å­˜æ•°æ®çŠ¶æ€:
{safe_cache_status}

ğŸ”§ åŒç¼“å­˜æœºåˆ¶è¯´æ˜:
- ç³»ç»Ÿä½¿ç”¨ä¸¤ä¸ªç¼“å­˜æ–‡ä»¶è½®æ›¿æ›´æ–°
- æ›´æ–°æ—¶ç”¨æˆ·è¯·æ±‚ä¸å—å½±å“
- è‡ªåŠ¨æ¸…ç†è¿‡æœŸçš„ç¼“å­˜æ–‡ä»¶
- ç¼“å­˜æœ‰æ•ˆæœŸ: 10åˆ†é’Ÿï¼ˆå®½æ¾æ¨¡å¼ï¼‰

âš¡ ä¼˜åŒ–ç‰¹æ€§:
- éé˜»å¡åå°æ›´æ–°
- æ™ºèƒ½ç¼“å­˜é™çº§
- åŸå­æ€§æ–‡ä»¶æ“ä½œ
- è¯·æ±‚é¢‘ç‡æ§åˆ¶"""
        
        await update.message.reply_text(
            status_text,
            reply_markup=InlineKeyboardMarkup([[
                InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
            ]]),
            parse_mode='Markdown'
        )

    except Exception as e:
        logger.error(f"çŠ¶æ€å‘½ä»¤é”™è¯¯: {e}")
        await update.message.reply_text("âŒ è·å–çŠ¶æ€å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•")

async def handle_keyboard_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """å¤„ç†å¸¸é©»é”®ç›˜æŒ‰é’®æ¶ˆæ¯"""
    global user_handler

    # å®‰å…¨æ£€æŸ¥ï¼šç¡®ä¿update.messageå­˜åœ¨ä¸”æœ‰textå±æ€§
    if not update or not update.message or not hasattr(update.message, 'text') or not update.message.text:
        return

    # ç¾¤èŠç”¨æˆ·è§¦å‘çš„æ–‡æœ¬ä¹ŸæŒ‚è½½è‡ªåŠ¨åˆ é™¤
    await _maybe_delete_user_message(update, context)

    # å…¨å±€æƒé™æ‹¦æˆªï¼šæœªå¯ç”¨ï¼ˆé™¤ /helpï¼‰ä¸€å¾‹é™é»˜
    if not _is_command_allowed(update):
        return

    message_text = update.message.text
    
    # æ·»åŠ è°ƒè¯•æ—¥å¿—
    logger.info(f"ğŸ” æ”¶åˆ°æ¶ˆæ¯: '{message_text}'")
    
    if user_handler is None:
        logger.error("âŒ user_handler æœªåˆå§‹åŒ–")
        await update.message.reply_text("ğŸš€ æœºå™¨äººæ­£åœ¨åˆå§‹åŒ–ä¸­ï¼Œè¯·ç¨ç­‰...")
        return
    
    # æ˜ å°„å¸¸é©»é”®ç›˜æŒ‰é’®åˆ°å¯¹åº”åŠŸèƒ½
    button_mapping = {
        "ğŸ‹ æŒä»“é‡æ’è¡Œ": "position_ranking",
        "ğŸ’± èµ„é‡‘è´¹ç‡æ’è¡Œ": "funding_rate_ranking",
        "ğŸ“ˆ æˆäº¤é‡æ’è¡Œ": "volume_ranking",
        "ğŸ’¥ çˆ†ä»“æ’è¡Œ": "liquidation_ranking",
        "ğŸ­ å¸‚åœºæƒ…ç»ª": "market_sentiment",
        "ğŸ“¡ è¡Œæƒ…æ€»è§ˆ": "basic_market",
        "ğŸ“ˆ å¸‚åœºæ€»è§ˆ": "basic_market",
        "ğŸ’§ èµ„é‡‘æµå‘æ’è¡Œ": "money_flow",
        "ğŸ§Š å¸‚åœºæ·±åº¦æ’è¡Œ": "market_depth",
        "ğŸ“Š æ•°æ®é¢æ¿": "ranking_menu",
        "ğŸ’³ å……å€¼": "recharge",
        "ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ": "user_center",
        "ğŸš¨ ä¿¡å·": "aggregated_alerts",
        "ğŸ¤– AIåˆ†æ": "start_coin_analysis",
        "ğŸ  ä¸»èœå•": "main_menu",
        "â„¹ï¸ å¸®åŠ©": "help"
    }
    
    try:
        # -------- å•å¸æ„Ÿå¹å·è§¦å‘ï¼šå¦‚ "btc!" æˆ– "BTCï¼" --------
        import re
        norm_text = (message_text or "").replace("\u200b", "").strip()
        sym = None
        if "!" in norm_text or "ï¼" in norm_text:
            # ä¼˜å…ˆæŒ‰ç¬¦å·å‰çš„ token æŠ“å–
            m = re.search(r"([A-Za-z0-9]{2,15})\\s*[!ï¼]", norm_text, re.IGNORECASE)
            if m:
                sym = m.group(1)
            else:
                # å…œåº•ï¼šå–é¦–ä¸ªå­—æ¯/æ•°å­—ä¸²
                tokens = re.findall(r"[A-Za-z0-9]{2,15}", norm_text)
                if tokens:
                    sym = tokens[0]
        if sym:
            sym = sym.upper()
            user_id = update.effective_user.id
            # æ€§èƒ½ä¼˜åŒ–ï¼šä¸´æ—¶å…³é—­å•å¸æŸ¥è¯¢
            if os.getenv("DISABLE_SINGLE_TOKEN_QUERY", "1") == "1":
                await update.message.reply_text("âš ï¸ å•å¸æŸ¥è¯¢åŠŸèƒ½æš‚æ—¶å…³é—­ï¼ˆæ€§èƒ½ä¼˜åŒ–ä¸­ï¼‰")
                return
            # é»˜è®¤å‘¨æœŸå¼€å…³ï¼šä»…å¼€ 15m/1h/4h/1dï¼Œå…¶ä»–å¯é€šè¿‡æŒ‰é’®å†å¼€å¯
            enabled_periods = {"1m": False, "5m": False, "15m": True, "1h": True, "4h": True, "1d": True, "1w": False}
            # æŒä¹…åŒ–ç”¨æˆ·æ€ï¼ˆæŒ‰ user_id åˆ†æ¡¶ï¼‰ï¼ŒæŒ‰é’®å¯å¤ç”¨
            ustate = user_handler.user_states.setdefault(user_id, {})
            ustate["single_symbol"] = sym
            ustate["single_panel"] = "basic"
            ustate["single_periods"] = enabled_periods
            ustate["single_cards"] = {}  # é»˜è®¤å…¨å¼€ï¼ŒæŒ‰éœ€å­˜ False
            ustate["single_page"] = 0
            try:
                from bot.single_token_snapshot import SingleTokenSnapshot
                kb = build_single_snapshot_keyboard(enabled_periods, "basic", ustate["single_cards"], page=0, pages=1)
                snap = SingleTokenSnapshot()
                text, pages = snap.render_table(sym, panel="basic", enabled_periods=enabled_periods, enabled_cards=ustate["single_cards"], page=0)
                kb = build_single_snapshot_keyboard(enabled_periods, "basic", ustate["single_cards"], page=0, pages=pages)
                try:
                    await update.message.reply_text(text, reply_markup=kb, parse_mode='Markdown')
                except BadRequest as e:
                    msg = str(e).lower()
                    if "message is too long" in msg:
                        max_len = 3500
                        parts = [text[i:i+max_len] for i in range(0, len(text), max_len)]
                        await update.message.reply_text(parts[0], reply_markup=kb, parse_mode='Markdown')
                        for p in parts[1:]:
                            await update.message.reply_text(p, parse_mode='Markdown')
                    else:
                        raise
            except Exception as exc:
                logger.error("å•å¸å¿«ç…§æ¸²æŸ“å¤±è´¥: %s", exc)
                await update.message.reply_text("âŒ å•å¸æŸ¥è¯¢å¤±è´¥ï¼Œè¯·ç¨åé‡è¯•", parse_mode='Markdown')
            return

        if message_text in button_mapping:
            action = button_mapping[message_text]

            # ç™½åå•æ‹¦æˆªï¼šç¦ç”¨çŠ¶æ€ä»…å…è®¸å¸®åŠ©
            allow, _reason = _is_bot_allowed(update.message.chat, getattr(update.message, "message_thread_id", None))
            if not allow and action not in {"help"}:
                # é™é»˜ä¸¢å¼ƒ
                return
            
            # ç»Ÿä¸€å ä½ï¼šæœªå¼€æ”¾åŠŸèƒ½çš„æç¤º
            if action in {"start_coin_analysis", "aggregated_alerts"}:
                placeholder_kb = InlineKeyboardMarkup([[
                    InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"),
                    InlineKeyboardButton("ğŸ”„ åˆ·æ–°", callback_data="main_menu")
                ]])
                placeholder_text = (
                    AI_FEATURE_NOTICE if action == "start_coin_analysis"
                    else "ğŸš¨ ä¿¡å·åŠŸèƒ½æš‚æœªå¼€å‘"
                )
                await update.message.reply_text(
                    placeholder_text,
                    reply_markup=placeholder_kb,
                    parse_mode='Markdown'
                )
                return
            
            if action == "position_ranking":
                loop = asyncio.get_event_loop()
                text = await loop.run_in_executor(None, lambda: user_handler.get_position_ranking(
                    limit=user_handler.user_states.get('position_limit', 10),
                    sort_order=user_handler.user_states.get('position_sort', 'desc'),
                    period=user_handler.user_states.get('position_period', '24h')
                ))
                text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
                keyboard = user_handler.get_position_ranking_keyboard(
                    current_sort=user_handler.user_states.get('position_sort', 'desc'), 
                    current_limit=user_handler.user_states.get('position_limit', 10),
                    current_period=user_handler.user_states.get('position_period', '24h')
                )
                await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
                
            elif action == "funding_rate_ranking":
                await query.answer("åŠŸèƒ½æš‚æœªå¼€æ”¾", show_alert=True)
                
            elif action == "volume_ranking":
                loop = asyncio.get_event_loop()
                # ä¿®å¤: ä½¿ç”¨å…·ä½“çš„å‚æ•°è€Œä¸æ˜¯é€šç”¨çš„[:3]åˆ‡ç‰‡
                user_states = user_handler.user_states.get(update.effective_user.id, {})
                text = await loop.run_in_executor(None, lambda: user_handler.get_volume_ranking(
                    period=user_states.get('volume_period', '24h'),
                    sort=user_states.get('volume_sort', 'volume'),
                    limit=user_states.get('volume_limit', 10)
                ))
                text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
                keyboard = user_handler.get_volume_ranking_keyboard(
                    current_period=user_states.get('volume_period', '24h'), 
                    current_sort=user_states.get('volume_sort', 'volume'), 
                    current_limit=user_states.get('volume_limit', 10)
                )
                await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
                
            elif action == "liquidation_ranking":
                loop = asyncio.get_event_loop()
                # ä¿®å¤: ä½¿ç”¨å…·ä½“çš„å‚æ•°è€Œä¸æ˜¯é€šç”¨çš„[:3]åˆ‡ç‰‡
                user_states = user_handler.user_states.get(update.effective_user.id, {})
                text = await loop.run_in_executor(None, lambda: user_handler.get_liquidation_ranking(
                    limit=user_states.get('liquidation_limit', 10),
                    sort_order=user_states.get('liquidation_sort', 'desc'),
                    period=user_states.get('liquidation_period', '24h'),
                    liquidation_type=user_states.get('liquidation_type', 'total')
                ))
                text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
                keyboard = user_handler.get_liquidation_ranking_keyboard(
                    current_limit=user_states.get('liquidation_limit', 10), 
                    current_sort=user_states.get('liquidation_sort', 'desc'),
                    current_period=user_states.get('liquidation_period', '24h'),
                    current_type=user_states.get('liquidation_type', 'total')
                )
                await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
                
            elif action == "market_sentiment":
                await update.message.reply_text(
                    "â¸ï¸ å¸‚åœºæƒ…ç»ªæ¦œå•å·²ä¸‹çº¿ï¼Œæ•¬è¯·æœŸå¾…æ–°çš„æŒ‡æ ‡é¢æ¿ã€‚",
                    reply_markup=user_handler.get_market_sentiment_keyboard(),
                    parse_mode='Markdown'
                )
                
            elif action == "basic_market":
                loop = asyncio.get_event_loop()
                # ä¿®å¤: ä½¿ç”¨å…·ä½“çš„å‚æ•°è€Œä¸æ˜¯é€šç”¨çš„[:3]åˆ‡ç‰‡
                user_states = user_handler.user_states.get(update.effective_user.id, {})
                text = await loop.run_in_executor(None, lambda: user_handler.get_basic_market(
                    sort_type=user_states.get('basic_market_sort_type', 'change'),
                    period=user_states.get('basic_market_period', '24h'),
                    sort_order=user_states.get('basic_market_sort_order', 'desc'),
                    limit=user_states.get('basic_market_limit', 10),
                    market_type=user_states.get('basic_market_type', 'futures')
                ))
                text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
                keyboard = user_handler.get_basic_market_keyboard(
                    current_sort_type=user_states.get('basic_market_sort_type', 'change'), 
                    current_period=user_states.get('basic_market_period', '24h'), 
                    current_sort_order=user_states.get('basic_market_sort_order', 'desc'), 
                    current_limit=user_states.get('basic_market_limit', 10),
                    current_market_type=user_states.get('basic_market_type', 'futures')
                )
                await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
                
            elif action == "money_flow":
                loop = asyncio.get_event_loop()
                # ä¿®å¤: ä½¿ç”¨å…·ä½“çš„å‚æ•°è€Œä¸æ˜¯é€šç”¨çš„[:3]åˆ‡ç‰‡
                user_states = user_handler.user_states.get(update.effective_user.id, {})
                text = await loop.run_in_executor(None, lambda: user_handler.get_money_flow(
                    period=user_states.get('money_flow_period', '24h'),
                    sort=user_states.get('money_flow_sort', 'net_inflow'),
                    limit=user_states.get('money_flow_limit', 10),
                    flow_type=user_states.get('money_flow_type', 'all'),
                    market=user_states.get('money_flow_market', 'spot')
                ))
                text = ensure_valid_text(text, "ğŸ“Š æ•°æ®åŠ è½½ä¸­ï¼Œè¯·ç¨åé‡è¯•...")
                keyboard = user_handler.get_money_flow_keyboard(
                    current_period=user_states.get('money_flow_period', '24h'), 
                    current_sort=user_states.get('money_flow_sort', 'net_inflow'), 
                    current_limit=user_states.get('money_flow_limit', 10), 
                    current_flow_type=user_states.get('money_flow_type', 'all'),
                    current_market=user_states.get('money_flow_market', 'spot')
                )
                await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
                
            elif action == "market_depth":
                await update.message.reply_text(
                    "â¸ï¸ å¸‚åœºæ·±åº¦æ’è¡ŒåŠŸèƒ½å·²ä¸‹çº¿ï¼Œæ•¬è¯·æœŸå¾…æ›¿ä»£æ–¹æ¡ˆã€‚",
                    reply_markup=user_handler.get_market_depth_keyboard(),
                    parse_mode='Markdown'
                )

            elif action == "ranking_menu":
                # æ•°æ®é¢æ¿å…¥å£ï¼šæ˜¾ç¤ºæ¦œå•åˆ—è¡¨
                text = _build_ranking_menu_text(user_handler.user_states.get("ranking_group", "basic"))
                keyboard = user_handler.get_ranking_menu_keyboard()
                await update.message.reply_text(text, reply_markup=keyboard, parse_mode='Markdown')
                
            elif action == "main_menu":
                # ä¿®å¤: ä½¿ç”¨ä¸/startå‘½ä»¤ç›¸åŒçš„é€»è¾‘ï¼Œé¿å…ç©ºå­—ç¬¦ä¸²é”™è¯¯
                reply_keyboard = user_handler.get_reply_keyboard()  # å¸¸é©»é”®ç›˜
                main_text = user_handler.get_main_menu_text()
                main_keyboard = user_handler.get_main_menu_keyboard()  # å†…è”é”®ç›˜
                
                # ç¡®ä¿æ–‡æœ¬ä¸ä¸ºç©º
                main_text = ensure_valid_text(main_text, "âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–")
                
                # å…ˆå‘é€ç®€çŸ­æ¬¢è¿æ¶ˆæ¯å’Œå¸¸é©»é”®ç›˜æ¥æ¿€æ´»å¸¸é©»é”®ç›˜
                await update.message.reply_text(
                    "âš¡ï¸æ¬¢è¿ä½¿ç”¨åœŸå—é‡åŒ–",
                    reply_markup=reply_keyboard,      # æ¿€æ´»å¸¸é©»é”®ç›˜
                    parse_mode='Markdown'
                )
                
                # å†å‘é€å®Œæ•´ä¸»èœå•æ–‡æœ¬å’Œå†…è”é”®ç›˜
                await update.message.reply_text(
                    main_text,
                    reply_markup=main_keyboard,     # ä½¿ç”¨å†…è”é”®ç›˜
                    parse_mode='Markdown'
                )
                
            elif action == "help":
                # è°ƒç”¨å¸®åŠ©å‡½æ•°
                await help_command(update, context)
                
            elif action == "recharge":
                await show_recharge_menu(update, context)
                
            elif action == "user_center":
                await show_user_center(update, context)
                
            elif action == "aggregated_alerts":
                await show_subscription_settings(update, context)
                
            elif action in {"coin_search", "start_coin_analysis"}:
                await update.message.reply_text(
                    AI_FEATURE_NOTICE,
                    reply_markup=build_ai_placeholder_keyboard(),
                    parse_mode='Markdown'
                )
                return


        else:
            # å¦‚æœæ˜¯æ–œæ å¼€å¤´ä½†ä¸æ˜¯å·²çŸ¥æŒ‰é’®ï¼Œå¯èƒ½æ˜¯å‘½ä»¤ï¼Œä¸åšå¤„ç†
            if message_text.startswith('/'):
                return
            
            # æœªè¯†åˆ«çš„æ¶ˆæ¯ï¼Œæ˜¾ç¤ºæç¤º
            await update.message.reply_text(
                "ğŸ¤” æ²¡æœ‰è¯†åˆ«åˆ°æ‚¨çš„æŒ‡ä»¤ï¼Œè¯·ä½¿ç”¨ä¸‹æ–¹æŒ‰é’®æˆ–è¾“å…¥ /help æŸ¥çœ‹å¸®åŠ©ã€‚",
                parse_mode='Markdown'
            )
    except Exception as e:
        logger.error(f"å¤„ç†é”®ç›˜æ¶ˆæ¯é”™è¯¯: {e}")
        await update.message.reply_text(
            f"âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ï¼Œè¯·ç¨åé‡è¯•ã€‚\n\né”™è¯¯ä¿¡æ¯: {str(e)}",
            parse_mode='Markdown'
        )

# ================== æ•´åˆåŠŸèƒ½å‡½æ•° ==================

async def show_recharge_menu(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æ˜¾ç¤ºå……å€¼èœå• - é›†æˆzfbé€»è¾‘"""
    keyboard = [
        [
            InlineKeyboardButton("1", callback_data="recharge_1"),
            InlineKeyboardButton("5", callback_data="recharge_5"),
            InlineKeyboardButton("10", callback_data="recharge_10"),
            InlineKeyboardButton("50", callback_data="recharge_50"),
            InlineKeyboardButton("100", callback_data="recharge_100"),
            InlineKeyboardButton("300", callback_data="recharge_300"),
            InlineKeyboardButton("500", callback_data="recharge_500"),
            InlineKeyboardButton("1000", callback_data="recharge_1000")
        ],
        [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
    ]
    
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    message = (
        "ğŸ’³ å……å€¼ç§¯åˆ†\n\n"
        "è¯·åœ¨ä¸‹æ–¹é€‰æ‹©ä½ è¦å……å€¼çš„é‡‘é¢\n"
        "USDT ğŸ‘‡\n\n"
        "ğŸ’ å…‘æ¢æ¯”ä¾‹: 1 USDT = 10 ç§¯åˆ†\n"
        "âš¡ ä¿¡å·æœåŠ¡: éœ€è¦ç§¯åˆ†\n"
        "â±ï¸ æ”¯ä»˜æ—¶é™: 10åˆ†é’Ÿ\n"
        "âš ï¸ ä»…æ”¯æŒSOLé“¾USDT\n"
    )
    
    if update.message:
        await update.message.reply_text(message, parse_mode='HTML', reply_markup=reply_markup)
    else:
        await update.callback_query.edit_message_text(message, parse_mode='HTML', reply_markup=reply_markup)

async def show_user_center(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """æ˜¾ç¤ºç”¨æˆ·ä¸­å¿ƒ - é›†æˆé‚€è¯·èµšä½£å’Œæç°åŠŸèƒ½"""
    global invitation_manager

    try:
        user = update.effective_user
        user_data = DataManager.get_user_data(user.id, USER_DATA_FILE)

        # ğŸ”§ å®‰å…¨ä¿®å¤ï¼šç¡®ä¿ç”¨æˆ·æ•°æ®åŒ…å«å¿…è¦å­—æ®µï¼Œä½†ä¸è¦†ç›–ç°æœ‰æ•°æ®
        if not isinstance(user_data, dict) or not user_data:
            # å¦‚æœç”¨æˆ·æ•°æ®æ— æ•ˆï¼Œåˆ›å»ºæ–°ç”¨æˆ·æ•°æ®è€Œä¸æ˜¯ç©ºå­—å…¸
            logger.warning(f"âš ï¸ ç”¨æˆ· {user.id} æ•°æ®æ— æ•ˆï¼Œåˆ›å»ºæ–°ç”¨æˆ·æ•°æ®")
            user_data = {
                "user_id": user.id,
                "points": 0,
                "total_recharged": 0,
                "register_time": beijing_time_isoformat(),
                "last_active": beijing_time_isoformat(),
                "username": user.username or "",
                "first_name": user.first_name or "",
                "last_name": user.last_name or ""
            }

        if "invitations" not in user_data:
            user_data["invitations"] = {}
        if "invited_bonus_given" not in user_data:
            user_data["invited_bonus_given"] = False
        if "invited_by" not in user_data:
            user_data["invited_by"] = None
        if "alerts_received" not in user_data:
            user_data["alerts_received"] = {
                "ai": 0,
                "transfer": 0,
                "total": 0,
                "open_interest": 0,
                "rsi": 0,
                "funding_rate": 0
            }
        if "points" not in user_data:
            user_data["points"] = 20
        if "total_recharged" not in user_data:
            user_data["total_recharged"] = 0

        # æ›´æ–°ç”¨æˆ·ä¿¡æ¯
        user_data["username"] = user.username or user.first_name or ""
        user_data["last_active"] = beijing_time_isoformat()
        DataManager.update_user_data(user.id, user_data, USER_DATA_FILE)
    except Exception as e:
        logger.error(f"âŒ ç”¨æˆ·ä¸­å¿ƒæ•°æ®å¤„ç†é”™è¯¯: {e}")
        # å‘é€é”™è¯¯æ¶ˆæ¯ç»™ç”¨æˆ·
        error_message = "âŒ å¤„ç†è¯·æ±‚æ—¶å‘ç”Ÿé”™è¯¯ï¼Œæ­£åœ¨ä¿®å¤ç”¨æˆ·æ•°æ®..."
        if update.callback_query:
            await update.callback_query.answer(error_message)
            await update.callback_query.edit_message_text(
                "ğŸ”§ ç³»ç»Ÿæ­£åœ¨ä¿®å¤æ‚¨çš„ç”¨æˆ·æ•°æ®ï¼Œè¯·ç¨åé‡è¯•ã€‚",
                reply_markup=InlineKeyboardMarkup([[
                    InlineKeyboardButton("ğŸ”„ é‡è¯•", callback_data="user_center"),
                    InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")
                ]])
            )
        else:
            await update.message.reply_text(error_message)
        return
    
    # è·å–è®¢é˜…ä¿¡æ¯
    user_details = subscription_manager.get_user_details(user.id) if subscription_manager else {}
    alerts_received = user_details.get('alerts_received', {}) if user_details else {}
    is_subscribed = subscription_manager.is_subscribed(user.id) if subscription_manager else False
    
    # è·å–é‚€è¯·ä¿¡æ¯
    if not invitation_manager:
        invitation_manager = IntegratedInvitationManager()
    invitation_data = invitation_manager.get_user_invitation_data(user.id)
    if not invitation_data:
        invitation_manager.create_invitation(user.id, user.username)
        invitation_data = invitation_manager.get_user_invitation_data(user.id)
    
    # é‚€è¯·æ•°æ®
    invitation_code = invitation_data.get('invitation_code', f'INV_{user.id}')
    stats = invitation_data.get('stats', {})
    total_invites = stats.get('total_invites', 0)
    successful_invites = stats.get('successful_invites', 0)
    total_commission = invitation_data.get('total_commission', 0.0)
    available_commission = invitation_data.get('available_commission', 0.0)
    withdrawn_commission = invitation_data.get('withdrawn_commission', 0.0)
    commission_rate = invitation_manager.calculate_commission_rate(
        invitation_data.get('total_recharge', 0.0)
    ) * 100
    
    register_time = format_beijing_time(user_data["register_time"], "%Y-%m-%d %H:%M")
    
    # æ„å»ºé”®ç›˜ - åŒ…å«æç°åŠŸèƒ½
    keyboard = []
    
    # ç¬¬ä¸€è¡Œï¼šå…¨éƒ¨æç°å’Œè¿”å›ä¸»èœå•
    first_row = []
    
    # åªæœ‰å½“å¯æç°ä½£é‡‘å¤§äºç­‰äº1ç¾å…ƒæ—¶æ‰æ˜¾ç¤ºæç°æŒ‰é’®
    if available_commission >= 1.0:
        first_row.append(InlineKeyboardButton(f"ğŸ’° å…¨éƒ¨æç° (${available_commission:.2f})", callback_data=f"withdraw_all_{available_commission:.2f}"))
    
    first_row.append(InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu"))
    keyboard.append(first_row)
    reply_markup = InlineKeyboardMarkup(keyboard)
    
    # æ„å»ºé‚€è¯·é“¾æ¥
    BOT_USERNAME = context.bot.username
    invitation_link = f"https://t.me/{BOT_USERNAME}?start={invitation_code}"
    
    # æ„å»ºæç°çŠ¶æ€ä¿¡æ¯
    withdrawal_status = ""
    if available_commission >= 1.0:
        withdrawal_status = f"\nğŸ’° <b>æç°åŠŸèƒ½ï¼š</b>å¯ç”³è¯·å…¨éƒ¨æç°"
    elif available_commission > 0:
        withdrawal_status = f"\nğŸ’° <b>æç°åŠŸèƒ½ï¼š</b>ä½™é¢ä¸è¶³ï¼ˆæœ€ä½$1.00ï¼‰"
    else:
        withdrawal_status = f"\nğŸ’° <b>æç°åŠŸèƒ½ï¼š</b>æš‚æ— å¯æç°é‡‘é¢"
    
    # å¤„ç†ç”¨æˆ·åæ˜¾ç¤ºæ ¼å¼
    display_username = ""
    if user.username:
        display_username = f"@{user.username}"
    elif user.first_name:
        display_username = user.first_name
    else:
        display_username = "æœªè®¾ç½®"
    
    # ç”Ÿæˆå¯ç‚¹å‡»å¤åˆ¶çš„ç”¨æˆ·ID
    clickable_user_id = f"<code>{user.id}</code>"
    
    user_center_text = f"""ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ

ğŸ†” ç”¨æˆ·IDï¼š {clickable_user_id}
ğŸ‘¤ ç”¨æˆ·åï¼š {display_username}
ğŸ“… æ³¨å†Œæ—¶é—´ï¼š {register_time}
ğŸ’ å½“å‰ç§¯åˆ†ï¼š{user_data['points']}
ğŸ ç´¯è®¡å……å€¼ï¼š{user_data['total_recharged']} USDT
"""
    
    if update.message:
        await update.message.reply_text(
            user_center_text,
            parse_mode='HTML',
            reply_markup=reply_markup
        )
    else:
        await update.callback_query.edit_message_text(
            user_center_text,
            parse_mode='HTML',
            reply_markup=reply_markup
        )

async def show_subscription_settings(update: Update, context: ContextTypes.DEFAULT_TYPE):
    """è®¢é˜…åŠŸèƒ½æš‚æœªå¼€æ”¾ - ç»Ÿä¸€è¿”å›å ä½æç¤º"""
    placeholder = (
        "ğŸš§ AIå…¨å¸‚åœºå¼‚åŠ¨æé†’åŠŸèƒ½å¼€å‘ä¸­\n"
        "ğŸ“¢ å½“å‰æš‚ä¸å¯ç”¨ï¼Œæ•¬è¯·æœŸå¾…ã€‚\n"
        "ğŸ’¡ å¦‚éœ€å¸®åŠ©ï¼Œè¯·è¿”å›ä¸»èœå•ã€‚"
    )
    reply_markup = InlineKeyboardMarkup([
        [InlineKeyboardButton("ğŸ  è¿”å›ä¸»èœå•", callback_data="main_menu")]
    ])

    try:
        if update.callback_query:
            await update.callback_query.edit_message_text(
                placeholder,
                parse_mode='Markdown',
                reply_markup=reply_markup
            )
        else:
            await update.message.reply_text(
                placeholder,
                parse_mode='Markdown',
                reply_markup=reply_markup
            )
    except Exception as e:
        logger.error(f"æ˜¾ç¤ºè®¢é˜…å ä½å¤±è´¥: {e}")

async def process_recharge(update: Update, context: ContextTypes.DEFAULT_TYPE, amount: int):
    """å¤„ç†å……å€¼è¯·æ±‚ - é›†æˆzfbé€»è¾‘"""
    user_id = update.effective_user.id
    user = update.effective_user

    logger.info(f"ğŸ”” è¿›å…¥å……å€¼æµç¨‹ amount={amount} user={user_id}")

    # æ ¡éªŒæ¡£ä½ï¼Œé˜²æ­¢å¼‚å¸¸é‡‘é¢è§¦å‘é”™è¯¯è¿”å›ä¸»èœå•
    if amount not in RECHARGE_AMOUNTS:
        await update.callback_query.edit_message_text(
            f"âŒ ä¸æ”¯æŒçš„å……å€¼æ¡£ä½ï¼š{amount} USDT\nè¯·é€‰æ‹©åˆ—è¡¨ä¸­çš„é‡‘é¢é‡æ–°å‘èµ·ã€‚",
            reply_markup=InlineKeyboardMarkup([[InlineKeyboardButton("ğŸ’³ è¿”å›å……å€¼", callback_data="show_recharge")]]),
            parse_mode="HTML"
        )
        return
    
    # è·å–ç”¨æˆ·åï¼ˆä¼˜å…ˆusernameï¼Œå…¶æ¬¡first_nameï¼‰
    username = user.username if user.username else user.first_name
    username_display = f"@{user.username}" if user.username else (user.first_name or "æœªçŸ¥ç”¨æˆ·")
    
    existing_order = DataManager.get_user_active_order(user_id, amount, ORDERS_FILE)
    
    reuse_existing = False
    if existing_order:
        expires_at = datetime.fromisoformat(existing_order['expires_at'])
        deviation = amount - float(existing_order.get('exact_amount', 0))
        # è‹¥å·²è¿‡æœŸæˆ–åå·®è¶…è¿‡0.11ï¼ˆæ—§é€»è¾‘çš„å¤§å¹…åç§»ï¼‰ï¼Œæ ‡è®°è¿‡æœŸé‡å»º
        if expires_at <= get_beijing_time() or deviation > 0.11 or deviation < 0:
            existing_order['status'] = 'expired'
            orders = DataManager.load_json(ORDERS_FILE, {})
            orders[existing_order['order_id']] = existing_order
            DataManager.save_json(ORDERS_FILE, orders)
        else:
            reuse_existing = True
    
    if reuse_existing:
        order_id = existing_order['order_id']
        exact_amount = existing_order['exact_amount']
        expires_at = datetime.fromisoformat(existing_order['expires_at'])
        remaining_seconds = max(0, int((expires_at - get_beijing_time()).total_seconds()))
        remaining_minutes = remaining_seconds // 60
        remaining_secs = remaining_seconds % 60
        
        base_points = amount * 10
        bonus = 0
        if amount >= 1000:
            bonus = int(base_points * 0.25)
        elif amount >= 500:
            bonus = int(base_points * 0.10)
        
        total_points = base_points + bonus
        
        keyboard = [
            [InlineKeyboardButton("ğŸ”„ åˆ·æ–°è®¢å•", callback_data=f"refresh_order_{amount}"), 
             InlineKeyboardButton("ğŸ”™ è¿”å›å……å€¼", callback_data="recharge")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        message = (
            f"ğŸ’³ ç°æœ‰å……å€¼è®¢å•\n\n"
            f"ğŸ†” è®¢å•å·: <code>{order_id}</code>\n"
            f"ğŸ‘¤ ç”¨æˆ·å: {username_display}\n"
            f"ğŸ”¢ ç”¨æˆ·ID: <code>{user_id}</code>\n"
            f"ğŸ’° å……å€¼æ¡£ä½: {amount} USDT\n"
            f"ğŸ’¸ åˆ°è´¦é‡‘é¢: <code>{exact_amount:.4f}</code> USDT\n"
            f"ğŸ’ è·å¾—ç§¯åˆ†: {total_points}\n"
            f"â° å‰©ä½™æ—¶é—´: {remaining_minutes:02d}:{remaining_secs:02d}\n\n"
            f"ğŸ“® solé“¾æ”¶æ¬¾åœ°å€:\n"
            f"<code>{WALLET_ADDRESS}</code>\n\n"
            f"âš ï¸ é‡è¦æé†’ï¼š\n"
            f"ä»…æ”¯æŒsolé“¾çš„USDTï¼ï¼ï¼\n"
            f"ç‚¹å‡»é‡‘é¢ä¸åœ°å€å¯ä»¥ç›´æ¥å¤åˆ¶\n"
            f"å¿…é¡»è½¬è´¦ç²¾ç¡®é‡‘é¢: <code>{exact_amount:.4f}</code> USDT\n"
            f"æ­¤è®¢å•è¿˜æœ‰ {remaining_minutes:02d}:{remaining_secs:02d} æœ‰æ•ˆ\n"
            f"ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶å®Œæˆå……å€¼\n"
            f"å¦‚é‡é—®é¢˜ç‚¹å‡»è”ç³»å®¢æœ (æŠŠè¿™æ¡æ¶ˆæ¯è½¬å‘ç»™å®¢æœå³å¯) @desci0 "
        )
    else:
        import random
        # éšæœºå‡å» 0~0.0999ï¼ˆå››ä½å°æ•°ï¼Œâ‰¤1æ¯›ï¼‰ï¼Œé¿å…é‡å¤é‡‘é¢
        random_reduction = random.randint(0, 999) / 10000
        exact_amount = round(amount - random_reduction, 4)
        logger.info(f"ğŸ§¾ æ–°å»ºè®¢å•å‡†å¤‡ amount={amount} exact={exact_amount} user={user_id}")

        order_id = DataManager.create_order(user_id, amount, exact_amount, ORDERS_FILE)
        logger.info(f"ğŸ§¾ æ–°å»ºè®¢å•ç»“æœ order_id={order_id}")
        
        base_points = amount * 10
        bonus = 0
        if amount >= 1000:
            bonus = int(base_points * 0.25)
        elif amount >= 500:
            bonus = int(base_points * 0.10)
        
        total_points = base_points + bonus
        
        keyboard = [
            [InlineKeyboardButton("ğŸ”„ åˆ·æ–°è®¢å•", callback_data=f"refresh_order_{amount}"), 
             InlineKeyboardButton("ğŸ”™ è¿”å›å……å€¼", callback_data="recharge")]
        ]
        reply_markup = InlineKeyboardMarkup(keyboard)
        
        message = (
            f"ğŸ’³ æ–°å……å€¼è®¢å•\n\n"
            f"ğŸ†” è®¢å•å·: <code>{order_id}</code>\n"
            f"ğŸ‘¤ ç”¨æˆ·å: {username_display}\n"
            f"ğŸ”¢ ç”¨æˆ·ID: <code>{user_id}</code>\n"
            f"ğŸ’° å……å€¼æ¡£ä½: {amount} USDT\n"
            f"ğŸ’¸ åˆ°è´¦é‡‘é¢: <code>{exact_amount:.4f}</code> USDT\n"
            f"ğŸ’ è·å¾—ç§¯åˆ†: {total_points}\n"
            f"â° æœ‰æ•ˆæ—¶é—´: 10åˆ†é’Ÿ\n\n"
            f"ğŸ“® solé“¾æ”¶æ¬¾åœ°å€:\n"
            f"<code>{WALLET_ADDRESS}</code>\n\n"
            f"âš ï¸ é‡è¦æé†’ï¼š\n"
            f"ä»…æ”¯æŒsolé“¾çš„USDTï¼ï¼ï¼\n"
            f"ç‚¹å‡»é‡‘é¢ä¸åœ°å€å¯ä»¥ç›´æ¥å¤åˆ¶\n"
            f"å¿…é¡»è½¬è´¦ç²¾ç¡®é‡‘é¢: <code>{exact_amount:.4f}</code> USDT\n"
            f"è®¢å•10åˆ†é’Ÿå†…æœ‰æ•ˆ\n"
            f"ç³»ç»Ÿä¼šè‡ªåŠ¨æ£€æµ‹å¹¶å®Œæˆå……å€¼\n"
            f"å¦‚é‡é—®é¢˜ç‚¹å‡»è”ç³»å®¢æœ (æŠŠè¿™æ¡æ¶ˆæ¯è½¬å‘ç»™å®¢æœå³å¯) @desci0 "
        )
    
    await update.callback_query.edit_message_text(
        message,
        parse_mode='HTML',
        reply_markup=reply_markup
    )

async def initialize_bot_background():
    """åå°éé˜»å¡åˆå§‹åŒ–æœºå™¨äººå’Œç¼“å­˜ - å¹¶è¡Œå¯åŠ¨ç‰ˆæœ¬"""
    global bot, websocket_monitor, subscription_manager, signal_monitor
    try:
        print("ğŸš€ å¼€å§‹å¹¶è¡Œå¯åŠ¨æ‰€æœ‰åå°æœåŠ¡...")
        
        # å®šä¹‰æ‰€æœ‰å¯åŠ¨ä»»åŠ¡
        startup_tasks = []
        task_names = []
        
        # 1. åå°ç¼“å­˜åˆå§‹åŒ–ä»»åŠ¡
        async def cache_init_task():
            try:
                print("ğŸ“Š å¼€å§‹åå°é¢„åŠ è½½æ•°æ®ç¼“å­˜...")
                await bot.initialize_cache()
                logger.info("âœ… åå°ç¼“å­˜åˆå§‹åŒ–å®Œæˆï¼")
            except Exception as e:
                logger.error(f"âŒ ç¼“å­˜åˆå§‹åŒ–å¤±è´¥: {e}")
                logger.error(f"ç¼“å­˜åˆå§‹åŒ–å¤±è´¥: {e}")

        startup_tasks.append(cache_init_task())
        task_names.append("ç¼“å­˜åˆå§‹åŒ–")
        
        # 2. è¡¥æ‰£æ£€æŸ¥ä»»åŠ¡
        async def charge_check_task():
            try:
                if subscription_manager:
                    print("ğŸ’° æ‰§è¡Œå¯åŠ¨æ—¶è¡¥æ‰£æ£€æŸ¥...")
                    charge_result = subscription_manager.process_all_daily_charges()
                    if charge_result["success"]:
                        print(f"âœ… è¡¥æ‰£æ£€æŸ¥å®Œæˆ: å¤„ç†{charge_result.get('total_processed', 0)}ä¸ªç”¨æˆ·, "
                              f"æˆåŠŸæ‰£è´¹{charge_result.get('charged_users', 0)}ä¸ª, "
                              f"æš‚åœ{charge_result.get('suspended_users', 0)}ä¸ª")
                    else:
                        logger.warning(f"âš ï¸ è¡¥æ‰£æ£€æŸ¥å¤±è´¥: {charge_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                else:
                    logger.warning("âš ï¸ è®¢é˜…ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œè·³è¿‡è¡¥æ‰£æ£€æŸ¥")
            except Exception as e:
                logger.error(f"âŒ è¡¥æ‰£æ£€æŸ¥å¤±è´¥: {e}")
                logger.error(f"è¡¥æ‰£æ£€æŸ¥å¤±è´¥: {e}")
        
        startup_tasks.append(charge_check_task())
        task_names.append("è¡¥æ‰£æ£€æŸ¥")
        
        # 3. WebSocketç›‘æ§ä»»åŠ¡
        async def websocket_task():
            try:
                if websocket_monitor and getattr(websocket_monitor, "websocket_enabled", False):
                    print("ğŸ”— å¯åŠ¨WebSocketå……å€¼ç›‘æ§...")
                    await websocket_monitor.start_monitoring()
                    logger.info("âœ… WebSocketç›‘æ§å·²å¯åŠ¨ï¼")
                else:
                    logger.info("â¸ï¸ WebSocketç›‘æ§å·²ç¦ç”¨æˆ–æœªé…ç½®")
            except Exception as e:
                logger.error(f"âŒ WebSocketç›‘æ§å¯åŠ¨å¤±è´¥: {e}")
                logger.error(f"WebSocketç›‘æ§å¯åŠ¨å¤±è´¥: {e}")

        startup_tasks.append(websocket_task())
        task_names.append("WebSocketç›‘æ§")
        
        # 4. åå°åˆ·æ–°ä»»åŠ¡
        async def refresh_task():
            try:
                print("ğŸ”„ å¯åŠ¨åå°ç¼“å­˜åˆ·æ–°ä»»åŠ¡...")
                asyncio.create_task(bot.refresh_cache_background())
                logger.info("âœ… åå°åˆ·æ–°ä»»åŠ¡å·²å¯åŠ¨ï¼")
            except Exception as e:
                logger.error(f"âŒ åå°åˆ·æ–°ä»»åŠ¡å¯åŠ¨å¤±è´¥: {e}")
                logger.error(f"åå°åˆ·æ–°ä»»åŠ¡å¯åŠ¨å¤±è´¥: {e}")
        
        startup_tasks.append(refresh_task())
        task_names.append("åå°åˆ·æ–°")
        
        # 5. å®šæ—¶æ‰£è´¹ä»»åŠ¡
        async def scheduler_task():
            try:
                print("â° å¯åŠ¨å®šæ—¶æ‰£è´¹ä»»åŠ¡...")
                asyncio.create_task(start_daily_charge_scheduler())
                logger.info("âœ… å®šæ—¶æ‰£è´¹ä»»åŠ¡å·²å¯åŠ¨ï¼")
            except Exception as e:
                logger.error(f"âŒ å®šæ—¶æ‰£è´¹ä»»åŠ¡å¯åŠ¨å¤±è´¥: {e}")
                logger.error(f"å®šæ—¶æ‰£è´¹ä»»åŠ¡å¯åŠ¨å¤±è´¥: {e}")
        
        startup_tasks.append(scheduler_task())
        task_names.append("å®šæ—¶æ‰£è´¹")
        
        # 6. ä¿¡å·ç›‘æ§ä»»åŠ¡ï¼ˆä¿æŒå…³é—­ï¼‰
        
        # å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å¯åŠ¨ä»»åŠ¡
        logger.info(f"ğŸš€ å¼€å§‹å¹¶è¡Œæ‰§è¡Œ {len(startup_tasks)} ä¸ªå¯åŠ¨ä»»åŠ¡...")
        start_time = time.time()
        
        # ä½¿ç”¨asyncio.gatherå¹¶è¡Œæ‰§è¡Œï¼Œreturn_exceptions=Trueç¡®ä¿å³ä½¿æŸä¸ªä»»åŠ¡å¤±è´¥ä¹Ÿä¸å½±å“å…¶ä»–ä»»åŠ¡
        results = await asyncio.gather(*startup_tasks, return_exceptions=True)
        
        elapsed_time = time.time() - start_time
        
        # ç»Ÿè®¡ç»“æœ
        success_count = 0
        error_count = 0
        
        for i, result in enumerate(results):
            if isinstance(result, Exception):
                error_count += 1
                name = task_names[i] if i < len(task_names) else f"ä»»åŠ¡{i}"
                logger.error(f"âŒ {name}ä»»åŠ¡å¤±è´¥: {result}")
                logger.error(f"{name}ä»»åŠ¡å¤±è´¥: {result}")
            else:
                success_count += 1
        
        print(f"ğŸ‰ å¹¶è¡Œå¯åŠ¨å®Œæˆ! æˆåŠŸ: {success_count}/{len(startup_tasks)}, ç”¨æ—¶: {elapsed_time:.2f}ç§’")
        
        if error_count > 0:
            logger.warning(f"âš ï¸ æœ‰ {error_count} ä¸ªä»»åŠ¡å¯åŠ¨å¤±è´¥ï¼Œä½†ç³»ç»Ÿå°†ç»§ç»­è¿è¡Œ")
        else:
            logger.info("âœ… æ‰€æœ‰åå°æœåŠ¡å¯åŠ¨æˆåŠŸï¼")
            
    except Exception as e:
        logger.error(f"âŒ å¹¶è¡Œå¯åŠ¨è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        logger.error(f"å¹¶è¡Œå¯åŠ¨è¿‡ç¨‹å‘ç”Ÿå¼‚å¸¸: {e}")
        import traceback
        traceback.print_exc()

async def start_daily_charge_scheduler():
    """å¯åŠ¨æ¯æ—¥æ‰£è´¹å®šæ—¶è°ƒåº¦å™¨"""
    global subscription_manager
    
    async def daily_charge_task():
        """æ¯æ—¥å®šæ—¶æ‰£è´¹ä»»åŠ¡"""
        while True:
            try:
                # è®¡ç®—ä¸‹ä¸€ä¸ªå‡Œæ™¨00:01çš„æ—¶é—´
                now = get_beijing_time()
                tomorrow = now.replace(hour=0, minute=1, second=0, microsecond=0) + timedelta(days=1)
                seconds_until_charge = (tomorrow - now).total_seconds()
                
                logger.info(f"å®šæ—¶æ‰£è´¹ä»»åŠ¡ç­‰å¾… {seconds_until_charge/3600:.1f} å°æ—¶åæ‰§è¡Œ")
                
                # ç­‰å¾…åˆ°æ‰£è´¹æ—¶é—´
                await asyncio.sleep(seconds_until_charge)
                
                # æ‰§è¡Œæ¯æ—¥æ‰£è´¹
                if subscription_manager:
                    logger.info("å¼€å§‹æ‰§è¡Œæ¯æ—¥å®šæ—¶æ‰£è´¹...")
                    charge_result = subscription_manager.process_all_daily_charges()
                    
                    if charge_result["success"]:
                        charged = charge_result.get("charged_users", 0)
                        suspended = charge_result.get("suspended_users", 0)
                        revenue = charge_result.get("total_revenue", 0)
                        
                        logger.info(f"æ¯æ—¥æ‰£è´¹å®Œæˆ: æˆåŠŸæ‰£è´¹{charged}ä¸ªç”¨æˆ·, æš‚åœ{suspended}ä¸ªç”¨æˆ·, æ”¶å…¥{revenue}ç§¯åˆ†")
                        
                        # å¯ä»¥åœ¨è¿™é‡Œæ·»åŠ é€šçŸ¥ç®¡ç†å‘˜çš„é€»è¾‘
                        # await notify_admin_charge_result(charge_result)
                    else:
                        logger.error(f"æ¯æ—¥æ‰£è´¹å¤±è´¥: {charge_result.get('message', 'æœªçŸ¥é”™è¯¯')}")
                else:
                    logger.error("è®¢é˜…ç®¡ç†å™¨æœªåˆå§‹åŒ–ï¼Œæ— æ³•æ‰§è¡Œæ‰£è´¹")
                    
            except Exception as e:
                logger.error(f"å®šæ—¶æ‰£è´¹ä»»åŠ¡å¼‚å¸¸: {e}")
                # ç­‰å¾…5åˆ†é’Ÿåé‡è¯•
                await asyncio.sleep(300)
    
    # å¯åŠ¨å®šæ—¶ä»»åŠ¡
    asyncio.create_task(daily_charge_task())
def initialize_bot_sync():
    """åŒæ­¥åˆå§‹åŒ–æœºå™¨äººå®ä¾‹ï¼ˆä¸åŠ è½½ç¼“å­˜ï¼‰"""
    global bot, user_handler, subscription_manager, invitation_manager, websocket_monitor, signal_monitor
    
    print("ğŸš€ å¯åŠ¨tukuaiåŠ å¯†å¸‚åœºæƒ…æŠ¥æœºå™¨äºº...")
    print("ğŸ“Š UIè®¾è®¡: åŠ¨æ€è§†å›¾å¯¹é½ + ä¸“ä¸šæ’è¡Œæ¦œå±•ç¤º")
    print("âš¡ åŠŸèƒ½: ä»·æ ¼/æŒä»“/èµ„é‡‘è´¹ç‡æ’è¡Œæ¦œ + ä¿¡å·ç›‘æ§")
    print("ğŸ’¾ æ¶æ„: æ•°æ®å¤„ç†ä¸ç”¨æˆ·äº¤äº’åˆ†ç¦»ï¼Œæ— é˜»å¡è®¾è®¡")
    
    # ğŸ”§ ç´§æ€¥ä¿®å¤ï¼šå…ˆéªŒè¯å’Œæ¸…ç†ç°æœ‰çŠ¶æ€
    logger.info("ğŸ”§ ç´§æ€¥ä¿®å¤ï¼šå¼€å§‹é‡æ–°åˆå§‹åŒ–æ‰€æœ‰ç»„ä»¶...")
    
    # æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å’Œä¿®å¤
    logger.info("ğŸ” å¼€å§‹æ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
    try:
        integrity_result = DataManager.validate_data_integrity()
        if integrity_result["success"]:
            if integrity_result["fixes_applied"]:
                logger.info(f"âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å®Œæˆï¼Œåº”ç”¨äº† {len(integrity_result['fixes_applied'])} é¡¹ä¿®å¤")
            else:
                logger.info("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å®Œæˆï¼Œæ‰€æœ‰æ•°æ®æ­£å¸¸")
        else:
            logger.warning("âš ï¸ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å‘ç°é—®é¢˜ï¼Œä½†ç»§ç»­å¯åŠ¨")
    except Exception as e:
        logger.error(f"âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥: {e}")
    
    try:
    # ğŸ”§ å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–ç”¨æˆ·è¯·æ±‚å¤„ç†å™¨
        logger.info("ğŸ”§ æ­£åœ¨å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–ç”¨æˆ·è¯·æ±‚å¤„ç†å™¨...")
        user_handler = UserRequestHandler(card_registry=ensure_ranking_registry())
        if user_handler is None:
            raise RuntimeError("UserRequestHandleråˆ›å»ºå¤±è´¥")
        logger.info("âœ… ç”¨æˆ·è¯·æ±‚å¤„ç†å™¨å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–å®Œæˆ")
        
        # ğŸ”§ å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–è®¢é˜…ç®¡ç†å™¨
        logger.info("ğŸ”§ æ­£åœ¨å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–è®¢é˜…ç®¡ç†å™¨...")
        subscription_manager = IntegratedSubscriptionManager()
        if subscription_manager is None:
            raise RuntimeError("IntegratedSubscriptionManageråˆ›å»ºå¤±è´¥")
        logger.info("âœ… è®¢é˜…ç®¡ç†å™¨å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–å®Œæˆ")
        
        # ğŸ”§ å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–é‚€è¯·ç®¡ç†å™¨
        logger.info("ğŸ”§ æ­£åœ¨å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–é‚€è¯·ç®¡ç†å™¨...")
        invitation_manager = IntegratedInvitationManager()
        if invitation_manager is None:
            raise RuntimeError("IntegratedInvitationManageråˆ›å»ºå¤±è´¥")
        logger.info("âœ… é‚€è¯·ç®¡ç†å™¨å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–ç®¡ç†å‘˜ç®¡ç†å™¨
        # admin_manager = AdminManager()  # å·²åˆ é™¤
        logger.info("âœ… ç®¡ç†å‘˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–ç®€åŒ–ç®¡ç†å‘˜ç®¡ç†å™¨
        pass  # simple_admin_managerå·²åˆ é™¤
        logger.info("âœ… ç®€åŒ–ç®¡ç†å‘˜ç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ")
        
        # å¯ç”¨é“¾ä¸Šå……å€¼ç›‘æ§ï¼ˆå¯é€šè¿‡ ENABLE_WEBSOCKET_MONITOR å…³é—­ï¼‰
        websocket_monitor = WebSocketMonitor()
        logger.info("âœ… WebSocket å……å€¼ç›‘æ§åˆå§‹åŒ–å®Œæˆ")
        
        # åˆå§‹åŒ–åå°æ•°æ®å¤„ç†æœºå™¨äººå®ä¾‹
        bot = TradeCatBot()
        logger.info("âœ… åå°æ•°æ®å¤„ç†æœºå™¨äººåˆå§‹åŒ–å®Œæˆ")
        print("ğŸ”„ æ•°æ®ç¼“å­˜å°†åœ¨åå°å¼‚æ­¥åŠ è½½ï¼Œä¸å½±å“ç”¨æˆ·äº¤äº’...")
        
    except Exception as e:
        logger.error(f"âŒ ç»„ä»¶åˆå§‹åŒ–å¤±è´¥: {e}")
        raise e
    
    # ğŸ”§ éªŒè¯å…³é”®ç»„ä»¶çŠ¶æ€
    print(f"ğŸ”§ éªŒè¯ç»“æœ: user_handler = {user_handler}")
    print(f"ğŸ”§ éªŒè¯ç»“æœ: user_handlerç±»å‹ = {type(user_handler)}")
    print(f"ğŸ”§ éªŒè¯ç»“æœ: subscription_manager = {subscription_manager}")
    print(f"ğŸ”§ éªŒè¯ç»“æœ: invitation_manager = {invitation_manager}")
    
    # æœ€ç»ˆéªŒè¯
    if user_handler is None:
        raise RuntimeError("âŒ ä¸¥é‡é”™è¯¯: user_handleråˆå§‹åŒ–å¤±è´¥")
    if subscription_manager is None:
        raise RuntimeError("âŒ ä¸¥é‡é”™è¯¯: subscription_manageråˆå§‹åŒ–å¤±è´¥")
    if invitation_manager is None:
        raise RuntimeError("âŒ ä¸¥é‡é”™è¯¯: invitation_manageråˆå§‹åŒ–å¤±è´¥")
        
    logger.info("âœ… ç´§æ€¥ä¿®å¤å®Œæˆ: æ‰€æœ‰æ ¸å¿ƒç»„ä»¶å·²å¼ºåˆ¶é‡æ–°åˆå§‹åŒ–å¹¶éªŒè¯é€šè¿‡")
    print("ğŸš€ æœºå™¨äººç°åœ¨åº”è¯¥å¯ä»¥æ­£å¸¸å“åº”ç”¨æˆ·è¾“å…¥äº†ï¼")


async def post_init(application):
    """åº”ç”¨å¯åŠ¨åçš„åˆå§‹åŒ–"""
    global signal_monitor
    
    # æœ¬åœ°CSVæ¨¡å¼ï¼šå…³é—­ä¿¡å·ç›‘æ§è°ƒåº¦ï¼Œä»…ä¿ç•™å‰ç«¯å ä½æç¤º
    signal_monitor = None
    logger.info("â¸ï¸ ä¿¡å·ç›‘æ§å™¨æœªå¯åŠ¨ï¼ˆæœ¬åœ°CSV/ä»…å‰ç«¯å±•ç¤ºæ¨¡å¼ï¼‰")
    logger.info("ğŸ¤– AIåˆ†ææš‚æœªå¼€æ”¾ï¼Œè·³è¿‡AIå¯¹è¯å¤„ç†å™¨æ³¨å†Œ")
    
    # ğŸ”§ ç»Ÿä¸€ä½¿ç”¨ç®¡ç†è®¢é˜…åŠŸèƒ½ï¼Œæ— éœ€æ•°æ®åŒæ­¥
    logger.info("âœ… è®¢é˜…ç³»ç»Ÿä½¿ç”¨ç»Ÿä¸€æ•°æ®æº ()")
    
    # å»¶è¿Ÿå¯åŠ¨åå°ç¼“å­˜åŠ è½½ä»»åŠ¡ï¼Œç¡®ä¿botå…ˆå“åº”ç”¨æˆ·
    async def delayed_init():
        await asyncio.sleep(5)  # ç­‰å¾…5ç§’è®©botå…ˆæ­£å¸¸è¿è¡Œ
        await initialize_bot_background()
    
    asyncio.create_task(delayed_init())
    
    # è®¾ç½®Telegramå‘½ä»¤èœå•
    from telegram import BotCommand
    commands = [
        BotCommand("start", "ğŸ  å¼€å§‹ä½¿ç”¨"),
        BotCommand("data", "ğŸ“Š æ•°æ®é¢æ¿"),
        BotCommand("ai", "ğŸ¤– AIåˆ†æ"),
        BotCommand("charge", "ğŸ’³ å……å€¼"),
        BotCommand("subscribe", "ğŸš¨ ä¿¡å·"),
        BotCommand("status", "ğŸ‘¤ ç”¨æˆ·ä¸­å¿ƒ"),
        BotCommand("help", "â„¹ï¸ å¸®åŠ©")
    ]
    
    try:
        await application.bot.set_my_commands(commands)
        logger.info("âœ… Telegramå‘½ä»¤èœå•è®¾ç½®æˆåŠŸ")
    except Exception as e:
        logger.warning(f"âš ï¸ è®¾ç½®å‘½ä»¤èœå•å¤±è´¥: {e}")



def cleanup_existing_processes():
    """æ¸…ç†å·²å­˜åœ¨çš„Pythonè¿›ç¨‹ï¼Œé¿å…æœºå™¨äººå®ä¾‹å†²çª"""
    try:
        import subprocess
        import platform
        import time
        import psutil
        
        system = platform.system()
        current_pid = os.getpid()
        
        print("ğŸ§¹ æ­£åœ¨å¼ºåŠ›æ£€æŸ¥å¹¶æ¸…ç†å¯èƒ½å†²çªçš„è¿›ç¨‹...")
        print(f"ğŸ” å½“å‰è¿›ç¨‹ PID: {current_pid}")
        
        # æ–¹æ³•1ï¼šç²¾ç¡®æŸ¥æ‰¾å’Œç»ˆæ­¢å†²çªçš„Pythonè¿›ç¨‹ï¼ˆæ’é™¤å½“å‰è¿›ç¨‹ï¼‰
        if system == "Windows":
            try:
                print("ğŸ”§ æ–¹æ³•1: æŸ¥æ‰¾å¹¶ç»ˆæ­¢å†²çªçš„Pythonè¿›ç¨‹...")
                
                # å…ˆæŸ¥æ‰¾æ‰€æœ‰Pythonè¿›ç¨‹
                result = subprocess.run(
                    ['tasklist', '/FI', 'IMAGENAME eq python.exe', '/FO', 'CSV'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                
                if result.returncode == 0 and result.stdout:
                    lines = result.stdout.strip().split('\n')
                    killed_count = 0
                    
                    for line in lines[1:]:  # è·³è¿‡æ ‡é¢˜è¡Œ
                        if 'python.exe' in line:
                            try:
                                # è§£æCSVæ ¼å¼çš„è¾“å‡º
                                parts = line.split(',')
                                if len(parts) >= 2:
                                    pid_str = parts[1].strip('"')
                                    pid = int(pid_str)
                                    
                                    # ä¸ç»ˆæ­¢å½“å‰è¿›ç¨‹
                                    if pid != current_pid:
                                        subprocess.run(['taskkill', '/F', '/PID', str(pid)], 
                                                     capture_output=True, timeout=5)
                                        killed_count += 1
                                        print(f"ğŸ”§ å·²ç»ˆæ­¢è¿›ç¨‹ PID: {pid}")
                            except (ValueError, subprocess.TimeoutExpired):
                                continue
                    
                    if killed_count > 0:
                        print(f"âœ… å·²æ¸…ç† {killed_count} ä¸ªå†²çªè¿›ç¨‹")
                        time.sleep(2)  # ç­‰å¾…è¿›ç¨‹å®Œå…¨ç»ˆæ­¢
                    else:
                        print("âœ… æœªå‘ç°å†²çªè¿›ç¨‹")
                else:
                    print("âœ… æœªå‘ç°Pythonè¿›ç¨‹")
                    
            except Exception as e:
                print(f"âš ï¸ è¿›ç¨‹æ¸…ç†å¤±è´¥: {e}")
        
        # æ–¹æ³•2ï¼šä½¿ç”¨psutilç²¾ç¡®æŸ¥æ‰¾å’Œç»ˆæ­¢
        try:
            print("ğŸ”§ æ–¹æ³•2: ä½¿ç”¨psutilç²¾ç¡®æ¸…ç†...")
            killed_count = 0
            
            for proc in psutil.process_iter(['pid', 'name', 'cmdline']):
                try:
                    if proc.info['name'] and 'python' in proc.info['name'].lower():
                        pid = proc.info['pid']
                        if pid != current_pid:  # ä¸ç»ˆæ­¢å½“å‰è¿›ç¨‹
                            proc.kill()
                            killed_count += 1
                            print(f"ğŸ”§ å·²ç»ˆæ­¢Pythonè¿›ç¨‹ PID: {pid}")
                except (psutil.NoSuchProcess, psutil.AccessDenied, psutil.ZombieProcess):
                    continue
            
            if killed_count > 0:
                print(f"âœ… å·²ç²¾ç¡®æ¸…ç† {killed_count} ä¸ªPythonè¿›ç¨‹")
                time.sleep(2)  # ç­‰å¾…è¿›ç¨‹å®Œå…¨ç»ˆæ­¢
            else:
                print("âœ… æœªå‘ç°éœ€è¦æ¸…ç†çš„Pythonè¿›ç¨‹")
                
        except ImportError:
            print("âš ï¸ psutilä¸å¯ç”¨ï¼Œè·³è¿‡ç²¾ç¡®æ¸…ç†")
        except Exception as e:
            print(f"âš ï¸ ç²¾ç¡®æ¸…ç†å¤±è´¥: {e}")
        
        # æ–¹æ³•3ï¼šéªŒè¯æ¸…ç†ç»“æœ
        try:
            print("ğŸ” æ–¹æ³•3: éªŒè¯æ¸…ç†ç»“æœ...")
            if system == "Windows":
                result = subprocess.run(
                    ['tasklist', '/FI', 'IMAGENAME eq python.exe'],
                    capture_output=True,
                    text=True,
                    timeout=10
                )
                if "python.exe" in result.stdout:
                    remaining_lines = [line for line in result.stdout.split('\n') if 'python.exe' in line]
                    print(f"âš ï¸ ä»æœ‰ {len(remaining_lines)} ä¸ªPythonè¿›ç¨‹è¿è¡Œ")
                    for line in remaining_lines:
                        print(f"   {line.strip()}")
                else:
                    print("âœ… ç¡®è®¤ï¼šæ²¡æœ‰å‘ç°å…¶ä»–Pythonè¿›ç¨‹")
            
        except Exception as e:
            print(f"âš ï¸ éªŒè¯å¤±è´¥: {e}")
        
        print("ğŸš€ è¿›ç¨‹æ¸…ç†å®Œæˆï¼Œå‡†å¤‡å¯åŠ¨æœºå™¨äºº...")
        print("â³ ç­‰å¾…5ç§’ç¡®ä¿è¿›ç¨‹å®Œå…¨ç»ˆæ­¢...")
        time.sleep(5)
        
    except Exception as e:
        print(f"âš ï¸ è¿›ç¨‹æ¸…ç†è¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e}")
        print("ğŸ”„ ç»§ç»­å¯åŠ¨æœºå™¨äºº...")
        import traceback
        traceback.print_exc()

def main():
    """ä¸»å‡½æ•°"""
    try:
        # ğŸ”§ ç¬¬ä¸€æ­¥ï¼šæ¸…ç†å¯èƒ½å†²çªçš„è¿›ç¨‹ (æš‚æ—¶ç¦ç”¨ä»¥é¿å…è‡ªæ€)
        # cleanup_existing_processes()

        print(f"ğŸ”‘ ä½¿ç”¨ BOT_TOKEN: {BOT_TOKEN[:10]}...{BOT_TOKEN[-10:]}")

        # ğŸ” ç¬¬äºŒæ­¥ï¼šæ•°æ®å®Œæ•´æ€§æ£€æŸ¥ - é˜²æ­¢æ•°æ®é‡ç½®
        print("ğŸ” æ­£åœ¨è¿›è¡Œæ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
        try:
            integrity_result = DataManager.validate_data_integrity()
            if integrity_result["success"]:
                if integrity_result["issues_found"]:
                    print(f"âš ï¸ å‘ç° {len(integrity_result['issues_found'])} ä¸ªæ•°æ®é—®é¢˜")
                    print(f"âœ… åº”ç”¨äº† {len(integrity_result['fixes_applied'])} ä¸ªä¿®å¤")
                else:
                    print("âœ… æ•°æ®å®Œæ•´æ€§æ£€æŸ¥é€šè¿‡")
            else:
                print("âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¤±è´¥ï¼Œä½†ç»§ç»­å¯åŠ¨")
        except Exception as e:
            print(f"âŒ æ•°æ®å®Œæ•´æ€§æ£€æŸ¥å¼‚å¸¸: {e}")
            print("ğŸ”„ ç»§ç»­å¯åŠ¨æœºå™¨äºº...")

        # é¦–å…ˆåŒæ­¥åˆå§‹åŒ–æœºå™¨äººå®ä¾‹ï¼ˆå¿«é€Ÿï¼Œä¸é˜»å¡ï¼‰
        initialize_bot_sync()
        
        # åˆ›å»ºåº”ç”¨ï¼ˆå¢åŠ è¶…æ—¶ä¸é‡è¯•å®¹é”™ï¼‰
        print("ğŸ—ï¸ æ­£åœ¨åˆ›å»º Telegram Application...")
        # httpx v0.27 åœ¨ python-telegram-bot ä¸­ä¸å†æ”¯æŒ proxy å‚æ•°ï¼›ç›´æ¥ä¾èµ–ç¯å¢ƒå˜é‡è‡ªåŠ¨è¯»å–
        logger.info("ğŸŒ æœªæ˜¾å¼è®¾ç½®ä»£ç†å‚æ•°ï¼ŒæŒ‰ httpx é»˜è®¤è¡Œä¸ºä½¿ç”¨ç¯å¢ƒå˜é‡ç›´è¿/ä»£ç†")

        request = HTTPXRequest(
            connect_timeout=8,
            read_timeout=15,
        )
        _patch_extbot_auto_delete()
        application = Application.builder().token(BOT_TOKEN).request(request).build()
        logger.info("âœ… Telegram Application åˆ›å»ºæˆåŠŸ")
        
        # å…¨å±€é”™è¯¯å¤„ç†ï¼šæ•è·ç½‘ç»œæŠ–åŠ¨ç­‰å¼‚å¸¸ï¼Œé¿å…è¿›ç¨‹é€€å‡º
        async def log_error(update, context):
            err = context.error
            logger.exception("Telegram handler error", exc_info=err)
            # é’ˆå¯¹ç½‘ç»œç±»é”™è¯¯åšçŸ­æš‚é€€é¿ï¼Œé˜²æ­¢å´©æºƒ
            from telegram.error import NetworkError, TimedOut, RetryAfter
            delay = 1
            if isinstance(err, RetryAfter):
                delay = min(30, int(getattr(err, "retry_after", 1)) + 1)
            elif isinstance(err, (NetworkError, TimedOut)):
                delay = 3
            await asyncio.sleep(delay)

        application.add_error_handler(log_error)
        logger.info("âœ… å…¨å±€é”™è¯¯å¤„ç†å™¨å·²æ³¨å†Œ")

        # æ·»åŠ å¤„ç†å™¨ - å…ˆæŒ‚è½½å‘½ä»¤å¼ºåˆ¶è‡ªåŠ¨åˆ é™¤ï¼Œå†æŒ‚é€šç”¨æ–‡æœ¬è‡ªåŠ¨åˆ é™¤
        application.add_handler(MessageHandler(filters.COMMAND, _force_delete_command), group=-2)
        logger.info("âœ… å‘½ä»¤å¼ºåˆ¶è‡ªåŠ¨åˆ é™¤å·²æ³¨å†Œ")

        # æè‡´ä¸¥æ ¼æ¨¡å¼ï¼šç¾¤å…³é—­æ—¶æ‹¦æˆªæ‰€æœ‰æ¶ˆæ¯/å‘½ä»¤ï¼ˆé™¤ /helpï¼‰
        application.add_handler(MessageHandler(filters.ALL, _block_disabled_messages), group=-3)
        application.add_handler(MessageHandler(filters.COMMAND, _block_disabled_commands), group=-3)

        # æ·»åŠ å¤„ç†å™¨ - æ³¨å†Œæ‰€æœ‰å‘½ä»¤
        print("ğŸ“‹ æ­£åœ¨æ³¨å†Œå‘½ä»¤å¤„ç†å™¨...")
        application.add_handler(CommandHandler("start", start))
        logger.info("âœ… /start å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        application.add_handler(CommandHandler("help", help_command))
        logger.info("âœ… /help å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        application.add_handler(CommandHandler("menu", menu_command))
        logger.info("âœ… /menu å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        application.add_handler(CommandHandler("ping", health_command))
        logger.info("âœ… /ping å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        
        # æ–°å‘½ä»¤ç³»ç»Ÿ
        application.add_handler(CommandHandler("charge", charge_command))
        logger.info("âœ… /charge å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        application.add_handler(CommandHandler("subscribe", subscribe_command))
        logger.info("âœ… /subscribe å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        application.add_handler(CommandHandler("status", status_command_user))
        logger.info("âœ… /status å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        application.add_handler(CommandHandler("data", data_command))
        logger.info("âœ… /data å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        application.add_handler(CommandHandler("ai", ai_command))
        logger.info("âœ… /ai å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        
        # ä¿ç•™æ—§å‘½ä»¤å…¼å®¹æ€§
        application.add_handler(CommandHandler("stats", user_command))
        logger.info("âœ… /stats å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œï¼ˆå…¼å®¹ï¼‰")
        application.add_handler(CommandHandler("recharge", recharge_command))
        logger.info("âœ… /recharge å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œï¼ˆå…¼å®¹ï¼‰")
        
        # ç®¡ç†å‘˜å‘½ä»¤å·²ç§»é™¤
        logger.info("â¸ï¸ ç®¡ç†å‘˜å‘½ä»¤å·²ç¦ç”¨")
        logger.info("âœ… æ‰€æœ‰å‘½ä»¤å¤„ç†å™¨å·²æ³¨å†Œ")
        
        logger.info("ğŸ¤– AIåˆ†ææš‚æœªå¼€æ”¾ï¼Œè·³è¿‡AIå¯¹è¯å¤„ç†å™¨æ³¨å†Œ")
        
        application.add_handler(CallbackQueryHandler(button_callback))
        logger.info("âœ… å…¨å±€å›è°ƒæŸ¥è¯¢å¤„ç†å™¨å·²æ³¨å†Œ")
        
        # æ·»åŠ æ¶ˆæ¯å¤„ç†å™¨ï¼ˆå¤„ç†å¸¸é©»é”®ç›˜æŒ‰é’®ï¼‰
        application.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_keyboard_message))
        logger.info("âœ… æ¶ˆæ¯å¤„ç†å™¨å·²æ³¨å†Œ")
        
        # è®¾ç½®å¯åŠ¨ååˆå§‹åŒ–ï¼ˆåå°å¼‚æ­¥åŠ è½½ç¼“å­˜ï¼‰
        application.post_init = post_init
        
        # å¯åŠ¨æœºå™¨äºº
        logger.info("âœ… æœºå™¨äººå·²å¯åŠ¨ï¼Œç­‰å¾…æ¶ˆæ¯...")
        print("ğŸ”— æ•°æ®æº: Binance Futures API") 
        print("ğŸ’¾ ç¼“å­˜ç­–ç•¥: æœºå™¨äººç«‹å³å¯ç”¨ï¼Œæ•°æ®åå°å¼‚æ­¥åŠ è½½")
        print("ğŸ“ ç°åœ¨å¯ä»¥å‘é€ /start å‘½ä»¤æµ‹è¯•æœºå™¨äººï¼")
        print("âš¡ æ³¨æ„ï¼šåˆæ¬¡ä½¿ç”¨æ—¶æ•°æ®åŠŸèƒ½å¯èƒ½éœ€è¦å‡ ç§’é’ŸåŠ è½½")
        
        # æ˜¾å¼é˜»å¡ä¸»çº¿ç¨‹ï¼šclose_loop=True äº¤ç”±åº“å…³é—­äº‹ä»¶å¾ªç¯ï¼Œstop_signals=None é¿å…é¢å¤–ä¿¡å·å¹²æ‰°
        application.run_polling(
            allowed_updates=Update.ALL_TYPES,
            drop_pending_updates=True,  # ä¸¢å¼ƒå¾…å¤„ç†çš„æ›´æ–°ï¼Œé¿å…å†²çª
            close_loop=True,  # å…è®¸åº“å…³é—­å¾ªç¯ï¼ˆä¿®å¤ä¸é˜»å¡é—®é¢˜ï¼‰
            stop_signals=None  # ä¸æ³¨å†Œä¿¡å·å¤„ç†ï¼Œç¡®ä¿æ­£å¸¸é˜»å¡
        )
        
    except Exception as e:
        logger.error(f"âŒ æœºå™¨äººå¯åŠ¨å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()

# ================== ç®¡ç†å‘˜åŠŸèƒ½ ==================

# ================== ç®€åŒ–ç®¡ç†å‘˜åŠŸèƒ½ ==================

# ç®¡ç†å‘˜æ“ä½œå†å²æ–‡ä»¶è·¯å¾„
ADMIN_LOGS_FILE = os.path.join(DATA_DIR, "admin_logs.json")  # ç®¡ç†å‘˜æ“ä½œå†å²

def add_signal_formatting_to_bot():
    """ä¸ºTradeCatBotç±»æ·»åŠ ä¿¡å·æ ¼å¼åŒ–æ–¹æ³•"""
    
    def format_signal_message(self, signal_type: str, symbol: str, alert_value: float) -> str:
        """æ ¼å¼åŒ–ä¿¡å·æ¶ˆæ¯"""
        try:
            if not self.signal_formatter:
                return f"âŒ ä¿¡å·æ ¼å¼åŒ–å™¨æœªåˆå§‹åŒ–"
            
            result = None
            if signal_type == "funding_rate":
                result = self.signal_formatter.format_funding_rate_signal(symbol, alert_value)
            elif signal_type == "open_interest":
                result = self.signal_formatter.format_open_interest_signal(symbol, alert_value)
            elif signal_type == "rsi":
                result = self.signal_formatter.format_rsi_signal(symbol, alert_value)
            else:
                return f"âŒ æœªçŸ¥ä¿¡å·ç±»å‹: {signal_type}"
            
            # å¦‚æœä¿¡å·æ ¼å¼åŒ–å‡½æ•°è¿”å›Noneï¼Œè¡¨ç¤ºæ•°æ®ä¸å¯ç”¨ï¼Œè¿”å›Noneè€Œä¸æ˜¯é”™è¯¯æ¶ˆæ¯
            return result
            
        except Exception as e:
            logger.error(f"æ ¼å¼åŒ–ä¿¡å·æ¶ˆæ¯é”™è¯¯: {e}")
            return None  # å¼‚å¸¸æ—¶ä¹Ÿè¿”å›Noneè€Œä¸æ˜¯é”™è¯¯æ¶ˆæ¯
    
    def send_formatted_signal(self, signal_type: str, symbol: str, alert_value: float, chat_id: str = None):
        """å‘é€æ ¼å¼åŒ–çš„ä¿¡å·æ¶ˆæ¯"""
        try:
            message = self.format_signal_message(signal_type, symbol, alert_value)
            
            # åªæœ‰åœ¨æ¶ˆæ¯ä¸ä¸ºNoneæ—¶æ‰å‘é€
            if message:
                if chat_id:
                    # å‘é€åˆ°æŒ‡å®šèŠå¤©ï¼ˆè¿™é‡Œéœ€è¦å®é™…çš„å‘é€å®ç°ï¼‰
                    logger.info(f"å‘é€ä¿¡å·åˆ° {chat_id}: {signal_type} - {symbol}")
                    # å®é™…å‘é€é€»è¾‘éœ€è¦æ ¹æ®å…·ä½“çš„botå®ç°æ¥æ·»åŠ 
                    print(f"ğŸ“¡ å‘é€ä¿¡å·åˆ° {chat_id}:\n{message}")
                else:
                    # å‘é€åˆ°æ‰€æœ‰è®¢é˜…ç”¨æˆ·ï¼ˆè¿™é‡Œéœ€è¦å®é™…çš„å¹¿æ’­å®ç°ï¼‰
                    logger.info(f"å¹¿æ’­ä¿¡å·: {signal_type} - {symbol}")
                    # å®é™…å¹¿æ’­é€»è¾‘éœ€è¦æ ¹æ®å…·ä½“çš„botå®ç°æ¥æ·»åŠ 
                    print(f"ğŸ“¡ å¹¿æ’­ä¿¡å·:\n{message}")
            else:
                logger.debug(f"ğŸ“Š è·³è¿‡ {symbol} ä¿¡å·å‘é€ï¼Œæ•°æ®ä¸å¯ç”¨")
                
        except Exception as e:
            logger.error(f"å‘é€æ ¼å¼åŒ–ä¿¡å·é”™è¯¯: {e}")
    
    def get_formatted_signal_preview(self, signal_type: str, symbol: str, alert_value: float) -> str:
        """è·å–æ ¼å¼åŒ–ä¿¡å·é¢„è§ˆ"""
        try:
            result = self.format_signal_message(signal_type, symbol, alert_value)
            if result is None:
                return "ğŸ“Š æ•°æ®æš‚ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
            return result
        except Exception as e:
            logger.error(f"è·å–ä¿¡å·é¢„è§ˆé”™è¯¯: {e}")
            return "ğŸ“Š æ•°æ®æš‚ä¸å¯ç”¨ï¼Œè¯·ç¨åé‡è¯•"
    
    # æ·»åŠ å‘é€æ¶ˆæ¯çš„æ–¹æ³•
    async def send_message_to_user(self, user_id: int, message: str, parse_mode: str = 'HTML'):
        """å‘é€æ¶ˆæ¯ç»™æŒ‡å®šç”¨æˆ·"""
        try:
            # è¿™é‡Œéœ€è¦å®é™…çš„Telegram Bot APIå®ç°
            # å¦‚æœbotæœ‰telegram appå®ä¾‹ï¼Œä½¿ç”¨å®ƒ
            if hasattr(self, 'app') and self.app:
                await self.app.bot.send_message(
                    chat_id=user_id,
                    text=message,
                    parse_mode=parse_mode
                )
                logger.info(f"âœ… æ¶ˆæ¯å‘é€æˆåŠŸç»™ç”¨æˆ· {user_id}")
            else:
                # å¦‚æœæ²¡æœ‰appå®ä¾‹ï¼Œä½¿ç”¨ç›´æ¥çš„Bot APIè°ƒç”¨
                import requests
                BOT_TOKEN = _require_env('BOT_TOKEN', required=True)
                url = f"https://api.telegram.org/bot{BOT_TOKEN}/sendMessage"
                payload = {
                    'chat_id': user_id,
                    'text': message,
                    'parse_mode': parse_mode
                }
                # é…ç½®SSLéªŒè¯
                verify_ssl = certifi.where() if CERTIFI_AVAILABLE else True
                response = requests.post(url, json=payload, timeout=10, verify=verify_ssl)
                if response.status_code == 200:
                    logger.info(f"âœ… æ¶ˆæ¯å‘é€æˆåŠŸç»™ç”¨æˆ· {user_id}")
                else:
                    logger.error(f"âŒ æ¶ˆæ¯å‘é€å¤±è´¥: {response.status_code}")
        except Exception as e:
            logger.error(f"âŒ å‘é€æ¶ˆæ¯ç»™ç”¨æˆ· {user_id} å¤±è´¥: {e}")
            raise e
    
    async def send_signal_to_user(self, user_id: int, signal_type: str, symbol: str, alert_value: float, custom_message: str = None):
        """å‘é€æ ¼å¼åŒ–ä¿¡å·ç»™æŒ‡å®šç”¨æˆ·ï¼ˆå¸¦GIFåŠ¨ç”»ï¼‰"""
        try:
            # å¦‚æœæä¾›äº†è‡ªå®šä¹‰æ¶ˆæ¯ï¼Œä½¿ç”¨è‡ªå®šä¹‰æ¶ˆæ¯ï¼Œå¦åˆ™æ ¼å¼åŒ–ä¿¡å·æ¶ˆæ¯
            if custom_message:
                message = custom_message
            else:
                message = self.format_signal_message(signal_type, symbol, alert_value)
                if not message:
                    logger.warning(f"æ— æ³•æ ¼å¼åŒ–ä¿¡å· {signal_type} - {symbol}ï¼Œè·³è¿‡å‘é€")
                    return
            
            # æ ¹æ®ä¿¡å·ç±»å‹é€‰æ‹©å¯¹åº”çš„GIFæ–‡ä»¶
            gif_file_map = {
                'funding_rate': str((ANIMATION_DIR / 'ç‹™å‡»ä¿¡å·.gif.mp4').resolve()),
                'open_interest': str((ANIMATION_DIR / 'è¶‹åŠ¿ä¿¡å·.gif.mp4').resolve()),
                'rsi': str((ANIMATION_DIR / 'æƒ…ç»ªä¿¡å·.gif.mp4').resolve())
            }
            
            gif_file = gif_file_map.get(signal_type)
            
            # å‘é€æ¶ˆæ¯ï¼ˆå¸¦GIFåŠ¨ç”»ï¼‰
            if gif_file and os.path.exists(gif_file):
                try:
                    if hasattr(self, 'app') and self.app:
                        with open(gif_file, 'rb') as gif:
                            await self.app.bot.send_animation(
                                chat_id=user_id,
                                animation=gif,
                                caption=message,  # å°†ä¿¡å·æ–‡æœ¬ä½œä¸ºGIFçš„è¯´æ˜æ–‡å­—
                                parse_mode='HTML',
                                duration=3,  # åŠ¨ç”»æ—¶é•¿
                                width=320,   # åŠ¨ç”»å®½åº¦
                                height=240   # åŠ¨ç”»é«˜åº¦
                            )
                        logger.info(f"âœ… æˆåŠŸå‘é€å¸¦GIFçš„ {signal_type} ä¿¡å·ç»™ç”¨æˆ· {user_id}")
                    else:
                        # å¦‚æœæ²¡æœ‰appå®ä¾‹ï¼Œå›é€€åˆ°çº¯æ–‡æœ¬æ¶ˆæ¯
                        await self.send_message_to_user(user_id, message, 'HTML')
                        logger.info(f"âœ… æˆåŠŸå‘é€ {signal_type} ä¿¡å·ç»™ç”¨æˆ· {user_id} (çº¯æ–‡æœ¬)")
                except Exception as gif_error:
                    logger.warning(f"âš ï¸ å‘é€GIFå¤±è´¥ï¼Œä½¿ç”¨çº¯æ–‡æœ¬: {gif_error}")
                    # GIFå‘é€å¤±è´¥æ—¶ï¼Œå›é€€åˆ°çº¯æ–‡æœ¬æ¶ˆæ¯
                    await self.send_message_to_user(user_id, message, 'HTML')
            else:
                # æ²¡æœ‰GIFæ–‡ä»¶æ—¶ï¼Œå‘é€çº¯æ–‡æœ¬æ¶ˆæ¯
                await self.send_message_to_user(user_id, message, 'HTML')
                logger.info(f"âœ… æˆåŠŸå‘é€ {signal_type} ä¿¡å·ç»™ç”¨æˆ· {user_id}")
                
        except Exception as e:
            logger.error(f"âŒ å‘é€ä¿¡å·ç»™ç”¨æˆ· {user_id} å¤±è´¥: {e}")
            raise e
    
    async def start_bot(self):
        """å¯åŠ¨æœºå™¨äººï¼ˆå ä½ç¬¦æ–¹æ³•ï¼‰"""
        logger.info("âœ… æœºå™¨äººå¯åŠ¨å®Œæˆ")
        return True
    
    async def stop_bot(self):
        """åœæ­¢æœºå™¨äººï¼ˆå ä½ç¬¦æ–¹æ³•ï¼‰"""
        logger.info("ğŸ›‘ æœºå™¨äººå·²åœæ­¢")
        return True
    
    # å°†æ–¹æ³•æ·»åŠ åˆ°TradeCatBotç±»
    TradeCatBot.format_signal_message = format_signal_message
    TradeCatBot.send_formatted_signal = send_formatted_signal
    TradeCatBot.get_formatted_signal_preview = get_formatted_signal_preview
    TradeCatBot.send_message_to_user = send_message_to_user
    TradeCatBot.send_signal_to_user = send_signal_to_user
    TradeCatBot.start_bot = start_bot
    TradeCatBot.stop_bot = stop_bot
    
    logger.info("âœ… ä¿¡å·æ ¼å¼åŒ–å’Œå‘é€æ–¹æ³•å·²æ·»åŠ åˆ°TradeCatBotç±»")

# è°ƒç”¨å‡½æ•°æ·»åŠ æ–¹æ³•
add_signal_formatting_to_bot()



if __name__ == "__main__":
    # ä½¿ç”¨å®Œæ•´å¯åŠ¨æ¨¡å¼ï¼ŒåŒ…å«æ‰€æœ‰åŠŸèƒ½
    main() 
